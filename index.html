<!DOCTYPE html>
<meta charset=UTF-8>
<meta name=viewport content="width=device-width, initial-scale=1.0, user-scalable=0">
<title>QuickArrays</title>
<style rel=stylesheet>
button,
select,
input,
textarea {
  font: inherit;          /* inherits size, family, weight, line-height */
  letter-spacing: inherit;
}
.qa-itemlist-title,.qa-itemlist-colon{font-weight:700;}
html,body{text-size-adjust:none}html{background-color:#ddd;width:100%;font-family:RalewaySemiBold,sans-serif}
@media (width<=640px){
  html{font-size:3.2vw} 
  .qa-itemlist-enabled .qa-itemlist-header, .qa-itemlist-disabled .qa-itemlist-header{flex: 0 0 100%;width: 100%;}
  .qa-itemlist-disabled > .qa-itemlist-header{border-top: 1px solid #ddd; margin-top: 12px;padding-top: 12px;}
}
@media (width>=641px){html{font-size:16px}}body{background-color:#fff;flex-direction:column;margin:0;padding:0;display:flex}.qa-header{background-color:#ddd;background-position:.5em .5em;background-repeat:no-repeat;background-size:auto 3em;flex-shrink:0;height:4em}.qa-header h1{text-align:right;margin:0;padding-top:2em;padding-right:1em;font-size:1em;font-weight:700}@media (width<=720px){.qa-main{margin:0;padding:1em}}@media (width>=721px) and (width<=1280px),(width>=721px) and (height<=720px){.qa-main{margin:1em;padding:1em}}@media (width>=1281px) and (width<=1920px) and (height>=721px){.qa-main{margin:2em;padding:2em}}@media (width>=1921px) and (height>=721px){.qa-main{min-width:1856px;max-width:1856px;margin:2em auto;padding:2em}}.qa-main{box-sizing:border-box;background-color:#cfc;border:2px solid #9b9;border-radius:.5em;flex-direction:column;display:flex}.qa-main>*{flex-shrink:0;margin-bottom:.5em}.qa-description{margin-top:1em;margin-left:.5em;font-weight:700}.qa-textarea{box-sizing:border-box;resize:none;border:1px solid #9b9;padding:.5em;font-family:Source Code Pro,monospace;font-size:1em}.qa-shorttext{width:2em;padding-left:.5em;font-family:Source Code Pro,monospace}.qa-itemlist,.qa-stats{box-sizing:border-box;background-color:#fff;border:1px solid #9b9;flex-direction:column;padding:.25em;display:flex}.qa-item{box-sizing:border-box;cursor:move;cursor:-webkit-grabbing;border:1px solid #9b9;flex-shrink:0;margin:.25em;padding:.2em}.qa-itemlist-enabled,.qa-itemlist-disabled{box-sizing:border-box;flex-wrap:wrap;flex-shrink:0;width:100%;display:flex}.qa-itemlist-enabled .qa-item{background-color:#cfc}.qa-itemlist-disabled .qa-item{background-color:#fcc}.qa-itemlist-enabled .qa-item-ghost{background-color:#efe!important;border-color:#000!important}.qa-itemlist-disabled .qa-item-ghost{background-color:#fee!important;border-color:#000!important}.qa-item-drag{background-color:#fff!important;border-color:#000!important}.qa-itemlist-header{box-sizing:border-box;margin:.25em;padding:.2em}.qa-options{box-sizing:border-box;background-color:#fff;border:1px solid #9b9;flex-wrap:wrap;padding:.25em;display:flex}.qa-option{box-sizing:border-box;flex-shrink:0;margin:.25em .75em .25em .25em;padding:.2em}.qa-tooltiptext{visibility:hidden;color:#fff;text-align:left;z-index:1;background-color:#000;border-radius:6px;width:300px;margin:1em;padding:1em;position:absolute}.qa-item:active .qa-tooltiptext{display:none!important}.qa-item:hover .qa-tooltiptext{visibility:visible}.qa-hidden{display:none!important}#qa-tutorial-overlay{z-index:1000;width:100%;height:100%;display:none;position:fixed;top:0;left:0}#qa-tutorial-box{background-color:#fff;border:1px solid #888;width:50%;margin:15% auto;padding:20px;position:relative;box-shadow:0 4px 8px #0003}#qa-tutorial-close-button{cursor:pointer;font-size:28px;position:absolute;top:10px;right:15px}#qa-tutorial-open-button{display:none}
  .qa-toggle-btn{
  margin-left:.5em;
  padding:.05em .5em;
  border:1px solid #9b9;
  background:#fff;
  border-radius:.25em;
  font:inherit;
  cursor:pointer;
  }
  .qa-toggle-btn:active{ transform:translateY(1px); }

  /* Data-structures compact view */
  #qa-structures-compact-controls{
    margin:.25em;
    padding:.2em;
    display:flex;
    align-items:center;
    gap:.5em;
    flex-wrap:wrap;
  }
  #qa-structures-add-select{ min-width:14em; }
  #qa-structures-box.qa-compact-on #qa-structures-enabled .qa-itemlist-header{display:none!important}

</style>
<body>
  <div class=qa-header>
    <h1><i class="fa fa-circle-o-notch"></i> QuickArrays</h1>
  </div>
  <div class=qa-main>
    <div class=qa-description>
      <label for=qa-generate-string-list>Enter your text below or generate it:</label>
      <select id=qa-generate-string-list name=qa-generate-string-list>
        <option value=custom selected>Custom</option>
        <option value=baum_sweet_word title="k-th Baum-Sweet Word">Baum-Sweet</option>
        <option value=chacon_word title="k-th Chacon Word">Chacon</option>
        <option value=fibonacci_word title="k-th Fibonacci Word">Fibonacci</option>
        <option value=kolakoski_word title="k-th Kolakoski Word">Kolakoski</option>
        <option value=mephisto_waltz_word title="k-th Mephisto-Waltz Word">Mephisto-Waltz</option>
        <option value=von_neumann_word title="von Neumann Word">Neumannn</option>
        <option value=pell_word title="k-th Pell Word">Pell</option>
        <option value=rudin_shapiro_word title="k-th Rudin-Shapiro Word">Rudin-Shapiro</option>
        <option value=sierpinski_word title="Sierpinski Word">Sierpinski</option>
        <option value=thue_morse_word title="k-th Thue-Morse Word">Thue-Morse</option>
        <option value=tribonacci_word title="k-th Tribonacci Word">Tribonacci</option>
        <option value=vtm_word title="variant ternary squarefree Thue–Morse word">vtm</option>
      </select>
      <span id=qa-generate-string-span class=qa-hidden>
      <label for=qa-generate-string-range>Order:</label>
      <input type=range id=qa-generate-string-range name=qa-generate-string-range min=0 max=6 value=3 step=1>
      <span id=qa-generate-string-rank>3</span>
      </span>
      <button id=qa-tutorial-open-button></button>
    </div>
    <textarea class=qa-textarea id=qa-text placeholder=MISSISSIPPI></textarea>
    <div class=qa-itemlist>
      <div class=div>
        <label for=qa-transform-list>Text Transforms:</label>
        <select id=qa-transform-list name=qa-transform-list>
          <option value=none>None</option>
          <option value=bbw_transform title="Bijective Burrows-Wheeler Transform">BBWT</option>
          <option value=inverse_bbw_transform title="Inverse Bijective Burrows-Wheeler Transform">BBWT⁻¹</option>
          <option value=bw_transform title="Burrows-Wheeler Transform">BWT</option>
          <option value=first_array title="First Column Array">F</option>
          <option value=invert_transform title="Inverts a string by mapping each character to its complementary character">Invert</option>
          <option value=necklace_conjugate_transform title="Lexicographically smallest conjugate of a given string.">necklace</option>
          <option value=revert_transform title="Reverts a string by reading it backwards">Revert</option>
          <option value=custom>Custom</option>
        </select>
        <span id=qa-transform-active-span class=qa-hidden> 
        <input type=checkbox id=qa-transform-active name=qa-transform-active> <label for=qa-transform-active>activate</label>
        </span>
      </div>
      <textarea class="qa-hidden qa-textarea" id=qa-transform-input placeholder="text[i] == 'a' ? 'b' : 'a'"></textarea>
    </div>
    <div class=qa-description id=qa-structures-description>Choose your data structures and factorizations (drag and drop or double-click):<br>
      You can use drag and drop to reorder your selection!
    </div>
    <div class=qa-itemlist id=qa-structures-box>
      <div id="qa-structures-enabled" class="qa-itemlist-enabled">
        <!-- remove: <input type=checkbox id=qa-structures-enabled-visible ...> -->
        <div class="qa-itemlist-header">
          <span class="qa-itemlist-title">Enabled<span class="qa-itemlist-colon">:</span></span>
          <button type="button" class="qa-toggle-btn" aria-expanded="true">hide</button>
        </div>
        <div class="qa-item qa-structure qa-structure-string" data-ds="text">T</div>
        <div class="qa-item qa-structure qa-structure-index" data-ds="index_array">i<span class="qa-tooltiptext">Index Array</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds="suffix_array">SA<span class="qa-tooltiptext">Suffix Array</span></div>
      </div>
      <div id=qa-structures-compact-controls class=qa-hidden>
        <select id=qa-structures-add-select>
          <option value="" selected disabled>Add a structure…</option>
        </select>
      </div>
      
      <div id="qa-structures-disabled-string" class="qa-itemlist-disabled">
        <div class="qa-itemlist-header">
          <span class="qa-itemlist-title">Strings<span class="qa-itemlist-colon">:</span></span>
          <button type="button" class="qa-toggle-btn" aria-expanded="true">hide</button>
        </div>
      </div>
      <div id="qa-structures-disabled-index" class="qa-itemlist-disabled">
        <div class="qa-itemlist-header">
          <span class="qa-itemlist-title">Index arrays<span class="qa-itemlist-colon">:</span></span>
          <button type="button" class="qa-toggle-btn" aria-expanded="true">hide</button>
        </div>
      </div>
      <div id="qa-structures-disabled-length" class="qa-itemlist-disabled">
        <div class="qa-itemlist-header">
          <span class="qa-itemlist-title">Length arrays<span class="qa-itemlist-colon">:</span></span>
          <button type="button" class="qa-toggle-btn" aria-expanded="true">hide</button>
        </div>
      </div>
      <div id="qa-structures-disabled-factor" class="qa-itemlist-disabled">
        <div class="qa-itemlist-header">
          <span class="qa-itemlist-title">Factorizations<span class="qa-itemlist-colon">:</span></span>
          <button type="button" class="qa-toggle-btn" aria-expanded="true">hide</button>
        </div>
      </div>
      <div id="qa-structures-disabled-source" class="qa-hidden">
        <div class="qa-item qa-structure qa-structure-factor" data-ds=gamma_factorization>Γ<span class=qa-tooltiptext>Leftmost Smallest String Attractor</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=phi_array>Φ<span class=qa-tooltiptext>Phi Array</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=inverse_phi_array>Φ⁻¹<span class=qa-tooltiptext>Inverse Phi Array</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=psi_array>Ψ<span class=qa-tooltiptext>Psi Array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=border_array>B<span class=qa-tooltiptext>Border Array</span></div>
        <div class="qa-item qa-structure qa-structure-string" data-ds=bbw_transform>BBWT<span class=qa-tooltiptext>Bijective Burrows-Wheeler Transform</span></div>
        <div class="qa-item qa-structure qa-structure-string" data-ds=inverse_bbw_transform>BBWT⁻¹<span class=qa-tooltiptext>Inverse Bijective Burrows-Wheeler Transform</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=bbw_indices>BBWTi<span class=qa-tooltiptext>Text-Indices of the Bijective Burrows-Wheeler Transform</span></div>
        <div class="qa-item qa-structure qa-structure-string" data-ds=bw_transform>BWT<span class=qa-tooltiptext>Burrows-Wheeler Transform</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=inverse_circular_suffix_array>CISA<span class=qa-tooltiptext>Inverse Circular Suffix Array</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=circular_suffix_array>CSA<span class=qa-tooltiptext>Circular Suffix Array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=even_maximal_palindromic_length_array>e-pali<span class=qa-tooltiptext>Even Maximal Palindromic Length Array</span></div>
        <div class="qa-item qa-structure qa-structure-string" data-ds=first_array>F<span class=qa-tooltiptext>First Column Array</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=inverse_suffix_array>ISA<span class=qa-tooltiptext>Inverse Suffix Array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=lcp_array>LCP<span class=qa-tooltiptext>Longest Common Prefix array</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lexparse_factorization>LexParse<span class=qa-tooltiptext>Lexicographic Parse Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=lf_array>LF<span class=qa-tooltiptext>Last-to-First Mapping Array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=lnf_array>LNF<span class=qa-tooltiptext>Longest Next Factor array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=lpf_array>LPF<span class=qa-tooltiptext>Longest Previous Factor array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=lpnf_array>LPnF<span class=qa-tooltiptext>Longest Previous Non-Overlapping Factor array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=lyndon_array>Lyndon<span class=qa-tooltiptext>Lyndon Array</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lyndon_factorization>LynF<span class=qa-tooltiptext>Lyndon Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lz77_factorization>LZ77<span class=qa-tooltiptext>LZ77 Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lz78_factorization>LZ78<span class=qa-tooltiptext>LZ78 Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lzend_factorization>LZend<span class=qa-tooltiptext>LZ-end Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lzss_factorization>LZSS<span class=qa-tooltiptext>LZSS Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lzssno_factorization>LZSSno<span class=qa-tooltiptext>LZSS non-overlapping Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=lzw_factorization>LZW<span class=qa-tooltiptext>LZW Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=necklace_factorization>NeckF<span class=qa-tooltiptext>Necklace Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=nss_array>NSS<span class=qa-tooltiptext>Next Smaller Suffix Array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=odd_maximal_palindromic_length_array>o-pali<span class=qa-tooltiptext>Odd Maximal Palindromic Length Array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=plcp_array>PLCP<span class=qa-tooltiptext>Permuted Longest Common Prefix array</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=pss_array>PSS<span class=qa-tooltiptext>Previous Smaller Suffix Array</span></div>
        <div class="qa-item qa-structure qa-structure-factor" data-ds=reverse_lzss_factorization>rLZSS<span class=qa-tooltiptext>Reverse LZSS Factorization</span></div>
        <div class="qa-item qa-structure qa-structure-index" data-ds=rotation_array>Rot<span class=qa-tooltiptext>Rotation Array</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=sl_string>S/L<span class=qa-tooltiptext>S/L SAIS type string</span></div>
        <div class="qa-item qa-structure qa-structure-length" data-ds=substring_complexity>SC<span class=qa-tooltiptext>Substring Complexity Array</span></div>
      </div>
    </div>
        <div class=qa-options>
      <label class=qa-option><input type=checkbox id=qa-compact-view>Compact view</label>
      <label class=qa-option><input type=checkbox id=qa-show-advanced-options>Show advanced options</label>
<label class="qa-option qa-advanced-option">Prepend:&nbsp;<input id=qa-prepend-input name=qa-prepend-input class=qa-shorttext></label>
      <label class="qa-option qa-advanced-option">Append:&nbsp; <input id=qa-append-input name=qa-append-input class=qa-shorttext></label>
      <label class="qa-option qa-advanced-option"><input type=checkbox class=qa-option-cbx name=qa-option-dollar data-opt=dollar checked>Append '$'</label>
      <label class="qa-option qa-advanced-option"><input type=checkbox class=qa-option-cbx name=qa-option-baseone data-opt=baseone checked>Base Indices on '1'</label>
      <label class="qa-option qa-advanced-option"><input type=checkbox class=qa-option-cbx name=qa-option-whitespace data-opt=whitespace checked>Whitespaces as ⎵ and ↵</label>
      <label class="qa-option qa-advanced-option"><input type=checkbox class=qa-option-cbx name=qa-option-facttext data-opt=facttext checked>Factorization as Bars</label>
      <label class="qa-option qa-advanced-option"><input type=checkbox class=qa-option-cbx name=qa-option-tabularize data-opt=tabularize checked>Tabularize Text</label>
      <label class="qa-option qa-advanced-option">Separator:&nbsp;&nbsp;<input id=qa-separator-input class=qa-shorttext></label>
    </div>
    <div class=qa-description>
      QuickArrays built the following data structures and factorizations for you in
      <select id=qa-output-select name=qa-output-select>
        <option value=plain selected>text form</option>
        <option value=latex>LaTeX</option>
        <option value=markdown>markdown</option>
        <option value=csv>CSV</option>
      </select>
      :
    </div>
    <textarea class=qa-textarea style=flex-grow:1;line-height:175% id=qa-ds-output readonly></textarea>
    <div id=qa-counter-output></div>
    <div class=qa-description>Choose your counters
      <input type=checkbox id=qa-counter-automatic value=1 checked>
      <label for=qa-counter-automatic>automatically</label>.
      &nbsp;&nbsp;
      A text counters returns the size of its run length encoding, a factorization counter the numbers of its factors.
    </div>
    <div class="qa-hidden qa-itemlist" id=qa-counter-itemlists>
      <div id=qa-counter-enabled class=qa-itemlist-enabled>
        <input type=checkbox id=qa-counter-enabled-visible value=1 checked>
        <div class=qa-itemlist-header>Enabled: </div>
        <div class="qa-counter qa-item" data-ds=text>T</div>
      </div>
      <div id=qa-counter-disabled class=qa-itemlist-disabled>
        <input type=checkbox id=qa-counter-disabled-visible value=1 checked>
        <div class=qa-itemlist-header>Disabled: </div>
        <div class="qa-counter qa-item" data-ds=delta>
          δ
          <div class=qa-tooltiptext>Substring Complexity Measure</div>
        </div>
        <div class="qa-counter qa-item" data-ds=gamma_factorization>
          Γ
          <div class=qa-tooltiptext>Leftmost Smallest String Attractor</div>
        </div>
        <div class="qa-counter qa-item" data-ds=sigma>
          σ
          <div class=qa-tooltiptext>Alphabet size</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lcp_array>
          Σ LCP
          <div class=qa-tooltiptext>Sum of LCP array values</div>
        </div>
        <div class="qa-counter qa-item" data-ds=bbw_transform>
          BBWT
          <div class=qa-tooltiptext>Bijective Burrows-Wheeler Transform</div>
        </div>
        <div class="qa-counter qa-item" data-ds=inverse_bbw_transform>
          BBWT⁻¹
          <div class=qa-tooltiptext>Inverse Bijective Burrows-Wheeler Transform</div>
        </div>
        <div class="qa-counter qa-item" data-ds=bw_transform>
          BWT
          <div class=qa-tooltiptext>Burrows-Wheeler Transform</div>
        </div>
        <div class="qa-counter qa-item" data-ds=exponent>
          e
          <div class=qa-tooltiptext>Exponent</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lexparse_factorization>
          LexParse
          <div class=qa-tooltiptext>Lexicographic Parse Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lyndon_factorization>
          LynF
          <div class=qa-tooltiptext>Lyndon Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lz77_factorization>
          LZ77
          <div class=qa-tooltiptext>LZ77 Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lz78_factorization>
          LZ78
          <div class=qa-tooltiptext>LZ78 Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lzend_factorization>
          LZend
          <div class=qa-tooltiptext>LZ-end Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lzss_factorization>
          LZSS
          <div class=qa-tooltiptext>LZSS Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lzssno_factorization>
          LZSSno
          <div class=qa-tooltiptext>LZSS non-overlapping Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=lzw_factorization>
          LZW
          <div class=qa-tooltiptext>LZW Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=delta_argmax>
          max δ
          <div class=qa-tooltiptext>Substring Complexity Measure Length</div>
        </div>
        <div class="qa-counter qa-item" data-ds=necklace_factorization>
          NeckF
          <div class=qa-tooltiptext>Necklace Factorization</div>
        </div>
        <div class="qa-counter qa-item" data-ds=period>
          p
          <div class=qa-tooltiptext>Shortest Period</div>
        </div>
        <div class="qa-counter qa-item" data-ds=regularity>
          R
          <div class=qa-tooltiptext>Regularity Type</div>
        </div>
        <div class="qa-counter qa-item" data-ds=reverse_lzss_factorization>
          rLZSS
          <div class=qa-tooltiptext>Reverse LZSS Factorization</div>
        </div>
      </div>
    </div>
    <div class=qa-description>
      <label for=qa-timeout>Timeout:</label>
      <input type=range id=qa-timeout-range min=0 max=30 value=3 step=1>
      <span id=qa-timeout-value>3</span>s
      &nbsp;&nbsp;
      <span id=qa-computation-status></span>
    </div>
    <div class=qa-description>
      The state of QuickArrays is stored in the URL.<br>
      By creating a bookmark, you can return to the current state at any time.
    </div>
    <div style=text-align:right>
      Questions or problems? Feel free to use our <a href=https://github.com/quickarrays/quickarrays.github.io/issues>bug tracker</a>, or drop <a href=https://ellert.xyz/>Jonas</a> or <a href=https://dkppl.de/>Dominik</a> a mail.
      Like it? Cite us and give us <a href=https://github.com/quickarrays/quickarrays.github.io>a star at GitHub</a>!
    </div>
  </div>
  <div id=qa-tutorial-overlay>
    <div id=qa-tutorial-box>
      <span id=qa-tutorial-close-button>×</span>
      <h2 id=qa-tutorial-title>title</h2>
      <p id=qa-tutorial-content>content</p>
      <a id=qa-tutorial-oeis></a>
      <p id=qa-tutorial-cite></p>
      <a id=qa-tutorial-wikipedia></a>
    </div>
  </div>
  
  
  
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery-query-object@2.2.3/jquery.query-object.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/Sortable/1.15.6/Sortable.min.js"></script>
  
<script type=text/js-worker>class AlgorithmError extends Error {
  constructor(t, r, e) {
    super(t), this.algorithm = r, this.input = e, this.name = "AlgorithmError"
  }
}

function count_sigma(t) {
  return t ? new Set(t).size : 0
}

function count_period(t) {
  if (!t || 0 === t.length) return 0;
  const r = t[t.length - 1];
  return t.length - r
}

function count_exponent(t) {
  if (!t || 0 === t.length) return 0;
  const r = count_period(t);
  return t.length / r
}

function count_regularity(t) {
  if (!t || 0 === t.length) return "empty";
  const r = t.length,
    e = t[r - 1],
    a = count_period(t),
    n = count_exponent(t);
  return n > 1 && r % a == 0 ? 2 == n ? "square" : "non-primitive" : 0 == e ? "unbordered" : "primitive"
}

function construct_suffix_array(t) {
  if (!t) return [];
  const r = t.length,
    e = [...Array(r).keys()].map(r => [r, t.substring(r)]);
  return e.sort((t, r) => t[1].localeCompare(r[1])), e.map(t => t[0])
}

function construct_border_array(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r);
  e[0] = 0;
  for (let a = 1; a < r; a++) {
    let r = e[a - 1];
    for (; r > 0 && t[a] !== t[r];) r = e[r - 1];
    t[a] === t[r] && r++, e[a] = r
  }
  return e
}

function construct_bw_transform(t, r) {
  if (!t) return "";
  if (t.length !== r.length) throw new AlgorithmError("Invalid input: text must be a string and rotation_array must be an array", "BWT", {
    text: t,
    rotation_array: r
  });
  const e = t.length;
  let a = "";
  for (let n = 0; n < e; n++) a += t[(r[n] + e - 1) % e];
  return a
}

function construct_first_array(t) {
  return t ? [...t].sort().join("") : ""
}

function construct_index_array(t) {
  return !t || t <= 0 ? [] : Array.from(Array(t).keys())
}

function construct_rotation_array(t) {
  if (!t) return [];
  const r = t.length,
    e = [...Array(r).keys()].map(r => [r, conjugate_string(t, r)]);
  return e.sort((t, r) => {
    const e = t[1].localeCompare(r[1]);
    return 0 !== e ? e : t[0] - r[0]
  }), e.map(t => t[0])
}

function construct_inverse_suffix_array(t) {
  if (!t) return [];
  const r = new Array(t.length);
  for (let e = 0; e < t.length; e++) r[t[e]] = e;
  return r
}

function construct_phi_array(t, r) {
  const e = t.length,
    a = new Array(e);
  for (let n = 0; n < e; n++) 0 !== r[n] ? a[n] = t[r[n] - 1] : a[n] = e;
  return a
}

function construct_inverse_phi_array(t, r) {
  if (!t || !r) return [];
  const e = t.length,
    a = new Array(e);
  for (let n = 0; n < e; ++n) r[n] + 1 !== e ? a[n] = t[r[n] + 1] : a[n] = e;
  return a
}

function lcp_query(t, r, e) {
  if (!t || r < 0 || e < 0 || r >= t.length || e >= t.length) return 0;
  let a = 0;
  const n = Math.min(t.length - r, t.length - e);
  for (let i = 0; i < n && t[r + i] === t[e + i]; ++i) a++;
  return a
}

function construct_lcp_array(t, r) {
  if (!t || !r) return [];
  const e = [0];
  for (let a = 1; a < r.length; a++) e.push(lcp_query(t, r[a], r[a - 1]));
  return e
}

function count_lcp_array(t) {
  return t ? t.reduce((t, r) => t + r, 0) : 0
}

function construct_plcp_array(t, r) {
  if (!t || !r) return [];
  if (t.length !== r.length) throw new AlgorithmError("Inverse suffix array and LCP array must have the same length.", "PLCP", {
    inverse_suffix_array: t,
    lcp_array: r
  });
  const e = t.length;
  return [...new Array(e).keys()].map(e => r[t[e]])
}

function construct_psi_array(t, r) {
  if (!t || !r) return [];
  const e = t.length;
  return [...new Array(e).keys()].map(a => t[a] + 1 < e ? r[t[a] + 1] : e)
}

function construct_lyndon_factorization(t, r) {
  if (!t || !r) return [];
  const e = t.length;
  if (0 === e) return [];
  const a = new Array(e).fill(!1);
  if (r.length < e) throw new AlgorithmError(`Inverse suffix array (inverse_suffix_array) must have a length of at least text.length (${e}), but got ${r.length}.`, "LynF", {
    text: t,
    inverse_suffix_array: r
  });
  let n = r[0];
  for (let t = 0; t + 1 < e; ++t) n > r[t + 1] && (a[t] = !0, n = r[t + 1]);
  return a[e - 1] = !0, a
}

function delta(t) {
  if (0 === t.length) throw new AlgorithmError("Input array 'substring_complexity' cannot be empty.", "delta", {
    substring_complexity: t
  });
  let r = 1,
    e = t[0];
  for (let a = 1; a < t.length; ++a) {
    const n = t[a] / (a + 1);
    n > e && (r = a + 1, e = n)
  }
  return [r, e]
}

function count_delta(t) {
  return t ? delta(t)[1] : 0
}

function count_delta_argmax(t) {
  return t ? delta(t)[0] : 0
}

function construct_substring_complexity(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r),
    a = new Map;
  t.forEach(t => {
    a.set(t, (a.get(t) || 0) + 1)
  });
  let n = 0;
  for (let t = r; t >= 1; --t) n += 1, a.has(t) && (n -= a.get(t)), e[t - 1] = n;
  return e
}

function conjugate_string(t, r) {
  if (!t) return "";
  if (r < 0 || r > t.length) throw new AlgorithmError("Shift value must be between 0 and the length of the string.", "conjugate_string", {
    text: t,
    shift: r
  });
  return 0 === t.length || 0 === r ? t : t.substring(r) + t.substring(0, r)
}

function select_query(t, r, e) {
  if (!t) return -1;
  if (e <= 0) throw new AlgorithmError("The 'nth' parameter must be a positive integer for 1-based indexing.", "select_query", {
    text: t,
    pattern: r,
    nth: e
  });
  let a = -1;
  for (let n = 0; n < e; ++n)
    if (a = t.indexOf(r, a + 1), -1 === a) return -1;
  return a
}

function rank_query(t, r, e) {
  if (!t) return 0;
  return [...t.slice(0, e)].filter(t => t === r).length
}

function construct_lf_array(t, r) {
  if (!t || !r) return [];
  if (t.length !== r.length) throw new AlgorithmError("First array and BWT must have the same length.", "LF", {
    first_array: t,
    bw_transform: r
  });
  const e = t.length,
    a = new Array(e);
  for (let n = 0; n < e; ++n) {
    const e = r[n],
      i = rank_query(r, e, n + 1);
    a[n] = select_query(t, e, i)
  }
  return a
}

function construct_sl_string(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r);
  let a = "S";
  e[r - 1] = a;
  for (let n = r - 2; n >= 0; --n) t[n + 1] > t[n] ? a = "S" : t[n + 1] < t[n] && (a = "L", "S" == e[n + 1] && (e[n + 1] = "S*")), e[n] = a;
  return "S" == e[0] && (e[0] = "S*"), e
}

function construct_lpf_array(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r);
  e[0] = 0;
  for (let a = 1; a < r; a++) {
    let n = 0;
    for (let e = 0; e < a; e++) {
      let i = 0;
      for (; a + i < r && e + i < r && t[a + i] === t[e + i];) i++;
      n = Math.max(n, i)
    }
    e[a] = n
  }
  return e
}

function construct_lpnf_array(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r);
  e[0] = 0;
  for (let a = 1; a < r; a++) {
    let n = 0;
    for (let e = 0; e < a; e++) {
      let i = 0;
      for (; a + i < r && e + i < a && t[a + i] === t[e + i];) i++;
      n = Math.max(n, i)
    }
    e[a] = n
  }
  return e
}

function construct_lnf_array(t) {
  if (!t) return [];
  const r = construct_lpf_array(t.split("").reverse().join("")),
    e = r.length;
  return [...new Array(e).keys()].map(t => r[e - 1 - t])
}

function greedy_factorize(t) {
  if (!t) return [];
  const r = t.length;
  if (0 === r) return [];
  const e = new Array(r).fill(!1);
  for (let a = 0; a < r;) {
    const r = t[a];
    let n = 0 === r ? 1 : r;
    e[a + n - 1] = !0, a += n
  }
  return e
}

function construct_lzss_factorization(t) {
  return greedy_factorize(t)
}

function construct_lzssno_factorization(t) {
  return greedy_factorize(t)
}

function greedy_factorize_with_new_letter(t) {
  if (!t) return [];
  const r = t.length;
  if (0 === r) return [];
  const e = new Array(r).fill(!1);
  for (let a = 0; a < r;) {
    const n = t[a];
    let i = 0 === n ? 1 : Math.min(n + 1, r - a);
    e[a + i - 1] = !0, a += i
  }
  return e
}

function construct_lz77_factorization(t) {
  return greedy_factorize_with_new_letter(t)
}

function construct_reverse_lzss_factorization(t) {
  if (!t) return [];
  return greedy_factorize(t.slice().reverse())
}

function construct_lexparse_factorization(t) {
  return greedy_factorize(t)
}

function construct_nss_array(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r);
  for (let a = 0; a < r; ++a) {
    let n = a + 1;
    for (; n < r && t[n] > t[a];) ++n;
    e[a] = n >= r ? r : n
  }
  return e
}

function construct_pss_array(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r);
  for (let a = 0; a < r; ++a) {
    let n = a - 1;
    for (; n >= 0 && t[n] > t[a];) --n;
    e[a] = n < 0 ? r : n
  }
  return e
}

function construct_lyndon_array(t) {
  if (!t) return [];
  const r = t.length;
  let e = new Array(r);
  for (let a = 0; a < r; ++a) e[a] = t[a] === r ? r - a : t[a] - a;
  return e
}

function construct_necklace_conjugate_transform(t) {
  if (!t) return "";
  const r = t.length;
  let e = t;
  for (let a = 0; a < r; ++a) {
    const r = conjugate_string(t, a);
    r < e && (e = r)
  }
  return e
}

function construct_invert_transform(t) {
  if (!t) return "";
  const r = [...t].sort(),
    e = r[0],
    a = r.reverse()[0];
  return [...t].map(function(t) {
    return String.fromCharCode(a.charCodeAt(0) - (t.charCodeAt(0) - e.charCodeAt(0)))
  }).join("")
}

function construct_revert_transform(t) {
  return t ? t.split("").reverse().join("") : ""
}

function phrases_from_factorizations(t, r) {
  if (!t || !r) return [];
  const e = t.length,
    a = [];
  let n = 0;
  for (let i = 0; i < e; ++i)
    if (!0 === r[i]) {
      let r = t.slice(n, i + 1);
      n = i + 1, a.push(r)
    } return a
}

function omega_order(t, r) {
  if (void 0 === t || void 0 === r) throw new AlgorithmError("Undefined string input(s) for omega order comparison.", "OmegaOrder", {
    strA: t,
    strB: r
  });
  if (t === r) return 0;
  const e = 3 * Math.max(t.length, r.length);
  for (let a = 0; a < e; ++a) {
    if (t[a % t.length] < r[a % r.length]) return -1;
    if (t[a % t.length] > r[a % r.length]) return 1
  }
  return t.length < r.length ? -1 : 1
}

function construct_circular_suffix_array(t, r) {
  if (!t || !r) return [];
  const e = phrases_from_factorizations(t, r),
    a = [];
  let n = 0;
  for (const t of e) {
    const r = t.length;
    for (let e = 0; e < r; ++e) a.push({
      pos: n + e,
      str: conjugate_string(t, e)
    });
    n += r
  }
  return a.sort((t, r) => omega_order(t.str, r.str)), [...a].map(t => t.pos)
}

function construct_inverse_circular_suffix_array(t) {
  return t ? construct_inverse_suffix_array(t) : []
}

function construct_bbw_indices(t, r) {
  if (!t || !r) return [];
  const e = r.length;
  return [...r].map(r => {
    var a;
    if (0 == r || 1 == t[r - 1]) {
      const n = rank_query(t, !0, r),
        i = select_query(t, !0, 1 + n);
      a = -1 == i ? e - 1 : i
    } else a = r - 1;
    return a
  })
}

function construct_bbw_transform(t, r) {
  return t && r ? [...r].map(r => t[r]).join("") : ""
}

function construct_inverse_bbw_transform(t) {
  if (!t) return "";
  let r = t.length;
  var e = construct_first_array(t),
    a = new Array(r).fill(0),
    n = [];
  for (let o = 0; o < r; ++o) {
    let r = [];
    if (1 == a[o]) continue;
    for (var i = o; 0 == a[i];) {
      a[i] = !0, r.push(t[i]);
      let n = e[i],
        o = rank_query(e, n, i + 1);
      if (0 == o) throw new AlgorithmError("character_number is zero in inverse BBWT", "construct_inverse_bbw_transform", t);
      if (t.split(n).length + 1 <= o) throw new AlgorithmError("character_number exceeds occurrences in inverse BBWT", "construct_inverse_bbw_transform", t);
      i = select_query(t, n, o)
    }
    const s = construct_necklace_conjugate_transform(r.join(""));
    n.push(s)
  }
  return n.sort(), n.reverse(), n.join("")
}

function random_ternary_string(t) {
  let r = "";
  for (let e = 0; e < t; e++) {
    const t = Math.floor(3 * Math.random());
    r += "abc".charAt(t)
  }
  return r
}

function construct_lz78_factorization(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r).fill(!1),
    a = new Map;
  let n = 0;
  for (; n < r;) {
    let i = "";
    for (let e = n; e < r && (i += t[e], a.has(i)); e++);
    const o = i;
    a.set(o, n), e[n + o.length - 1] = !0, n += o.length
  }
  return e
}

function construct_lzw_factorization(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r).fill(!1),
    a = new Map;
  for (let e = 0; e < r; e++) {
    const r = t[e];
    a.has(r) || a.set(r, a.size)
  }
  for (let n = 0; n < r;) {
    let i = "";
    for (let e = n; e < r; e++)
      if (i += t[e], !a.has(i)) {
        i = i.slice(0, -1);
        break
      } let o = n + i.length - 1;
    if (o >= r) {
      e[r - 1] = !0;
      break
    }
    if (0 == i.length) throw new AlgorithmError("LZW factorization failed to find a valid substring.", "construct_lzw_factorization", {
      text: t
    });
    e[o] = !0, n + i.length < r && (i += t[n + i.length]), a.has(i) || a.set(i, a.size), n = o + 1
  }
  return e
}

function construct_necklace_factorization(t, r) {
  if (!t || !r) return [];
  const e = t.length,
    a = new Array(e).fill(!1);
  let n = 0,
    i = "";
  for (; n < e;) {
    let o = n;
    for (; o < e && 0 == r[o];) o++;
    const s = t.slice(n, o + 1);
    s !== i ? (i = s, a[o] = !0, n = o + 1) : (a[n - 1] = !1, a[o] = !0, n = o + 1)
  }
  return a
}

function construct_odd_maximal_palindromic_length_array(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r).fill(0);
  let a = 0,
    n = 0;
  for (let i = 0; i < r; i++) {
    let o = 2 * a - i;
    for (i < n && (e[i] = Math.min(n - i, e[o])); i - e[i] - 1 >= 0 && i + e[i] + 1 < r && t[i - e[i] - 1] === t[i + e[i] + 1];) e[i]++;
    i + e[i] > n && (a = i, n = i + e[i])
  }
  return e
}

function construct_even_maximal_palindromic_length_array(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r).fill(0);
  let a = 0,
    n = 0;
  for (let i = 0; i < r; i++) {
    let o = 2 * a - i + 1;
    for (i < n && (e[i] = Math.min(n - i, e[o])); i - e[i] - 1 >= 0 && i + e[i] < r && t[i - e[i] - 1] === t[i + e[i]];) e[i]++;
    i + e[i] > n && (a = i - 1, n = i + e[i])
  }
  return e
}

function get_lzend_reference(t, r, e) {
  let a = 0;
  for (; - 1 !== (a = t.indexOf(r, a));) {
    if (e[a + r.length - 1]) return a;
    a += r.length
  }
  return -1
}

function construct_lzend_factorization(t) {
  if (!t) return [];
  const r = t.length,
    e = new Array(r).fill(!1);
  for (let a = 0; a < r;) {
    let n = "",
      i = "";
    const o = t.slice(0, a);
    for (let s = a; s < r && (i += t[s], -1 !== o.indexOf(i)); s++) - 1 !== get_lzend_reference(o, i, e) && (n = i);
    n ? n += t[a + n.length - 1] : n = t[a];
    let s = a + n.length - 1;
    if (s >= r) {
      e[r - 1] = !0;
      break
    }
    e[s] = !0, a = s + 1
  }
  return e
}

function is_stringattractor(t, r) {
  const e = t.length,
    a = new Set(r);
  for (let r = 0; r < e; r++) {
    let n = "";
    for (let i = r; i < e; i++) {
      n += t[i];
      let r = !1;
      for (let i = 0; i + n.length <= e; i++) {
        if (t.slice(i, i + n.length) === n)
          for (let t = i; t < i + n.length; t++)
            if (a.has(t)) {
              r = !0;
              break
            } if (r) break
      }
      if (!r) return !1
    }
  }
  return !0
}

function construct_gamma_factorization(t) {
  if (!t) return [];
  const r = t.length,
    e = new Map;
  for (let a = 0; a < r; a++) {
    let n = "";
    for (let i = a; i < r; i++) n += t[i], e.set(n, (e.get(n) || 0) + 1)
  }
  const a = [];
  for (const [t, r] of e.entries()) {
    let n = !0;
    for (let a = 0; a < t.length && n; a++) {
      const i = t.slice(0, a) + t.slice(a + 1);
      i.length > 0 && e.get(i) <= r && (n = !1)
    }
    n && a.push(t)
  }
  const n = a.map(e => {
      const a = new Set;
      for (let n = 0; n + e.length <= r; n++)
        if (t.slice(n, n + e.length) === e)
          for (let t = n; t < n + e.length; t++) a.add(t);
      return a
    }),
    i = [...Array(r).keys()];
  const o = function t(r, e, a) {
      if (a.size > 0 && e.size >= a.size) return new Set;
      let o = !0;
      for (const t of n) {
        let r = !1;
        for (const a of e)
          if (t.has(a)) {
            r = !0;
            break
          } if (!r) {
          o = !1;
          break
        }
      }
      return o ? new Set(e) : r === i.length ? new Set : (e.add(i[r]), a = (s = t(r + 1, e, a)).size > 0 ? s : a, e.delete(i[r]), a = (s = t(r + 1, e, a)).size > 0 ? s : a);
      var s
    }(0, new Set, new Set),
    s = new Array(r).fill(!1);
  return o.forEach(t => s[t] = !0), s
}

function factorization_to_positions(t) {
  const r = [];
  for (let e = 0; e < t.length; e++) t[e] && r.push(e);
  return r
}
var structure_flags = {
  counter_sigma: 1,
  suffix_array: 2,
  border_array: 4,
  first_array: 8,
  index_array: 16,
  rotation_array: 32,
  sl_string: 64,
  lpf_array: 128,
  lpnf_array: 256,
  lnf_array: 512,
  necklace_conjugate_transform: 1024,
  invert_transform: 2048,
  revert_transform: 4096,
  lz78_factorization: 8192,
  lzw_factorization: 16384,
  odd_maximal_palindromic_length_array: 32768,
  even_maximal_palindromic_length_array: 65536,
  lzend_factorization: 131072,
  gamma_factorization: 262144,
  inverse_suffix_array: 524288,
  lcp_array: 1048576,
  counter_period: 2097152,
  counter_exponent: 4194304,
  counter_regularity: 8388608,
  bw_transform: 16777216,
  lzss_factorization: 33554432,
  lz77_factorization: 67108864,
  lzssno_factorization: 134217728,
  reverse_lzss_factorization: 268435456,
  phi_array: 536870912,
  inverse_phi_array: 1073741824,
  psi_array: -2147483648,
  lyndon_factorization: 1,
  nss_array: 2,
  pss_array: 4,
  counter_lcp_array: 8,
  plcp_array: 16,
  substring_complexity: 32,
  lf_array: 64,
  circular_suffix_array: 128,
  necklace_factorization: 256,
  lyndon_array: 512,
  lexparse_factorization: 1024,
  counter_delta: 2048,
  counter_delta_argmax: 4096,
  inverse_circular_suffix_array: 8192,
  bbw_indices: 16384,
  bbw_transform: 32768,
  inverse_bbw_transform: 65536
};

function build_ds(t, r = -1) {
  t.length;
  var e = {};
  r & structure_flags.counter_sigma && (e.counter_sigma = !0), r & structure_flags.suffix_array && (e.suffix_array = !0), r & structure_flags.border_array && (e.border_array = !0), r & structure_flags.first_array && (e.first_array = !0), r & structure_flags.index_array && (e.index_array = !0), r & structure_flags.rotation_array && (e.rotation_array = !0), r & structure_flags.sl_string && (e.sl_string = !0), r & structure_flags.lpf_array && (e.lpf_array = !0), r & structure_flags.lpnf_array && (e.lpnf_array = !0), r & structure_flags.lnf_array && (e.lnf_array = !0), r & structure_flags.necklace_conjugate_transform && (e.necklace_conjugate_transform = !0), r & structure_flags.invert_transform && (e.invert_transform = !0), r & structure_flags.revert_transform && (e.revert_transform = !0), r & structure_flags.lz78_factorization && (e.lz78_factorization = !0), r & structure_flags.lzw_factorization && (e.lzw_factorization = !0), r & structure_flags.odd_maximal_palindromic_length_array && (e.odd_maximal_palindromic_length_array = !0), r & structure_flags.even_maximal_palindromic_length_array && (e.even_maximal_palindromic_length_array = !0), r & structure_flags.lzend_factorization && (e.lzend_factorization = !0), r & structure_flags.gamma_factorization && (e.gamma_factorization = !0), r & structure_flags.inverse_suffix_array && (e.inverse_suffix_array = !0), r & structure_flags.lcp_array && (e.lcp_array = !0), r & structure_flags.counter_period && (e.counter_period = !0), r & structure_flags.counter_exponent && (e.counter_exponent = !0), r & structure_flags.counter_regularity && (e.counter_regularity = !0), r & structure_flags.bw_transform && (e.bw_transform = !0), r & structure_flags.lzss_factorization && (e.lzss_factorization = !0), r & structure_flags.lz77_factorization && (e.lz77_factorization = !0), r & structure_flags.lzssno_factorization && (e.lzssno_factorization = !0), r & structure_flags.reverse_lzss_factorization && (e.reverse_lzss_factorization = !0), r & structure_flags.phi_array && (e.phi_array = !0), r & structure_flags.inverse_phi_array && (e.inverse_phi_array = !0), r & structure_flags.psi_array && (e.psi_array = !0), r & structure_flags.lyndon_factorization && (e.lyndon_factorization = !0), r & structure_flags.nss_array && (e.nss_array = !0), r & structure_flags.pss_array && (e.pss_array = !0), r & structure_flags.counter_lcp_array && (e.counter_lcp_array = !0), r & structure_flags.plcp_array && (e.plcp_array = !0), r & structure_flags.substring_complexity && (e.substring_complexity = !0), r & structure_flags.lf_array && (e.lf_array = !0), r & structure_flags.circular_suffix_array && (e.circular_suffix_array = !0), r & structure_flags.necklace_factorization && (e.necklace_factorization = !0), r & structure_flags.lyndon_array && (e.lyndon_array = !0), r & structure_flags.lexparse_factorization && (e.lexparse_factorization = !0), r & structure_flags.counter_delta && (e.counter_delta = !0), r & structure_flags.counter_delta_argmax && (e.counter_delta_argmax = !0), r & structure_flags.inverse_circular_suffix_array && (e.inverse_circular_suffix_array = !0), r & structure_flags.bbw_indices && (e.bbw_indices = !0), r & structure_flags.bbw_transform && (e.bbw_transform = !0), r & structure_flags.inverse_bbw_transform && (e.inverse_bbw_transform = !0);
  for (var a = !0; a;) a = !1, e.inverse_suffix_array && !e.suffix_array && (e.suffix_array = !0, a = !0), e.lcp_array && !e.suffix_array && (e.suffix_array = !0, a = !0), e.counter_period && !e.border_array && (e.border_array = !0, a = !0), e.counter_exponent && !e.border_array && (e.border_array = !0, a = !0), e.counter_regularity && !e.border_array && (e.border_array = !0, a = !0), e.bw_transform && !e.rotation_array && (e.rotation_array = !0, a = !0), e.lzss_factorization && !e.lpf_array && (e.lpf_array = !0, a = !0), e.lz77_factorization && !e.lpf_array && (e.lpf_array = !0, a = !0), e.lzssno_factorization && !e.lpnf_array && (e.lpnf_array = !0, a = !0), e.reverse_lzss_factorization && !e.lnf_array && (e.lnf_array = !0, a = !0), e.phi_array && !e.suffix_array && (e.suffix_array = !0, a = !0), e.phi_array && !e.inverse_suffix_array && (e.inverse_suffix_array = !0, a = !0), e.inverse_phi_array && !e.suffix_array && (e.suffix_array = !0, a = !0), e.inverse_phi_array && !e.inverse_suffix_array && (e.inverse_suffix_array = !0, a = !0), e.psi_array && !e.suffix_array && (e.suffix_array = !0, a = !0), e.psi_array && !e.inverse_suffix_array && (e.inverse_suffix_array = !0, a = !0), e.lyndon_factorization && !e.inverse_suffix_array && (e.inverse_suffix_array = !0, a = !0), e.nss_array && !e.inverse_suffix_array && (e.inverse_suffix_array = !0, a = !0), e.pss_array && !e.inverse_suffix_array && (e.inverse_suffix_array = !0, a = !0), e.counter_lcp_array && !e.lcp_array && (e.lcp_array = !0, a = !0), e.plcp_array && !e.inverse_suffix_array && (e.inverse_suffix_array = !0, a = !0), e.plcp_array && !e.lcp_array && (e.lcp_array = !0, a = !0), e.substring_complexity && !e.lcp_array && (e.lcp_array = !0, a = !0), e.lf_array && !e.first_array && (e.first_array = !0, a = !0), e.lf_array && !e.bw_transform && (e.bw_transform = !0, a = !0), e.circular_suffix_array && !e.lyndon_factorization && (e.lyndon_factorization = !0, a = !0), e.necklace_factorization && !e.lyndon_factorization && (e.lyndon_factorization = !0, a = !0), e.lyndon_array && !e.nss_array && (e.nss_array = !0, a = !0), e.lexparse_factorization && !e.plcp_array && (e.plcp_array = !0, a = !0), e.counter_delta && !e.substring_complexity && (e.substring_complexity = !0, a = !0), e.counter_delta_argmax && !e.substring_complexity && (e.substring_complexity = !0, a = !0), e.inverse_circular_suffix_array && !e.circular_suffix_array && (e.circular_suffix_array = !0, a = !0), e.bbw_indices && !e.lyndon_factorization && (e.lyndon_factorization = !0, a = !0), e.bbw_indices && !e.circular_suffix_array && (e.circular_suffix_array = !0, a = !0), e.bbw_transform && !e.bbw_indices && (e.bbw_indices = !0, a = !0), e.inverse_bbw_transform && !e.bbw_transform && (e.bbw_transform = !0, a = !0);
  const n = t,
    i = t.length;
  var o, s, c, f, l, h, u, _, m, p, g, d, y, b, x, w, v, z, S, T, k, A, L, P, C, j, B, F, I, W, M, q, E, R, Z, G, N, J, D, K, O, $, H, V, U, Q, X, Y, tt;
  return e.counter_sigma && (o = count_sigma(n)), e.suffix_array && (s = construct_suffix_array(n)), e.border_array && (c = construct_border_array(n)), e.first_array && (f = construct_first_array(n)), e.index_array && (l = construct_index_array(i)), e.rotation_array && (h = construct_rotation_array(n)), e.sl_string && (u = construct_sl_string(n)), e.lpf_array && (_ = construct_lpf_array(n)), e.lpnf_array && (m = construct_lpnf_array(n)), e.lnf_array && (p = construct_lnf_array(n)), e.necklace_conjugate_transform && (g = construct_necklace_conjugate_transform(n)), e.invert_transform && (d = construct_invert_transform(n)), e.revert_transform && (y = construct_revert_transform(n)), e.lz78_factorization && (b = construct_lz78_factorization(n)), e.lzw_factorization && (x = construct_lzw_factorization(n)), e.odd_maximal_palindromic_length_array && (w = construct_odd_maximal_palindromic_length_array(n)), e.even_maximal_palindromic_length_array && (v = construct_even_maximal_palindromic_length_array(n)), e.lzend_factorization && (z = construct_lzend_factorization(n)), e.gamma_factorization && (S = construct_gamma_factorization(n)), e.inverse_suffix_array && (T = construct_inverse_suffix_array(s)), e.lcp_array && (k = construct_lcp_array(n, s)), e.counter_period && (A = count_period(c)), e.counter_exponent && (L = count_exponent(c)), e.counter_regularity && (P = count_regularity(c)), e.bw_transform && (C = construct_bw_transform(n, h)), e.lzss_factorization && (j = construct_lzss_factorization(_)), e.lz77_factorization && (B = construct_lz77_factorization(_)), e.lzssno_factorization && (F = construct_lzssno_factorization(m)), e.reverse_lzss_factorization && (I = construct_reverse_lzss_factorization(p)), e.phi_array && (W = construct_phi_array(s, T)), e.inverse_phi_array && (M = construct_inverse_phi_array(s, T)), e.psi_array && (q = construct_psi_array(s, T)), e.lyndon_factorization && (E = construct_lyndon_factorization(n, T)), e.nss_array && (R = construct_nss_array(T)), e.pss_array && (Z = construct_pss_array(T)), e.counter_lcp_array && (G = count_lcp_array(k)), e.plcp_array && (N = construct_plcp_array(T, k)), e.substring_complexity && (J = construct_substring_complexity(k)), e.lf_array && (D = construct_lf_array(f, C)), e.circular_suffix_array && (K = construct_circular_suffix_array(n, E)), e.necklace_factorization && (O = construct_necklace_factorization(n, E)), e.lyndon_array && ($ = construct_lyndon_array(R)), e.lexparse_factorization && (H = construct_lexparse_factorization(N)), e.counter_delta && (V = count_delta(J)), e.counter_delta_argmax && (U = count_delta_argmax(J)), e.inverse_circular_suffix_array && (Q = construct_inverse_circular_suffix_array(K)), e.bbw_indices && (X = construct_bbw_indices(E, K)), e.bbw_transform && (Y = construct_bbw_transform(n, X)), e.inverse_bbw_transform && (tt = construct_inverse_bbw_transform(Y)), {
    counter_sigma: o,
    suffix_array: s,
    border_array: c,
    first_array: f,
    index_array: l,
    rotation_array: h,
    sl_string: u,
    lpf_array: _,
    lpnf_array: m,
    lnf_array: p,
    necklace_conjugate_transform: g,
    invert_transform: d,
    revert_transform: y,
    lz78_factorization: b,
    lzw_factorization: x,
    odd_maximal_palindromic_length_array: w,
    even_maximal_palindromic_length_array: v,
    lzend_factorization: z,
    gamma_factorization: S,
    inverse_suffix_array: T,
    lcp_array: k,
    counter_period: A,
    counter_exponent: L,
    counter_regularity: P,
    bw_transform: C,
    lzss_factorization: j,
    lz77_factorization: B,
    lzssno_factorization: F,
    reverse_lzss_factorization: I,
    phi_array: W,
    inverse_phi_array: M,
    psi_array: q,
    lyndon_factorization: E,
    nss_array: R,
    pss_array: Z,
    counter_lcp_array: G,
    plcp_array: N,
    substring_complexity: J,
    lf_array: D,
    circular_suffix_array: K,
    necklace_factorization: O,
    lyndon_array: $,
    lexparse_factorization: H,
    counter_delta: V,
    counter_delta_argmax: U,
    inverse_circular_suffix_array: Q,
    bbw_indices: X,
    bbw_transform: Y,
    inverse_bbw_transform: tt,
    counter_text: number_of_runs(n),
    counter_lyndon_factorization: number_of_factors(E),
    counter_lzss_factorization: number_of_factors(j),
    counter_lzssno_factorization: number_of_factors(F),
    counter_lz77_factorization: number_of_factors(B),
    counter_reverse_lzss_factorization: number_of_factors(I),
    counter_lexparse_factorization: number_of_factors(H),
    counter_lz78_factorization: number_of_factors(b),
    counter_lzw_factorization: number_of_factors(x),
    counter_necklace_factorization: number_of_factors(O),
    counter_lzend_factorization: number_of_factors(z),
    counter_gamma_factorization: number_of_factors(S),
    counter_bw_transform: number_of_runs(C),
    counter_necklace_conjugate_transform: number_of_runs(g),
    counter_invert_transform: number_of_runs(d),
    counter_revert_transform: number_of_runs(y),
    counter_bbw_transform: number_of_runs(Y),
    counter_inverse_bbw_transform: number_of_runs(tt)
  }
}
const citations = {};

function generate_fibonacci_word(t) {
  if (t <= 0) return "b";
  return [...generate_fibonacci_word(t - 1)].map(t => "a" == t ? "ab" : "a").join("")
}

function generate_tribonacci_word(t) {
  if (t <= 0) return "a";
  return [...generate_tribonacci_word(t - 1)].map(t => "a" == t ? "ab" : "b" == t ? "ac" : "a").join("")
}

function generate_thue_morse_word(t) {
  if (t <= 0) return "a";
  const r = generate_thue_morse_word(t - 1);
  return r + [...r].map(t => "a" == t ? "b" : "a").join("")
}

function generate_mephisto_waltz_word(t) {
  if (t <= 0) return "a";
  return [...generate_mephisto_waltz_word(t - 1)].map(t => "a" == t ? "aab" : "bba").join("")
}

function generate_vtm_word(t) {
  if (t <= 0) return "a";
  return [...generate_vtm_word(t - 1)].map(t => "a" == t ? "abc" : "b" == t ? "ac" : "b").join("")
}

function generate_sierpinski_word(t) {
  if (t <= 0) return "a";
  return [...generate_sierpinski_word(t - 1)].map(t => "a" == t ? "aba" : "bbb").join("")
}

function generate_pell_word(t) {
  if (t <= 0) return "a";
  return [...generate_pell_word(t - 1)].map(t => "a" == t ? "aab" : "a").join("")
}

function generate_chacon_word(t) {
  if (t <= 0) return "a";
  return [...generate_chacon_word(t - 1)].map(t => "a" == t ? "aaba" : "b").join("")
}

function generate_von_neumann_word(t) {
  if (t <= 0) return "a";
  return [...generate_von_neumann_word(t - 1)].map(t => "a" == t ? "aab" : "b").join("")
}

function rudin_shapiro_preword(t) {
  if (t <= 0) return "a";
  return [...rudin_shapiro_preword(t - 1)].map(t => "a" == t ? "ab" : "b" == t ? "ac" : "c" == t ? "db" : "dc").join("")
}

function generate_rudin_shapiro_word(t) {
  if (t <= 0) return "a";
  return [...rudin_shapiro_preword(t)].map(t => "a" == t || "b" == t ? "a" : "b").join("")
}

function baum_sweet_preword(t) {
  if (t <= 0) return "a";
  return [...baum_sweet_preword(t - 1)].map(t => "a" == t ? "ab" : "b" == t ? "cb" : "c" == t ? "bd" : "dd").join("")
}

function generate_baum_sweet_word(t) {
  if (t <= 0) return "a";
  return [...baum_sweet_preword(t)].map(t => "c" == t || "d" == t ? "a" : t).join("")
}

function generate_kolakoski_word(t) {
  if (t <= 0) return "ab";
  const r = generate_kolakoski_word(t - 1);
  let e = "";
  for (let t = 0; t < r.length; ++t) e += t % 2 == 0 ? "a" == r[t] ? "a" : "aa" : "a" == r[t] ? "b" : "bb";
  return e
}
citations.allouche03automatic = 'Jean-Paul Allouche and Jeffrey Shallit. <em><a href="https://doi.org/10.1017/CBO9780511546563">Automatic sequences: Theory, applications, generalizations</a></em>. Cambridge University Press, 2003.', citations.manber93sa = 'Udi Manber and Eugene W. Myers. <a href="https://doi.org/10.1137/0222058">Suffix arrays: <span>A</span> new method for on-line string searches</a>. <em><span>SIAM</span> J. Comput.</em>, 22(5):935–948, 1993.', citations.burrows94bwt = "Michael Burrows and David J. Wheeler. A block sorting lossless data compression algorithm. Technical report, 124, Digital Equipment Corporation, Palo Alto, California, 1994.", citations.burrows94bwt = "Michael Burrows and David J. Wheeler. A block sorting lossless data compression algorithm. Technical report, 124, Digital Equipment Corporation, Palo Alto, California, 1994.", citations.manber93sa = 'Udi Manber and Eugene W. Myers. <a href="https://doi.org/10.1137/0222058">Suffix arrays: <span>A</span> new method for on-line string searches</a>. <em><span>SIAM</span> J. Comput.</em>, 22(5):935–948, 1993.', citations.karkkainen09plcp = 'Juha Kärkkäinen, Giovanni Manzini, and Simon J. Puglisi. <a href="https://doi.org/10.1007/978-3-642-02441-2_17">Permuted longest-common-prefix array</a>. In <em>Proc. CPM</em>, volume 5577, pages 181–192. 2009.', citations.karkkainen09plcp = 'Juha Kärkkäinen, Giovanni Manzini, and Simon J. Puglisi. <a href="https://doi.org/10.1007/978-3-642-02441-2_17">Permuted longest-common-prefix array</a>. In <em>Proc. CPM</em>, volume 5577, pages 181–192. 2009.', citations.grossi05csa = 'Roberto Grossi and Jeffrey Scott Vitter. <a href="https://doi.org/10.1137/S0097539702402354">Compressed suffix arrays and suffix trees with applications to text indexing and string matching</a>. <em><span>SIAM</span> J. Comput.</em>, 35(2):378–407, 2005.', citations.chen58lyndon = "Kuo Tsai Chen, Ralph H. Fox, and Roger C. Lyndon. Free differential calculus, <span>IV</span>. <span>T</span>he quotient groups of the lower central series. <em>Annals of Mathematics</em>, 68(1):81–95, 1958.", citations.raskhodnikova13sublinear = 'Sofya Raskhodnikova, Dana Ron, Ronitt Rubinfeld, and Adam D. Smith. <a href="https://doi.org/10.1007/s00453-012-9618-6">Sublinear algorithms for approximating string compressibility</a>. <em>Algorithmica</em>, 65(3):685–709, 2013.', citations.raskhodnikova13sublinear = 'Sofya Raskhodnikova, Dana Ron, Ronitt Rubinfeld, and Adam D. Smith. <a href="https://doi.org/10.1007/s00453-012-9618-6">Sublinear algorithms for approximating string compressibility</a>. <em>Algorithmica</em>, 65(3):685–709, 2013.', citations.raskhodnikova13sublinear = 'Sofya Raskhodnikova, Dana Ron, Ronitt Rubinfeld, and Adam D. Smith. <a href="https://doi.org/10.1007/s00453-012-9618-6">Sublinear algorithms for approximating string compressibility</a>. <em>Algorithmica</em>, 65(3):685–709, 2013.', citations.burrows94bwt = "Michael Burrows and David J. Wheeler. A block sorting lossless data compression algorithm. Technical report, 124, Digital Equipment Corporation, Palo Alto, California, 1994.", citations.nong11sais = 'Ge Nong, Sen Zhang, and Wai Hong Chan. <a href="https://doi.org/10.1109/TC.2010.188">Two efficient algorithms for linear time suffix array construction</a>. <em><span>IEEE</span> Trans. Computers</em>, 60(10):1471–1484, 2011.', citations.storer82lzss = 'James A. Storer and Thomas G. Szymanski. <a href="https://doi.org/10.1145/322344.322346">Data compression via textural substitution</a>. <em>J. <span>ACM</span></em>, 29(4):928–951, 1982.', citations.storer82lzss = 'James A. Storer and Thomas G. Szymanski. <a href="https://doi.org/10.1145/322344.322346">Data compression via textural substitution</a>. <em>J. <span>ACM</span></em>, 29(4):928–951, 1982.', citations.ziv77lz = 'Jacob Ziv and Abraham Lempel. <a href="https://doi.org/10.1109/TIT.1977.1055714">A universal algorithm for sequential data compression</a>. <em><span>IEEE</span> Trans. Information Theory</em>, 23(3):337–343, 1977.', citations.storer82lzss = 'James A. Storer and Thomas G. Szymanski. <a href="https://doi.org/10.1145/322344.322346">Data compression via textural substitution</a>. <em>J. <span>ACM</span></em>, 29(4):928–951, 1982.', citations.navarro21approximation = 'Gonzalo Navarro, Carlos Ochoa, and Nicola Prezza. <a href="https://doi.org/10.1109/TIT.2020.3042746">On the approximation ratio of ordered parsings</a>. <em><span>IEEE</span> Trans. Inf. Theory</em>, 67(2):1008–1026, 2021.', citations.franek16algorithms = "Frantisek Franek, A. S. M. Sohidull Islam, Mohammad Sohel Rahman, and William F. Smyth. Algorithms to compute the <span>Lyndon</span> array. In <em>Proc. PSC</em>, pages 172–184. 2016.", citations.hon13spaceefficient = 'Wing-Kai Hon, Tsung-Han Ku, Rahul Shah, and Sharma V. Thankachan. <a href="https://doi.org/10.1007/978-3-642-38905-4\\_15">Space-efficient construction algorithm for the circular suffix tree</a>. In <em>Proc. CPM</em>, volume 7922, pages 142–152. 2013.', citations.hon13spaceefficient = 'Wing-Kai Hon, Tsung-Han Ku, Rahul Shah, and Sharma V. Thankachan. <a href="https://doi.org/10.1007/978-3-642-38905-4\\_15">Space-efficient construction algorithm for the circular suffix tree</a>. In <em>Proc. CPM</em>, volume 7922, pages 142–152. 2013.', citations.bannai25survey = 'Hideo Bannai, Dominik Köppl, and Zsuzsanna Lipták. <a href="https://doi.org/10.4230/OASIcs.Manzini.2">A survey of the bijective <span>Burrows</span>–<span>Wheeler</span> transform</a>. In <em>The expanding world of compressed data: A festschrift for <span>Giovanni</span> <span>Manzini</span>’s 60th birthday</em>, volume 131, pages 2:1–2:26. 2025.', citations.bannai25survey = 'Hideo Bannai, Dominik Köppl, and Zsuzsanna Lipták. <a href="https://doi.org/10.4230/OASIcs.Manzini.2">A survey of the bijective <span>Burrows</span>–<span>Wheeler</span> transform</a>. In <em>The expanding world of compressed data: A festschrift for <span>Giovanni</span> <span>Manzini</span>’s 60th birthday</em>, volume 131, pages 2:1–2:26. 2025.', citations.bannai25survey = 'Hideo Bannai, Dominik Köppl, and Zsuzsanna Lipták. <a href="https://doi.org/10.4230/OASIcs.Manzini.2">A survey of the bijective <span>Burrows</span>–<span>Wheeler</span> transform</a>. In <em>The expanding world of compressed data: A festschrift for <span>Giovanni</span> <span>Manzini</span>’s 60th birthday</em>, volume 131, pages 2:1–2:26. 2025.', citations.ziv78lz = 'Jacob Ziv and Abraham Lempel. <a href="https://doi.org/10.1109/TIT.1978.1055934">Compression of individual sequences via variable-rate coding</a>. <em><span>IEEE</span> Trans. Information Theory</em>, 24(5):530–536, 1978.', citations.welch84lzw = 'Terry A. Welch. <a href="https://doi.org/10.1109/MC.1984.1659158">A technique for high-performance data compression</a>. <em><span>IEEE</span> Computer</em>, 17(6):8–19, 1984.', citations.chen58lyndon = "Kuo Tsai Chen, Ralph H. Fox, and Roger C. Lyndon. Free differential calculus, <span>IV</span>. <span>T</span>he quotient groups of the lower central series. <em>Annals of Mathematics</em>, 68(1):81–95, 1958.", citations.manacher75new = 'Glenn K. Manacher. <a href="https://doi.org/10.1145/321892.321896">A new linear-time "on-line" algorithm for finding the smallest initial palindrome of a string</a>. <em>J. <span>ACM</span></em>, 22(3):346–351, 1975.', citations.manacher75new = 'Glenn K. Manacher. <a href="https://doi.org/10.1145/321892.321896">A new linear-time "on-line" algorithm for finding the smallest initial palindrome of a string</a>. <em>J. <span>ACM</span></em>, 22(3):346–351, 1975.', citations.kreft13lzend = 'Sebastian Kreft and Gonzalo Navarro. <a href="https://doi.org/10.1016/j.tcs.2012.02.006">On compressing and indexing repetitive sequences</a>. <em>Theor. Comput. Sci.</em>, 483:115–133, 2013.', citations.kempa18stringattractors = 'Dominik Kempa and Nicola Prezza. <a href="https://doi.org/10.1145/3188745.3188814">At the roots of dictionary compression: String attractors</a>. In <em>Proc. STOC</em>, pages 827–840. 2018.';
const string_generators = {
    fibonacci_word: generate_fibonacci_word,
    tribonacci_word: generate_tribonacci_word,
    thue_morse_word: generate_thue_morse_word,
    mephisto_waltz_word: generate_mephisto_waltz_word,
    vtm_word: generate_vtm_word,
    sierpinski_word: generate_sierpinski_word,
    pell_word: generate_pell_word,
    chacon_word: generate_chacon_word,
    von_neumann_word: generate_von_neumann_word,
    rudin_shapiro_word: generate_rudin_shapiro_word,
    baum_sweet_word: generate_baum_sweet_word,
    kolakoski_word: generate_kolakoski_word
  },
  tutorials = {};

function number_of_runs(t) {
  if (!t) return 0;
  let r = 1,
    e = t[0];
  for (let a = 1; a < t.length; ++a) t[a] !== e && (r++, e = t[a]);
  return r
}

function number_of_factors(t) {
  return t ? t.reduce((t, r) => t + (r ? 1 : 0), 0) : 0
}

function pad_right(t, r, e) {
  if (t.length >= e || 0 === r.length) return t;
  const a = Math.ceil((e - t.length) / r.length);
  return t + r.repeat(a)
}

function pad_left(t, r, e) {
  if (t.length >= e || 0 === r.length) return t;
  const a = Math.ceil((e - t.length) / r.length);
  return r.repeat(a) + t
}

function increment_array(t, r = 1) {
  return t.map(t => t + r)
}

function replace_invalid_position(t, r) {
  return t.map(t => t >= r ? "-" : t)
}

function prettify_string(t, r = " ", e = 0, a = !0) {
  t = t.split("\0").join("$");
  const n = a ? String(t.length + e - 1).length : 0;
  let i = r;
  return a || (i = ""), t.split("").map(t => pad_left(t, " ", n)).join(i)
}

function prettify_array(t, r = " ", e = 0) {
  const a = ("" + Math.max(0, t.length + e - 1)).toString().length;
  return t.map(t => pad_left("" + t, " ", a)).join(r)
}

function prettify_factorization(t, r, e = " ", a = 0) {
  const n = t.length,
    i = String(Math.max(0, n + a - 1)).length;
  let o = "";
  for (let a = 0; a < n; ++a) {
    o += pad_left(a === n - 1 && "\0" === t[a] ? "$" : t[a], " ", i), o += !0 === r[a] ? "|" + e.substring(1) : e
  }
  return o
}

function encodeWhitespaces(t) {
  return t.replace(/\r/g, "␍").replace(/\n/g, "↵").replace(/\t/g, "␉").replace(/\v/g, "␋").replace(/\f/g, "␌").replace(/ /g, "⎵")
}

function decodeWhitespaces(t) {
  return t.replace(/\u240d/g, "\r").replace(/\u21b5/g, "\n").replace(/\u2409/g, "\t").replace(/\u240b/g, "\v").replace(/\u240c/g, "\f").replace(/\u23b5/g, " ")
}

function repeat(t, r) {
  let e = "";
  for (; r-- > 0;) e += t;
  return e
}

function escapeLatex(t) {
  return String(t).replace(/\\/g, "\\textbackslash{}").replace(/([#$%&_{}])/g, "\\$1")
}

function isBoolRow(t) {
  return "boolean" == typeof t.data[0]
}

function isStringRow(t) {
  return "string" == typeof t.data[0]
}

function partitionsFromBool(t) {
  const r = [];
  let e = 0;
  for (let a = 0; a < t.length; a++) e++, t[a] && (r.push(e), e = 0);
  return r
}

function export_latex(t) {
  const r = t[0].data.length,
    e = t.find(isStringRow);
  if (!e) throw new Error("Row T (string[]) required");
  const a = e.data,
    n = [];
  n.push(`\\begin{tabular}{l|${"c".repeat(r)}}`), n.push("\\hline");
  for (const e of t) {
    let t = `${escapeLatex(e.name)} & `;
    if (isBoolRow(e)) {
      const r = partitionsFromBool(e.data);
      let n = 0;
      for (let e = 0; e < r.length; e++) {
        const i = r[e];
        let o = "";
        for (let t = 0; t < i; t++) o += escapeLatex(a[n++]);
        t += `\\multicolumn{${i}}{c}{${o}}`, e !== r.length - 1 && (t += " & ")
      }
    } else
      for (let a = 0; a < r; a++) t += escapeLatex(e.data[a]), a !== r - 1 && (t += " & ");
    t += " \\\\", n.push(t)
  }
  return n.push("\\hline"), n.push("\\end{tabular}"), n.join("\n")
}

function export_markdown(t) {
  const r = t[0].data.length,
    e = t.find(isStringRow);
  if (!e) throw new Error("Row T (string[]) required for boolean partitions");
  const a = e.data,
    n = [],
    i = [" "];
  for (let t = 0; t < r; t++) i.push(String(t + 1));
  n.push("|" + i.join("|") + "|"), n.push("|" + repeat("---|", r + 1));
  for (const e of t) {
    const t = [e.name];
    if (isBoolRow(e)) {
      let n = "";
      for (let t = 0; t < r; t++) n += a[t], e.data[t] && (n += "|");
      t.push(n)
    } else
      for (let a = 0; a < r; a++) t.push(String(e.data[a]));
    n.push("|" + t.join("|") + "|")
  }
  return n.join("\n")
}

function escape_csv(t) {
  const r = String(t);
  return /[",\n]/.test(r) ? `"${r.replace(/"/g,'""')}"` : r
}

function export_csv(t) {
  const r = t[0].data.length,
    e = [];
  for (const a of t) {
    const t = [];
    t.push(a.name);
    for (let e = 0; e < r; e++) t.push(String(a.data[e]));
    e.push(t.map(escape_csv).join(","))
  }
  return e.join("\n")
}
tutorials.fibonacci_word = {
  title: "Fibonacci",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to ab, b \\to a \\} \\) on the letter 'b'",
  oeis: "A003849",
  wikipedia: "Fibonacci_word"
}, tutorials.tribonacci_word = {
  title: "Tribonacci",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to ab, b \\to ac, c \\to a \\} \\) on the letter 'a'",
  oeis: "A080843",
  wikipedia: "Tribonacci_word"
}, tutorials.thue_morse_word = {
  title: "Thue-Morse",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to ab, b \\to ba \\} \\) on the letter 'a'",
  oeis: "A010060",
  wikipedia: "Thue-Morse_sequence"
}, tutorials.mephisto_waltz_word = {
  title: "Mephisto-Waltz",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aab, b \\to bba \\} \\) on the letter 'a'",
  oeis: "A064990",
  cite: "allouche03automatic"
}, tutorials.vtm_word = {
  title: "vtm",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to abc, b \\to ac, c \\to b \\} \\) on the letter 'a'"
}, tutorials.sierpinski_word = {
  title: "Sierpinski",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aba, b \\to bbb \\} \\) on the letter 'a'",
  oeis: "A316829"
}, tutorials.pell_word = {
  title: "Pell",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aab, b \\to a \\} \\) on the letter 'a'",
  oeis: "A171588",
  wikipedia: "Pell_number"
}, tutorials.chacon_word = {
  title: "Chacon",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aaba, b \\to b \\} \\) on the letter 'a'",
  oeis: "A049320"
}, tutorials.von_neumann_word = {
  title: "Neumannn",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aab, b \\to b \\} \\) on the letter 'a'",
  oeis: "A308187"
}, tutorials.rudin_shapiro_word = {
  title: "Rudin-Shapiro",
  content: "Morphic word generated by the morphism \\( \\{ a \\to ab, b \\to ac, c \\to db, d \\to dc \\} \\) followed by the coding \\( \\{ a,b \\to a; c,d \\to b \\} \\) on the letter 'a'",
  oeis: "A020987",
  wikipedia: "Rudin–Shapiro_sequence"
}, tutorials.baum_sweet_word = {
  title: "Baum-Sweet",
  content: "Word defined by setting the \\(j\\)-th letter to 'b' if the binary representation of \\(j\\) contains no block of consecutive 0s of odd length, and to 'a' otherwise.",
  oeis: "A086747",
  wikipedia: "Baum–Sweet_sequence"
}, tutorials.kolakoski_word = {
  title: "Kolakoski",
  content: "Self-generating word over the alphabet {a,b} where 'a' represents 1 and 'b' represents 2. The word starts with \"ab\" and the lengths of consecutive runs are given by the word itself.",
  oeis: "A000002",
  wikipedia: "Kolakoski_sequence"
}, tutorials.sigma = {
  title: "&sigma;",
  content: "The shortest period of a string is the smallest positive integer such that the string is a prefix of an infinite repetition of the prefix of that length. Concretely, the shortest period \\(p\\) of the text \\(T\\) is the length of the shortest prefix \\(P\\) of \\(T\\) such that \\(T\\) is a prefix of \\(P^{k}\\) for some integer \\(k \\geq 1\\).",
  wikipedia: "Alphabet_(formal_languages)"
}, tutorials.period = {
  title: "p",
  content: "The shortest period of a string is the smallest positive integer such that the string is a prefix of an infinite repetition of the prefix of that length. Concretely, the shortest period \\(p\\) of the text \\(T\\) is the length of the shortest prefix \\(P\\) of \\(T\\) such that \\(T\\) is a prefix of \\(P^{k}\\) for some integer \\(k \\geq 1\\).",
  wikipedia: "Periodic_sequence"
}, tutorials.exponent = {
  title: "e",
  content: "The exponent of a string is the division of the string's length by its shortest period, representing how many times the shortest period needs to be repeated to form the string. Formally, the exponent of the text \\(T\\) is defined as the length of \\(T\\) divided by the length of its shortest period \\(p\\), i.e., \\(\\frac{|T|}{p}\\).",
  wikipedia: "Periodic_sequence"
}, tutorials.regularity = {
  title: "R",
  content: "The regularity type of a string classifies it based on its periodic structure. A string can be categorized as unbordered, primitive, square, or non-primitive based on its borders and periods. Specifically, a string is unbordered if it has no proper border, primitive if it cannot be expressed as a repetition of a smaller substring, square if it is formed by repeating a substring exactly twice, and non-primitive if it can be expressed as a repetition of a smaller substring more than twice."
}, tutorials.suffix_array = {
  title: "SA",
  content: "The suffix array sorts the entry indices of a string based on the lexicographical order of their corresponding suffixes. Formally, the suffix array \\(\\mathsf{SA}\\) of the text \\(T[1..n]\\) is an array of integers representing the starting indices of all the suffixes of \\(T\\), sorted in lexicographical order. It obeys that \\(T[\\mathsf{SA}[i]..n] \\prec T[\\mathsf{SA}[i+1]..n]\\) for all text positions \\(i \\in [1..n-1]\\).",
  cite: "manber93sa",
  wikipedia: "Suffix_array"
}, tutorials.border_array = {
  title: "B",
  content: "The border array of a string stores the lengths of the longest borders for each prefix of the string. A border of a string is defined as a substring that is both a proper prefix and a proper suffix. Formally, the border array \\(\\mathsf{B}\\) for a text \\(T[1..n]\\) is an array where each entry \\(\\mathsf{B}[i]\\) represents the length of the longest border of the prefix \\(T[1..i]\\), i.e., \\(\\mathsf{B}[i]\\) is the largest integer \\(k \\le i-1\\) such that \\(T[1..k] = T[i-k+1..i]\\). By definition, \\(\\mathsf{B}[0] = 0\\).",
  wikipedia: "Knuth–Morris–Pratt_algorithm"
}, tutorials.bw_transform = {
  title: "BWT",
  content: "The Burrows-Wheeler Transform (BWT) is a reversible transformation that rearranges the characters of a string based on the lexicographical order of its cyclic rotations. Formally, given a text \\(T[1..n]\\) and its rotation array \\(\\mathsf{Rot}\\), the BWT \\(\\mathsf{BWT}[1..n]\\) is defined such that \\(\\mathsf{BWT}[i] = T[(\\mathsf{Rot}[i] + n - 1) \\mod n]\\) for each \\(i \\in [1..n]\\).",
  cite: "burrows94bwt",
  wikipedia: "Burrows%E2%80%93Wheeler_transform"
}, tutorials.first_array = {
  title: "F",
  content: "The First Column Array represents the first column of the sorted rotations of a string, which is obtained by sorting the characters of the string in lexicographical order. Formally, for a given text \\(T[1..n]\\), the First Column Array \\(\\mathsf{F}\\) is defined as the sorted sequence of characters in \\(T\\).",
  cite: "burrows94bwt",
  wikipedia: "Burrows%E2%80%93Wheeler_transform"
}, tutorials.index_array = {
  title: "i",
  content: "The index array contains a sequence of integers from \\(1\\) to \\(n\\), where \\(n\\) is the length of the input text \\(T[1..n]\\). Formally, the index array \\(\\mathsf{i}\\) is defined such that \\(\\mathsf{i}[j] = j\\) for each \\(j \\in [1..n]\\)."
}, tutorials.rotation_array = {
  title: "Rot",
  content: "The rotation array sorts the entry indices of a string based on the lexicographical order of their corresponding cyclic rotations. Formally, the rotation array \\(\\mathsf{Rot}\\) of the text \\(T[1..n]\\) is an array of integers representing the starting indices of all the cyclic rotations of \\(T\\), sorted in lexicographical order. It obeys that \\(T[\\mathsf{Rot}[i]..n]T[1..\\mathsf{Rot}[i]-1] \\prec T[\\mathsf{Rot}[i+1]..n]T[1..\\mathsf{Rot}[i+1]-1]\\) for all text positions \\(i \\in [1..n-1]\\), where $\\prec$ is a total order by assigning lower ranks to lexicographically smaller strings and uses the text position \\(i\\) for tie-breaking."
}, tutorials.inverse_suffix_array = {
  title: "ISA",
  content: "The inverse suffix array provides a mapping from each starting index of the suffixes of a string back to their respective positions in the suffix array. Formally, given the suffix array \\(\\mathsf{SA}\\) of the text \\(T[1..n]\\), the inverse suffix array \\(\\mathsf{ISA}\\) is defined such that \\(\\mathsf{ISA}[\\mathsf{SA}[i]] = i\\) for each \\(i \\in [1..n]\\).",
  cite: "manber93sa",
  wikipedia: "Suffix_array"
}, tutorials.phi_array = {
  title: "&Phi;",
  content: "The Phi array provides a mapping from each starting index of the suffixes of a string to the starting index of the lexicographically preceding suffix. Formally, given the suffix array \\(\\mathsf{SA}\\) and the inverse suffix array \\(\\mathsf{ISA}\\) of the text \\(T[1..n]\\), the Phi array \\(\\mathsf{\\Phi}\\) is defined such that \\(\\mathsf{\\Phi}[i] = \\mathsf{SA}[\\mathsf{ISA}[i] - 1]\\) if \\(\\mathsf{ISA}[i] > 0\\), and \\(\\mathsf{\\Phi}[i] = \\bot\\) if \\(\\mathsf{ISA}[i] = 0\\), for each \\(i \\in [1..n]\\).",
  cite: "karkkainen09plcp"
}, tutorials.inverse_phi_array = {
  title: "&Phi;&#8315;&#185;",
  content: "The inverse Phi array provides a mapping from each starting index of the suffixes of a string to the starting index of the lexicographically succeeding suffix. Formally, given the suffix array \\(\\mathsf{SA}\\) and the inverse suffix array \\(\\mathsf{ISA}\\) of the text \\(T[1..n]\\), the inverse Phi array \\(\\mathsf{\\Phi}^{-1}\\) is defined such that \\(\\mathsf{\\Phi}^{-1}[i] = \\mathsf{SA}[\\mathsf{ISA}[i] + 1]\\) if \\(\\mathsf{ISA}[i] \\le n-1 \\), and \\(\\mathsf{\\Phi}^{-1}[i] = \\bot\\) if \\(\\mathsf{ISA}[i] = n \\), for each \\(i \\in [1..n]\\)."
}, tutorials.lcp_array = {
  title: "LCP",
  content: "The Longest Common Prefix (LCP) array stores the lengths of the longest common prefixes between consecutive suffixes in the suffix array of a string. Formally, for a given text \\(T[1..n]\\) and its suffix array \\(\\mathsf{SA}\\), the LCP array \\(\\mathsf{LCP}[1..n]\\) is defined such that \\(\\mathsf{LCP}[1] = 0\\) and \\(\\mathsf{LCP}[i] = \\text{lcp}(T[\\mathsf{SA}[i]..n], T[\\mathsf{SA}[i-1]..n])\\) for each \\(i \\in [2..n]\\), where \\(\\text{lcp}(S_1, S_2)\\) denotes the length of the longest common prefix between the suffixes \\(S_1\\) and \\(S_2\\).",
  wikipedia: "Longest_common_prefix_array"
}, tutorials.lcp_array = {
  title: "&Sigma; LCP",
  content: "The sum of the Longest Common Prefix (LCP) array values provides a measure of the total length of common prefixes between consecutive suffixes in the suffix array of a string. Formally, for a given LCP array \\(\\mathsf{LCP}[1..n]\\), the sum \\(\\Sigma \\mathsf{LCP}\\) is defined as \\(\\sum_{i=1}^{n} \\mathsf{LCP}[i]\\).",
  wikipedia: "Longest_common_prefix_array"
}, tutorials.plcp_array = {
  title: "PLCP",
  content: "The Permuted Longest Common Prefix (PLCP) array reorders the values of the Longest Common Prefix (LCP) array based on the respective positions in the string. Formally, for the inverse suffix array \\(\\mathsf{ISA}\\) and LCP array \\(\\mathsf{LCP}\\) of the text \\(T[1..n]\\), the PLCP array \\(\\mathsf{PLCP}[1..n]\\) is defined such that \\(\\mathsf{PLCP}[i] = \\mathsf{LCP}[\\mathsf{ISA}[i]]\\) for each \\(i \\in [1..n]\\).",
  cite: "karkkainen09plcp",
  wikipedia: "Longest_common_prefix_array"
}, tutorials.psi_array = {
  title: "&Psi;",
  content: "The Psi array provides a mapping inside the suffix array that advances by one text position. Formally, given the suffix array \\(\\mathsf{SA}\\) and the inverse suffix array \\(\\mathsf{ISA}\\) of the text \\(T[1..n]\\), the Psi array \\(\\mathsf{\\Psi}\\) is defined such that \\(\\mathsf{\\Psi}[i] = \\mathsf{ISA}[\\mathsf{SA}[i] + 1]\\) if \\(\\mathsf{SA}[i] + 1 < n\\), and \\(\\mathsf{\\Psi}[i] = \\bot\\) if \\(\\mathsf{SA}[i] + 1 = n\\), for each \\(i \\in [1..n]\\).",
  cite: "grossi05csa"
}, tutorials.lyndon_factorization = {
  title: "LynF",
  content: "The Lyndon factorization of a string decomposes it into a sequence of Lyndon words in lexicographically non-increasing order, where a Lyndon word is a non-empty string that is strictly smaller in lexicographical order than all of its non-trivial rotations.",
  cite: "chen58lyndon"
}, tutorials.delta = {
  title: "&delta;",
  content: "The substring complexity measure quantifies the maximum ratio of substring complexity to length. Given an array of substring complexities for lengths \\(1\\) to \\(n\\), it computes the maximum value of \\(\\frac{\\mathsf{SC}[k]}{k}\\) for \\(k \\in [1..n]\\), where \\(\\mathsf{SC}[k]\\) is the substring complexity for length \\(k\\).",
  cite: "raskhodnikova13sublinear"
}, tutorials.delta_argmax = {
  title: "max &delta;",
  content: "The substring complexity measure length identifies the substring length that maximizes the ratio of substring complexity to length. Given an array of substring complexities for lengths \\(1\\) to \\(n\\), it computes the length \\(k\\) that maximizes \\(\\frac{\\mathsf{SC}[k]}{k}\\), where \\(\\mathsf{SC}[k]\\) is the substring complexity for length \\(k\\).",
  cite: "raskhodnikova13sublinear"
}, tutorials.substring_complexity = {
  title: "SC",
  content: "The substring complexity array quantifies the number of distinct substrings of various lengths within a string. Given the Longest Common Prefix (LCP) array of a string, the substring complexity array \\(\\mathsf{SC}[1..n]\\) is defined such that for each length \\(k \\in [1..n]\\), \\(\\mathsf{SC}[k]\\) represents the count of distinct substrings of length \\(k\\). The computation leverages the LCP values to efficiently determine the number of new substrings introduced at each length.",
  cite: "raskhodnikova13sublinear"
}, tutorials.lf_array = {
  title: "LF",
  content: "The Last-to-First (LF) mapping array identifies characters from the last column with those from the first column of the Burrows-Wheeler Transform (BWT) that orginated from the same text position. Given the first column \\(\\mathsf{F}\\) and \\(\\textsf{BWT}\\), the LF mapping array \\(\\mathsf{LF}[1..n]\\) is defined such that \\(\\mathsf{LF}[i] = \\text{select}(\\textsf{F}, \\textsf{BWT}[i], \\text{rank}(\\textsf{BWT}, \\textsf{BWT}[i], i))\\) for each \\(i \\in [1..n]\\), where \\(\\text{rank}(\\textsf{BWT}, c, i)\\) counts the occurrences of character \\(c\\) in the prefix \\(\\textsf{BWT}[1..i]\\), and \\(\\text{select}(\\textsf{F}, c, r)\\) finds the position of the \\(r\\)-th occurrence of character \\(c\\) in \\(\\textsf{F}\\).",
  cite: "burrows94bwt",
  wikipedia: "Burrows%E2%80%93Wheeler_transform"
}, tutorials.sl_string = {
  title: "S/L",
  content: "The S/L type string classifies each character in a string as either S-type or L-type based on the lexicographic order of the suffixes starting at those characters. A character at position \\(i\\) is classified as S-type if the suffix starting at \\(i\\) is lexicographically smaller than the suffix starting at \\(i+1\\), and L-type if it is larger. If the suffixes are equal, the type is determined by the type of the suffix starting at \\(i+1\\). Additionally, an S-type character that is the first character or immediately preceded by an L-type character is marked as S*-type.",
  cite: "nong11sais"
}, tutorials.lpf_array = {
  title: "LPF",
  content: "The Longest Previous Factor (LPF) array stores the length of the longest prefix of each suffix of a string that matches a substring starting at a prior position within the same string. Formally, for a given text \\(T[1..n]\\), the LPF array \\(\\mathsf{LPF}[1..n]\\) is defined such that \\(\\mathsf{LPF}[i] = \\max_{j \\in [1..i-1]} \\text{lcp}(T[i..n], T[j..n])\\) for each \\(i \\in [1..n]\\), where \\(\\text{lcp}(S_1, S_2)\\) denotes the length of the longest common prefix between the suffixes \\(S_1\\) and \\(S_2\\)."
}, tutorials.lpnf_array = {
  title: "LPnF",
  content: "The Longest Previous Non-Overlapping Factor (LPnF) array stores the length of the longest prefix of each suffix of a string that matches a substring ending at a prior position within the same string. Formally, for a given text \\(T[1..n]\\), the LPnF array \\(\\mathsf{LPnF}[1..n]\\) is defined such that \\(\\mathsf{LPnF}[i] = \\max_{j \\in [1..i-1]} \\min(i-j,\\text{lcp}(T[i..n], T[j..n]))\\) for each \\(i \\in [1..n]\\), where \\(\\text{lcp}(S_1, S_2)\\) denotes the length of the longest common prefix between the suffixes \\(S_1\\) and \\(S_2\\)."
}, tutorials.lnf_array = {
  title: "LNF",
  content: "The Longest Next Factor (LNF) array is the LPF array of the reversed text."
}, tutorials.lzss_factorization = {
  title: "LZSS",
  content: "The Lempel-Ziv-Storer-Szymanski (LZSS) factorization decomposes a string into a sequence of factors, where each factor is either a new character or a reference to a substring with an earlier starting position. The factorization is constructed greedily by selecting the longest previous factor at each position in the string. Formally, given a text \\(T[1..n]\\) the length of the factor starting at position \\(i\\) is \\(\\max \\{1\\} \\cup \\{\\text{lcp}(T[i..n], T[j..n]) \\mid j \\in [1..i-1] \\}\\).",
  cite: "storer82lzss"
}, tutorials.lzssno_factorization = {
  title: "LZSSno",
  content: "The Lempel-Ziv-Storer-Szymanski non-overlapping (LZSSno) factorization decomposes a string into a sequence of factors, where each factor is either a new character or a reference to a substring ending at an earlier positition. The factorization is constructed greedily by selecting the longest previous non-overlapping factor at each position in the string. Formally, given a text \\(T[1..n]\\) the length of the factor starting at position \\(i\\) is \\(\\max \\{1\\} \\cup \\{\\min(i-j, \\text{lcp}(T[i..n], T[j..n])) \\mid j \\in [1..i-1] \\}\\).",
  cite: "storer82lzss"
}, tutorials.lz77_factorization = {
  title: "LZ77",
  content: "The Lempel-Ziv-77  (LZ77) factorization decomposes a string into a sequence of factors, where each factor is either a new character or a reference to a substring starting at a prior position within the same string. The factorization is constructed greedily by selecting the longest previous factor at each position in the string, with an additional character appended to the factor. Formally, given a text \\(T[1..n]\\) the length of the factor starting at position \\(i\\) is \\(\\max \\{1\\} \\cup \\{\\text{lcp}(T[i..n], T[j..n]) + 1 \\mid j \\in [1..i-1] \\}\\).",
  cite: "ziv77lz"
}, tutorials.reverse_lzss_factorization = {
  title: "rLZSS",
  content: "The Reverse Lempel-Ziv-Storer-Szymanski (rLZSS) factorization of a string is the LZSS factorization of the reversed string obtained by reading the string in reversed order.",
  cite: "storer82lzss"
}, tutorials.lexparse_factorization = {
  title: "LexParse",
  content: "The lexicographic parse (lexparse) decomposes a string into a sequence of factors based on the permuted longest common prefix (PLCP) array. Each factor is determined by the longest prefix of the suffix starting at the current position that matches a substring starting at a lexicographically smaller suffix position. Formally, for a given text \\(T[1..n]\\) and its PLCP array \\(\\mathsf{PLCP}[1..n]\\), the length of the factor starting at position \\(i\\) is \\(\\mathsf{PLCP}[i]\\) or 1 if \\(\\mathsf{PLCP}[i] = 0\\).",
  cite: "navarro21approximation"
}, tutorials.nss_array = {
  title: "NSS",
  content: "The Next Smaller Suffix (NSS) array identifies the subsequent suffix in text order that is lexicographically smaller than the current suffix. Given the inverse suffix array \\(\\mathsf{ISA}\\) of a text \\(T[1..n]\\), the NSS array \\(\\mathsf{NSS}[1..n]\\) is defined such that \\(\\mathsf{NSS}[i] = \\min \\{ j > i \\mid \\mathsf{ISA}[j] < \\mathsf{ISA}[i] \\}\\) if such a \\(j\\) exists, and \\(\\mathsf{NSS}[i] = \\bot \\) otherwise, for each \\(i \\in [1..n]\\)."
}, tutorials.pss_array = {
  title: "PSS",
  content: "The Previous Smaller Suffix (PSS) array identifies the preceding suffix in text order that is lexicographically smaller than the current suffix. Given the inverse suffix array \\(\\mathsf{ISA}\\) of a text \\(T[1..n]\\), the PSS array \\(\\mathsf{PSS}[1..n]\\) is defined such that \\(\\mathsf{PSS}[i] = \\max \\{ j < i \\mid \\mathsf{ISA}[j] < \\mathsf{ISA}[i] \\}\\) if such a \\(j\\) exists, and \\(\\mathsf{PSS}[i] = \\bot \\) otherwise, for each \\(i \\in [1..n]\\)."
}, tutorials.lyndon_array = {
  title: "Lyndon",
  content: "The Lyndon array stores the lengths of the longest Lyndon words starting at each position in a string. A Lyndon word is a non-empty string that is strictly smaller in lexicographical order than all of its non-trivial rotations. Given the Next Smaller Suffix (NSS) array \\(\\mathsf{NSS}[1..n]\\) of a text \\(T[1..n]\\), the Lyndon array \\(\\mathsf{Lyndon}[1..n]\\) is defined such that \\(\\mathsf{Lyndon}[i] = \\mathsf{NSS}[i] - i\\) if \\(\\mathsf{NSS}[i] \\neq \\bot\\), and \\(\\mathsf{Lyndon}[i] = n - i + 1\\) otherwise, for each \\(i \\in [1..n]\\).",
  cite: "franek16algorithms"
}, tutorials.necklace_conjugate_transform = {
  title: "necklace",
  content: "The necklace conjugate of a string is the lexicographically smallest string that can be obtained by rotating the original string. This involves generating all possible rotations (conjugates) of the string and selecting the smallest one in lexicographic order."
}, tutorials.invert_transform = {
  title: "Invert",
  content: "The invert transform of a string maps each character to its complementary character based on the minimum and maximum characters in the string. Specifically, given a text \\(T[1..n]\\), the invert transform \\(\\mathsf{Invert}(T)\\) maps each character \\(T[i]\\) to \\(\\text{max_j} T[j] - (c - \\text{min_j T[j]})\\)."
}, tutorials.revert_transform = {
  title: "Revert",
  content: "The revert transform of a string is obtained by reversing the order of its characters. Given a text \\(T[1..n]\\), the revert transform \\(\\mathsf{Revert}(T)\\) produces the string \\(T[n] T[n-1] \\ldots T[1]\\), where the characters are arranged in the opposite order, effectively reading the string backwards."
}, tutorials.circular_suffix_array = {
  title: "CSA",
  content: "The Circular Suffix Array (CSA) of a string is a permutation of text positions that assigns a rank to each cyclic rotation (conjugate) of the Lyndon factors of the string based on the omega order. Given a text \\(T[1..n]\\) and its Lyndon factorization, the CSA \\(\\mathsf{CSA}[1..n]\\) is defined such that \\(\\mathsf{CSA}[i]\\) gives the starting position in \\(T\\) of the \\(i\\)-th smallest conjugate in \\(\\omega\\)-order among all conjugates of the Lyndon factors of \\(T\\).",
  cite: "hon13spaceefficient"
}, tutorials.inverse_circular_suffix_array = {
  title: "CISA",
  content: "The inverse circular suffix array (ICSA) is the reverse permutation of the circular suffix array (CSA).",
  cite: "hon13spaceefficient"
}, tutorials.bbw_indices = {
  title: "BBWTi",
  content: "The Bijective Burrows-Wheeler Transform Indices (BBWTi) array stores the text positions of the circular sufix array (CSA) decremented by one, but mapping positions at the beginning of Lyndon factors to the end of the respective Lyndon factor.",
  cite: "bannai25survey"
}, tutorials.bbw_transform = {
  title: "BBWT",
  content: "The Bijective Burrows-Wheeler Transform (BBWT) of a string rearranges the characters of the original string based on the Bijective Burrows-Wheeler Transform Indices (BBWTi). Given a text \\(T[1..n]\\) and its BBWTi array \\(\\mathsf{BBWTi}[1..n]\\), the BBWT \\(\\mathsf{BBWT}[1..n]\\) is defined such that \\(\\mathsf{BBWT}[i] = T[\\mathsf{BBWTi}[i]]\\) for each \\(i \\in [1..n]\\).",
  cite: "bannai25survey"
}, tutorials.inverse_bbw_transform = {
  title: "BBWT&#8315;&#185;",
  content: "The inverse Bijective Burrows-Wheeler Transform (inverse BBWT), also called the Gessel-Reutenauer transformation, applies the LF-mapping on the cycles in the BBWT to extract all Lyndon words, which sorted in lexicographically descreing order recovers the original text.",
  cite: "bannai25survey"
}, tutorials.lz78_factorization = {
  title: "LZ78",
  content: "The Lempel-Ziv-78 (LZ78) factorization decomposes a string into a sequence of factors based on previously seen substrings. Each factor consists of a reference to the longest previously seen factor (or zero if none exists) followed by a new character.",
  cite: "ziv78lz"
}, tutorials.lzw_factorization = {
  title: "LZW",
  content: "The Lempel-Ziv-Welch (LZW) factorization decomposes a string into a sequence of factors by building a dictionary of previously seen substrings. Each factor is the longest prefix of the remaining text that exists in the dictionary, followed by the next character.",
  cite: "welch84lzw"
}, tutorials.necklace_factorization = {
  title: "NeckF",
  content: "The Necklace factorization is the Lyndon factorization colliding all equal Lyndon factors to a single factor that is a necklace. The number of factors is the number of distinct Lyndon factors.",
  cite: "chen58lyndon"
}, tutorials.odd_maximal_palindromic_length_array = {
  title: "o-pali",
  content: "The odd maximal palindromic length array (o-pali) stores at each position the length of the left arm of the longest odd-length palindromic substring centered at that position, excluding the position itself in the length measurement. Hence, a palindrome of length \\(2k+1\\) contributes \\(k\\) to the o-pali array at its center position.",
  cite: "manacher75new"
}, tutorials.even_maximal_palindromic_length_array = {
  title: "e-pali",
  content: "The even maximal palindromic length array (e-pali) stores at each position the length of the longest even-length palindromic substring centered between that and its preding position.",
  cite: "manacher75new"
}, tutorials.lzend_factorization = {
  title: "LZend",
  content: "The LZ-end factorization is a restriction of the Lempel-Ziv 77 factorization where each new factor, omitting its last new character, must be the longest possible prefix of the remaining text that also appears ending exactly at the end of a previous factor, or just a single character if no such match exists.",
  cite: "kreft13lzend"
}, tutorials.gamma_factorization = {
  title: "&Gamma;",
  content: "A string attractor is a set of positions in a string such that every distinct substring has at least one occurrence that crosses one of these positions. The smallest string attractor size is the minimum number of positions needed to form such a set. Here, \\(\\Gamma\\) is the leftmost such smallest string attractor, i.e., the one that has the lexicographically smallest sequence of positions.",
  cite: "kempa18stringattractors"
}, self.onmessage = function(t) {
  const r = t.data,
    e = build_ds(r[0], r[1]);
  self.postMessage(e)
};
</script>
  
  

  
<script>class AlgorithmError extends Error {
  constructor(t, e, n) {
    super(t), this.algorithm = e, this.input = n, this.name = "AlgorithmError"
  }
}

function count_sigma(t) {
  return t ? new Set(t).size : 0
}

function count_period(t) {
  if (!t || 0 === t.length) return 0;
  const e = t[t.length - 1];
  return t.length - e
}

function count_exponent(t) {
  if (!t || 0 === t.length) return 0;
  const e = count_period(t);
  return t.length / e
}

function count_regularity(t) {
  if (!t || 0 === t.length) return "empty";
  const e = t.length,
    n = t[e - 1],
    r = count_period(t),
    i = count_exponent(t);
  return i > 1 && e % r == 0 ? 2 == i ? "square" : "non-primitive" : 0 == n ? "unbordered" : "primitive"
}

function construct_suffix_array(t) {
  if (!t) return [];
  const e = t.length,
    n = [...Array(e).keys()].map(e => [e, t.substring(e)]);
  return n.sort((t, e) => t[1].localeCompare(e[1])), n.map(t => t[0])
}

function construct_border_array(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e);
  n[0] = 0;
  for (let r = 1; r < e; r++) {
    let e = n[r - 1];
    for (; e > 0 && t[r] !== t[e];) e = n[e - 1];
    t[r] === t[e] && e++, n[r] = e
  }
  return n
}

function construct_bw_transform(t, e) {
  if (!t) return "";
  if (t.length !== e.length) throw new AlgorithmError("Invalid input: text must be a string and rotation_array must be an array", "BWT", {
    text: t,
    rotation_array: e
  });
  const n = t.length;
  let r = "";
  for (let i = 0; i < n; i++) r += t[(e[i] + n - 1) % n];
  return r
}

function construct_first_array(t) {
  return t ? [...t].sort().join("") : ""
}

function construct_index_array(t) {
  return !t || t <= 0 ? [] : Array.from(Array(t).keys())
}

function construct_rotation_array(t) {
  if (!t) return [];
  const e = t.length,
    n = [...Array(e).keys()].map(e => [e, conjugate_string(t, e)]);
  return n.sort((t, e) => {
    const n = t[1].localeCompare(e[1]);
    return 0 !== n ? n : t[0] - e[0]
  }), n.map(t => t[0])
}

function construct_inverse_suffix_array(t) {
  if (!t) return [];
  const e = new Array(t.length);
  for (let n = 0; n < t.length; n++) e[t[n]] = n;
  return e
}

function construct_phi_array(t, e) {
  const n = t.length,
    r = new Array(n);
  for (let i = 0; i < n; i++) 0 !== e[i] ? r[i] = t[e[i] - 1] : r[i] = n;
  return r
}

function construct_inverse_phi_array(t, e) {
  if (!t || !e) return [];
  const n = t.length,
    r = new Array(n);
  for (let i = 0; i < n; ++i) e[i] + 1 !== n ? r[i] = t[e[i] + 1] : r[i] = n;
  return r
}

function lcp_query(t, e, n) {
  if (!t || e < 0 || n < 0 || e >= t.length || n >= t.length) return 0;
  let r = 0;
  const i = Math.min(t.length - e, t.length - n);
  for (let a = 0; a < i && t[e + a] === t[n + a]; ++a) r++;
  return r
}

function construct_lcp_array(t, e) {
  if (!t || !e) return [];
  const n = [0];
  for (let r = 1; r < e.length; r++) n.push(lcp_query(t, e[r], e[r - 1]));
  return n
}

function count_lcp_array(t) {
  return t ? t.reduce((t, e) => t + e, 0) : 0
}

function construct_plcp_array(t, e) {
  if (!t || !e) return [];
  if (t.length !== e.length) throw new AlgorithmError("Inverse suffix array and LCP array must have the same length.", "PLCP", {
    inverse_suffix_array: t,
    lcp_array: e
  });
  const n = t.length;
  return [...new Array(n).keys()].map(n => e[t[n]])
}

function construct_psi_array(t, e) {
  if (!t || !e) return [];
  const n = t.length;
  return [...new Array(n).keys()].map(r => t[r] + 1 < n ? e[t[r] + 1] : n)
}

function construct_lyndon_factorization(t, e) {
  if (!t || !e) return [];
  const n = t.length;
  if (0 === n) return [];
  const r = new Array(n).fill(!1);
  if (e.length < n) throw new AlgorithmError(`Inverse suffix array (inverse_suffix_array) must have a length of at least text.length (${n}), but got ${e.length}.`, "LynF", {
    text: t,
    inverse_suffix_array: e
  });
  let i = e[0];
  for (let t = 0; t + 1 < n; ++t) i > e[t + 1] && (r[t] = !0, i = e[t + 1]);
  return r[n - 1] = !0, r
}

function delta(t) {
  if (0 === t.length) throw new AlgorithmError("Input array 'substring_complexity' cannot be empty.", "delta", {
    substring_complexity: t
  });
  let e = 1,
    n = t[0];
  for (let r = 1; r < t.length; ++r) {
    const i = t[r] / (r + 1);
    i > n && (e = r + 1, n = i)
  }
  return [e, n]
}

function count_delta(t) {
  return t ? delta(t)[1] : 0
}

function count_delta_argmax(t) {
  return t ? delta(t)[0] : 0
}

function construct_substring_complexity(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e),
    r = new Map;
  t.forEach(t => {
    r.set(t, (r.get(t) || 0) + 1)
  });
  let i = 0;
  for (let t = e; t >= 1; --t) i += 1, r.has(t) && (i -= r.get(t)), n[t - 1] = i;
  return n
}

function conjugate_string(t, e) {
  if (!t) return "";
  if (e < 0 || e > t.length) throw new AlgorithmError("Shift value must be between 0 and the length of the string.", "conjugate_string", {
    text: t,
    shift: e
  });
  return 0 === t.length || 0 === e ? t : t.substring(e) + t.substring(0, e)
}

function select_query(t, e, n) {
  if (!t) return -1;
  if (n <= 0) throw new AlgorithmError("The 'nth' parameter must be a positive integer for 1-based indexing.", "select_query", {
    text: t,
    pattern: e,
    nth: n
  });
  let r = -1;
  for (let i = 0; i < n; ++i)
    if (r = t.indexOf(e, r + 1), -1 === r) return -1;
  return r
}

function rank_query(t, e, n) {
  if (!t) return 0;
  return [...t.slice(0, n)].filter(t => t === e).length
}

function construct_lf_array(t, e) {
  if (!t || !e) return [];
  if (t.length !== e.length) throw new AlgorithmError("First array and BWT must have the same length.", "LF", {
    first_array: t,
    bw_transform: e
  });
  const n = t.length,
    r = new Array(n);
  for (let i = 0; i < n; ++i) {
    const n = e[i],
      a = rank_query(e, n, i + 1);
    r[i] = select_query(t, n, a)
  }
  return r
}

function construct_sl_string(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e);
  let r = "S";
  n[e - 1] = r;
  for (let i = e - 2; i >= 0; --i) t[i + 1] > t[i] ? r = "S" : t[i + 1] < t[i] && (r = "L", "S" == n[i + 1] && (n[i + 1] = "S*")), n[i] = r;
  return "S" == n[0] && (n[0] = "S*"), n
}

function construct_lpf_array(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e);
  n[0] = 0;
  for (let r = 1; r < e; r++) {
    let i = 0;
    for (let n = 0; n < r; n++) {
      let a = 0;
      for (; r + a < e && n + a < e && t[r + a] === t[n + a];) a++;
      i = Math.max(i, a)
    }
    n[r] = i
  }
  return n
}

function construct_lpnf_array(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e);
  n[0] = 0;
  for (let r = 1; r < e; r++) {
    let i = 0;
    for (let n = 0; n < r; n++) {
      let a = 0;
      for (; r + a < e && n + a < r && t[r + a] === t[n + a];) a++;
      i = Math.max(i, a)
    }
    n[r] = i
  }
  return n
}

function construct_lnf_array(t) {
  if (!t) return [];
  const e = construct_lpf_array(t.split("").reverse().join("")),
    n = e.length;
  return [...new Array(n).keys()].map(t => e[n - 1 - t])
}

function greedy_factorize(t) {
  if (!t) return [];
  const e = t.length;
  if (0 === e) return [];
  const n = new Array(e).fill(!1);
  for (let r = 0; r < e;) {
    const e = t[r];
    let i = 0 === e ? 1 : e;
    n[r + i - 1] = !0, r += i
  }
  return n
}

function construct_lzss_factorization(t) {
  return greedy_factorize(t)
}

function construct_lzssno_factorization(t) {
  return greedy_factorize(t)
}

function greedy_factorize_with_new_letter(t) {
  if (!t) return [];
  const e = t.length;
  if (0 === e) return [];
  const n = new Array(e).fill(!1);
  for (let r = 0; r < e;) {
    const i = t[r];
    let a = 0 === i ? 1 : Math.min(i + 1, e - r);
    n[r + a - 1] = !0, r += a
  }
  return n
}

function construct_lz77_factorization(t) {
  return greedy_factorize_with_new_letter(t)
}

function construct_reverse_lzss_factorization(t) {
  if (!t) return [];
  return greedy_factorize(t.slice().reverse())
}

function construct_lexparse_factorization(t) {
  return greedy_factorize(t)
}

function construct_nss_array(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e);
  for (let r = 0; r < e; ++r) {
    let i = r + 1;
    for (; i < e && t[i] > t[r];) ++i;
    n[r] = i >= e ? e : i
  }
  return n
}

function construct_pss_array(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e);
  for (let r = 0; r < e; ++r) {
    let i = r - 1;
    for (; i >= 0 && t[i] > t[r];) --i;
    n[r] = i < 0 ? e : i
  }
  return n
}

function construct_lyndon_array(t) {
  if (!t) return [];
  const e = t.length;
  let n = new Array(e);
  for (let r = 0; r < e; ++r) n[r] = t[r] === e ? e - r : t[r] - r;
  return n
}

function construct_necklace_conjugate_transform(t) {
  if (!t) return "";
  const e = t.length;
  let n = t;
  for (let r = 0; r < e; ++r) {
    const e = conjugate_string(t, r);
    e < n && (n = e)
  }
  return n
}

function construct_invert_transform(t) {
  if (!t) return "";
  const e = [...t].sort(),
    n = e[0],
    r = e.reverse()[0];
  return [...t].map(function(t) {
    return String.fromCharCode(r.charCodeAt(0) - (t.charCodeAt(0) - n.charCodeAt(0)))
  }).join("")
}

function construct_revert_transform(t) {
  return t ? t.split("").reverse().join("") : ""
}

function phrases_from_factorizations(t, e) {
  if (!t || !e) return [];
  const n = t.length,
    r = [];
  let i = 0;
  for (let a = 0; a < n; ++a)
    if (!0 === e[a]) {
      let e = t.slice(i, a + 1);
      i = a + 1, r.push(e)
    } return r
}

function omega_order(t, e) {
  if (void 0 === t || void 0 === e) throw new AlgorithmError("Undefined string input(s) for omega order comparison.", "OmegaOrder", {
    strA: t,
    strB: e
  });
  if (t === e) return 0;
  const n = 3 * Math.max(t.length, e.length);
  for (let r = 0; r < n; ++r) {
    if (t[r % t.length] < e[r % e.length]) return -1;
    if (t[r % t.length] > e[r % e.length]) return 1
  }
  return t.length < e.length ? -1 : 1
}

function construct_circular_suffix_array(t, e) {
  if (!t || !e) return [];
  const n = phrases_from_factorizations(t, e),
    r = [];
  let i = 0;
  for (const t of n) {
    const e = t.length;
    for (let n = 0; n < e; ++n) r.push({
      pos: i + n,
      str: conjugate_string(t, n)
    });
    i += e
  }
  return r.sort((t, e) => omega_order(t.str, e.str)), [...r].map(t => t.pos)
}

function construct_inverse_circular_suffix_array(t) {
  return t ? construct_inverse_suffix_array(t) : []
}

function construct_bbw_indices(t, e) {
  if (!t || !e) return [];
  const n = e.length;
  return [...e].map(e => {
    var r;
    if (0 == e || 1 == t[e - 1]) {
      const i = rank_query(t, !0, e),
        a = select_query(t, !0, 1 + i);
      r = -1 == a ? n - 1 : a
    } else r = e - 1;
    return r
  })
}

function construct_bbw_transform(t, e) {
  return t && e ? [...e].map(e => t[e]).join("") : ""
}

function construct_inverse_bbw_transform(t) {
  if (!t) return "";
  let e = t.length;
  var n = construct_first_array(t),
    r = new Array(e).fill(0),
    i = [];
  for (let o = 0; o < e; ++o) {
    let e = [];
    if (1 == r[o]) continue;
    for (var a = o; 0 == r[a];) {
      r[a] = !0, e.push(t[a]);
      let i = n[a],
        o = rank_query(n, i, a + 1);
      if (0 == o) throw new AlgorithmError("character_number is zero in inverse BBWT", "construct_inverse_bbw_transform", t);
      if (t.split(i).length + 1 <= o) throw new AlgorithmError("character_number exceeds occurrences in inverse BBWT", "construct_inverse_bbw_transform", t);
      a = select_query(t, i, o)
    }
    const s = construct_necklace_conjugate_transform(e.join(""));
    i.push(s)
  }
  return i.sort(), i.reverse(), i.join("")
}

function random_ternary_string(t) {
  let e = "";
  for (let n = 0; n < t; n++) {
    const t = Math.floor(3 * Math.random());
    e += "abc".charAt(t)
  }
  return e
}

function construct_lz78_factorization(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e).fill(!1),
    r = new Map;
  let i = 0;
  for (; i < e;) {
    let a = "";
    for (let n = i; n < e && (a += t[n], r.has(a)); n++);
    const o = a;
    r.set(o, i), n[i + o.length - 1] = !0, i += o.length
  }
  return n
}

function construct_lzw_factorization(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e).fill(!1),
    r = new Map;
  for (let n = 0; n < e; n++) {
    const e = t[n];
    r.has(e) || r.set(e, r.size)
  }
  for (let i = 0; i < e;) {
    let a = "";
    for (let n = i; n < e; n++)
      if (a += t[n], !r.has(a)) {
        a = a.slice(0, -1);
        break
      } let o = i + a.length - 1;
    if (o >= e) {
      n[e - 1] = !0;
      break
    }
    if (0 == a.length) throw new AlgorithmError("LZW factorization failed to find a valid substring.", "construct_lzw_factorization", {
      text: t
    });
    n[o] = !0, i + a.length < e && (a += t[i + a.length]), r.has(a) || r.set(a, r.size), i = o + 1
  }
  return n
}

function construct_necklace_factorization(t, e) {
  if (!t || !e) return [];
  const n = t.length,
    r = new Array(n).fill(!1);
  let i = 0,
    a = "";
  for (; i < n;) {
    let o = i;
    for (; o < n && 0 == e[o];) o++;
    const s = t.slice(i, o + 1);
    s !== a ? (a = s, r[o] = !0, i = o + 1) : (r[i - 1] = !1, r[o] = !0, i = o + 1)
  }
  return r
}

function construct_odd_maximal_palindromic_length_array(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e).fill(0);
  let r = 0,
    i = 0;
  for (let a = 0; a < e; a++) {
    let o = 2 * r - a;
    for (a < i && (n[a] = Math.min(i - a, n[o])); a - n[a] - 1 >= 0 && a + n[a] + 1 < e && t[a - n[a] - 1] === t[a + n[a] + 1];) n[a]++;
    a + n[a] > i && (r = a, i = a + n[a])
  }
  return n
}

function construct_even_maximal_palindromic_length_array(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e).fill(0);
  let r = 0,
    i = 0;
  for (let a = 0; a < e; a++) {
    let o = 2 * r - a + 1;
    for (a < i && (n[a] = Math.min(i - a, n[o])); a - n[a] - 1 >= 0 && a + n[a] < e && t[a - n[a] - 1] === t[a + n[a]];) n[a]++;
    a + n[a] > i && (r = a - 1, i = a + n[a])
  }
  return n
}

function get_lzend_reference(t, e, n) {
  let r = 0;
  for (; - 1 !== (r = t.indexOf(e, r));) {
    if (n[r + e.length - 1]) return r;
    r += e.length
  }
  return -1
}

function construct_lzend_factorization(t) {
  if (!t) return [];
  const e = t.length,
    n = new Array(e).fill(!1);
  for (let r = 0; r < e;) {
    let i = "",
      a = "";
    const o = t.slice(0, r);
    for (let s = r; s < e && (a += t[s], -1 !== o.indexOf(a)); s++) - 1 !== get_lzend_reference(o, a, n) && (i = a);
    i ? i += t[r + i.length - 1] : i = t[r];
    let s = r + i.length - 1;
    if (s >= e) {
      n[e - 1] = !0;
      break
    }
    n[s] = !0, r = s + 1
  }
  return n
}

function is_stringattractor(t, e) {
  const n = t.length,
    r = new Set(e);
  for (let e = 0; e < n; e++) {
    let i = "";
    for (let a = e; a < n; a++) {
      i += t[a];
      let e = !1;
      for (let a = 0; a + i.length <= n; a++) {
        if (t.slice(a, a + i.length) === i)
          for (let t = a; t < a + i.length; t++)
            if (r.has(t)) {
              e = !0;
              break
            } if (e) break
      }
      if (!e) return !1
    }
  }
  return !0
}

function construct_gamma_factorization(t) {
  if (!t) return [];
  const e = t.length,
    n = new Map;
  for (let r = 0; r < e; r++) {
    let i = "";
    for (let a = r; a < e; a++) i += t[a], n.set(i, (n.get(i) || 0) + 1)
  }
  const r = [];
  for (const [t, e] of n.entries()) {
    let i = !0;
    for (let r = 0; r < t.length && i; r++) {
      const a = t.slice(0, r) + t.slice(r + 1);
      a.length > 0 && n.get(a) <= e && (i = !1)
    }
    i && r.push(t)
  }
  const i = r.map(n => {
      const r = new Set;
      for (let i = 0; i + n.length <= e; i++)
        if (t.slice(i, i + n.length) === n)
          for (let t = i; t < i + n.length; t++) r.add(t);
      return r
    }),
    a = [...Array(e).keys()];
  const o = function t(e, n, r) {
      if (r.size > 0 && n.size >= r.size) return new Set;
      let o = !0;
      for (const t of i) {
        let e = !1;
        for (const r of n)
          if (t.has(r)) {
            e = !0;
            break
          } if (!e) {
          o = !1;
          break
        }
      }
      return o ? new Set(n) : e === a.length ? new Set : (n.add(a[e]), r = (s = t(e + 1, n, r)).size > 0 ? s : r, n.delete(a[e]), r = (s = t(e + 1, n, r)).size > 0 ? s : r);
      var s
    }(0, new Set, new Set),
    s = new Array(e).fill(!1);
  return o.forEach(t => s[t] = !0), s
}

function factorization_to_positions(t) {
  const e = [];
  for (let n = 0; n < t.length; n++) t[n] && e.push(n);
  return e
}
var structure_flags = {
  counter_sigma: 1,
  suffix_array: 2,
  border_array: 4,
  first_array: 8,
  index_array: 16,
  rotation_array: 32,
  sl_string: 64,
  lpf_array: 128,
  lpnf_array: 256,
  lnf_array: 512,
  necklace_conjugate_transform: 1024,
  invert_transform: 2048,
  revert_transform: 4096,
  lz78_factorization: 8192,
  lzw_factorization: 16384,
  odd_maximal_palindromic_length_array: 32768,
  even_maximal_palindromic_length_array: 65536,
  lzend_factorization: 131072,
  gamma_factorization: 262144,
  inverse_suffix_array: 524288,
  lcp_array: 1048576,
  counter_period: 2097152,
  counter_exponent: 4194304,
  counter_regularity: 8388608,
  bw_transform: 16777216,
  lzss_factorization: 33554432,
  lz77_factorization: 67108864,
  lzssno_factorization: 134217728,
  reverse_lzss_factorization: 268435456,
  phi_array: 536870912,
  inverse_phi_array: 1073741824,
  psi_array: -2147483648,
  lyndon_factorization: 1,
  nss_array: 2,
  pss_array: 4,
  counter_lcp_array: 8,
  plcp_array: 16,
  substring_complexity: 32,
  lf_array: 64,
  circular_suffix_array: 128,
  necklace_factorization: 256,
  lyndon_array: 512,
  lexparse_factorization: 1024,
  counter_delta: 2048,
  counter_delta_argmax: 4096,
  inverse_circular_suffix_array: 8192,
  bbw_indices: 16384,
  bbw_transform: 32768,
  inverse_bbw_transform: 65536
};

function build_ds(t, e = -1) {
  t.length;
  var n = {};
  e & structure_flags.counter_sigma && (n.counter_sigma = !0), e & structure_flags.suffix_array && (n.suffix_array = !0), e & structure_flags.border_array && (n.border_array = !0), e & structure_flags.first_array && (n.first_array = !0), e & structure_flags.index_array && (n.index_array = !0), e & structure_flags.rotation_array && (n.rotation_array = !0), e & structure_flags.sl_string && (n.sl_string = !0), e & structure_flags.lpf_array && (n.lpf_array = !0), e & structure_flags.lpnf_array && (n.lpnf_array = !0), e & structure_flags.lnf_array && (n.lnf_array = !0), e & structure_flags.necklace_conjugate_transform && (n.necklace_conjugate_transform = !0), e & structure_flags.invert_transform && (n.invert_transform = !0), e & structure_flags.revert_transform && (n.revert_transform = !0), e & structure_flags.lz78_factorization && (n.lz78_factorization = !0), e & structure_flags.lzw_factorization && (n.lzw_factorization = !0), e & structure_flags.odd_maximal_palindromic_length_array && (n.odd_maximal_palindromic_length_array = !0), e & structure_flags.even_maximal_palindromic_length_array && (n.even_maximal_palindromic_length_array = !0), e & structure_flags.lzend_factorization && (n.lzend_factorization = !0), e & structure_flags.gamma_factorization && (n.gamma_factorization = !0), e & structure_flags.inverse_suffix_array && (n.inverse_suffix_array = !0), e & structure_flags.lcp_array && (n.lcp_array = !0), e & structure_flags.counter_period && (n.counter_period = !0), e & structure_flags.counter_exponent && (n.counter_exponent = !0), e & structure_flags.counter_regularity && (n.counter_regularity = !0), e & structure_flags.bw_transform && (n.bw_transform = !0), e & structure_flags.lzss_factorization && (n.lzss_factorization = !0), e & structure_flags.lz77_factorization && (n.lz77_factorization = !0), e & structure_flags.lzssno_factorization && (n.lzssno_factorization = !0), e & structure_flags.reverse_lzss_factorization && (n.reverse_lzss_factorization = !0), e & structure_flags.phi_array && (n.phi_array = !0), e & structure_flags.inverse_phi_array && (n.inverse_phi_array = !0), e & structure_flags.psi_array && (n.psi_array = !0), e & structure_flags.lyndon_factorization && (n.lyndon_factorization = !0), e & structure_flags.nss_array && (n.nss_array = !0), e & structure_flags.pss_array && (n.pss_array = !0), e & structure_flags.counter_lcp_array && (n.counter_lcp_array = !0), e & structure_flags.plcp_array && (n.plcp_array = !0), e & structure_flags.substring_complexity && (n.substring_complexity = !0), e & structure_flags.lf_array && (n.lf_array = !0), e & structure_flags.circular_suffix_array && (n.circular_suffix_array = !0), e & structure_flags.necklace_factorization && (n.necklace_factorization = !0), e & structure_flags.lyndon_array && (n.lyndon_array = !0), e & structure_flags.lexparse_factorization && (n.lexparse_factorization = !0), e & structure_flags.counter_delta && (n.counter_delta = !0), e & structure_flags.counter_delta_argmax && (n.counter_delta_argmax = !0), e & structure_flags.inverse_circular_suffix_array && (n.inverse_circular_suffix_array = !0), e & structure_flags.bbw_indices && (n.bbw_indices = !0), e & structure_flags.bbw_transform && (n.bbw_transform = !0), e & structure_flags.inverse_bbw_transform && (n.inverse_bbw_transform = !0);
  for (var r = !0; r;) r = !1, n.inverse_suffix_array && !n.suffix_array && (n.suffix_array = !0, r = !0), n.lcp_array && !n.suffix_array && (n.suffix_array = !0, r = !0), n.counter_period && !n.border_array && (n.border_array = !0, r = !0), n.counter_exponent && !n.border_array && (n.border_array = !0, r = !0), n.counter_regularity && !n.border_array && (n.border_array = !0, r = !0), n.bw_transform && !n.rotation_array && (n.rotation_array = !0, r = !0), n.lzss_factorization && !n.lpf_array && (n.lpf_array = !0, r = !0), n.lz77_factorization && !n.lpf_array && (n.lpf_array = !0, r = !0), n.lzssno_factorization && !n.lpnf_array && (n.lpnf_array = !0, r = !0), n.reverse_lzss_factorization && !n.lnf_array && (n.lnf_array = !0, r = !0), n.phi_array && !n.suffix_array && (n.suffix_array = !0, r = !0), n.phi_array && !n.inverse_suffix_array && (n.inverse_suffix_array = !0, r = !0), n.inverse_phi_array && !n.suffix_array && (n.suffix_array = !0, r = !0), n.inverse_phi_array && !n.inverse_suffix_array && (n.inverse_suffix_array = !0, r = !0), n.psi_array && !n.suffix_array && (n.suffix_array = !0, r = !0), n.psi_array && !n.inverse_suffix_array && (n.inverse_suffix_array = !0, r = !0), n.lyndon_factorization && !n.inverse_suffix_array && (n.inverse_suffix_array = !0, r = !0), n.nss_array && !n.inverse_suffix_array && (n.inverse_suffix_array = !0, r = !0), n.pss_array && !n.inverse_suffix_array && (n.inverse_suffix_array = !0, r = !0), n.counter_lcp_array && !n.lcp_array && (n.lcp_array = !0, r = !0), n.plcp_array && !n.inverse_suffix_array && (n.inverse_suffix_array = !0, r = !0), n.plcp_array && !n.lcp_array && (n.lcp_array = !0, r = !0), n.substring_complexity && !n.lcp_array && (n.lcp_array = !0, r = !0), n.lf_array && !n.first_array && (n.first_array = !0, r = !0), n.lf_array && !n.bw_transform && (n.bw_transform = !0, r = !0), n.circular_suffix_array && !n.lyndon_factorization && (n.lyndon_factorization = !0, r = !0), n.necklace_factorization && !n.lyndon_factorization && (n.lyndon_factorization = !0, r = !0), n.lyndon_array && !n.nss_array && (n.nss_array = !0, r = !0), n.lexparse_factorization && !n.plcp_array && (n.plcp_array = !0, r = !0), n.counter_delta && !n.substring_complexity && (n.substring_complexity = !0, r = !0), n.counter_delta_argmax && !n.substring_complexity && (n.substring_complexity = !0, r = !0), n.inverse_circular_suffix_array && !n.circular_suffix_array && (n.circular_suffix_array = !0, r = !0), n.bbw_indices && !n.lyndon_factorization && (n.lyndon_factorization = !0, r = !0), n.bbw_indices && !n.circular_suffix_array && (n.circular_suffix_array = !0, r = !0), n.bbw_transform && !n.bbw_indices && (n.bbw_indices = !0, r = !0), n.inverse_bbw_transform && !n.bbw_transform && (n.bbw_transform = !0, r = !0);
  const i = t,
    a = t.length;
  var o, s, c, l, u, f, h, d, p, g, _, m, y, v, b, x, w, T, S, q, k, C, A, E, z, L, D, P, j, B, I, N, M, W, O, R, F, H, $, V, G, U, X, Y, Z, J, K, Q, tt;
  return n.counter_sigma && (o = count_sigma(i)), n.suffix_array && (s = construct_suffix_array(i)), n.border_array && (c = construct_border_array(i)), n.first_array && (l = construct_first_array(i)), n.index_array && (u = construct_index_array(a)), n.rotation_array && (f = construct_rotation_array(i)), n.sl_string && (h = construct_sl_string(i)), n.lpf_array && (d = construct_lpf_array(i)), n.lpnf_array && (p = construct_lpnf_array(i)), n.lnf_array && (g = construct_lnf_array(i)), n.necklace_conjugate_transform && (_ = construct_necklace_conjugate_transform(i)), n.invert_transform && (m = construct_invert_transform(i)), n.revert_transform && (y = construct_revert_transform(i)), n.lz78_factorization && (v = construct_lz78_factorization(i)), n.lzw_factorization && (b = construct_lzw_factorization(i)), n.odd_maximal_palindromic_length_array && (x = construct_odd_maximal_palindromic_length_array(i)), n.even_maximal_palindromic_length_array && (w = construct_even_maximal_palindromic_length_array(i)), n.lzend_factorization && (T = construct_lzend_factorization(i)), n.gamma_factorization && (S = construct_gamma_factorization(i)), n.inverse_suffix_array && (q = construct_inverse_suffix_array(s)), n.lcp_array && (k = construct_lcp_array(i, s)), n.counter_period && (C = count_period(c)), n.counter_exponent && (A = count_exponent(c)), n.counter_regularity && (E = count_regularity(c)), n.bw_transform && (z = construct_bw_transform(i, f)), n.lzss_factorization && (L = construct_lzss_factorization(d)), n.lz77_factorization && (D = construct_lz77_factorization(d)), n.lzssno_factorization && (P = construct_lzssno_factorization(p)), n.reverse_lzss_factorization && (j = construct_reverse_lzss_factorization(g)), n.phi_array && (B = construct_phi_array(s, q)), n.inverse_phi_array && (I = construct_inverse_phi_array(s, q)), n.psi_array && (N = construct_psi_array(s, q)), n.lyndon_factorization && (M = construct_lyndon_factorization(i, q)), n.nss_array && (W = construct_nss_array(q)), n.pss_array && (O = construct_pss_array(q)), n.counter_lcp_array && (R = count_lcp_array(k)), n.plcp_array && (F = construct_plcp_array(q, k)), n.substring_complexity && (H = construct_substring_complexity(k)), n.lf_array && ($ = construct_lf_array(l, z)), n.circular_suffix_array && (V = construct_circular_suffix_array(i, M)), n.necklace_factorization && (G = construct_necklace_factorization(i, M)), n.lyndon_array && (U = construct_lyndon_array(W)), n.lexparse_factorization && (X = construct_lexparse_factorization(F)), n.counter_delta && (Y = count_delta(H)), n.counter_delta_argmax && (Z = count_delta_argmax(H)), n.inverse_circular_suffix_array && (J = construct_inverse_circular_suffix_array(V)), n.bbw_indices && (K = construct_bbw_indices(M, V)), n.bbw_transform && (Q = construct_bbw_transform(i, K)), n.inverse_bbw_transform && (tt = construct_inverse_bbw_transform(Q)), {
    counter_sigma: o,
    suffix_array: s,
    border_array: c,
    first_array: l,
    index_array: u,
    rotation_array: f,
    sl_string: h,
    lpf_array: d,
    lpnf_array: p,
    lnf_array: g,
    necklace_conjugate_transform: _,
    invert_transform: m,
    revert_transform: y,
    lz78_factorization: v,
    lzw_factorization: b,
    odd_maximal_palindromic_length_array: x,
    even_maximal_palindromic_length_array: w,
    lzend_factorization: T,
    gamma_factorization: S,
    inverse_suffix_array: q,
    lcp_array: k,
    counter_period: C,
    counter_exponent: A,
    counter_regularity: E,
    bw_transform: z,
    lzss_factorization: L,
    lz77_factorization: D,
    lzssno_factorization: P,
    reverse_lzss_factorization: j,
    phi_array: B,
    inverse_phi_array: I,
    psi_array: N,
    lyndon_factorization: M,
    nss_array: W,
    pss_array: O,
    counter_lcp_array: R,
    plcp_array: F,
    substring_complexity: H,
    lf_array: $,
    circular_suffix_array: V,
    necklace_factorization: G,
    lyndon_array: U,
    lexparse_factorization: X,
    counter_delta: Y,
    counter_delta_argmax: Z,
    inverse_circular_suffix_array: J,
    bbw_indices: K,
    bbw_transform: Q,
    inverse_bbw_transform: tt,
    counter_text: number_of_runs(i),
    counter_lyndon_factorization: number_of_factors(M),
    counter_lzss_factorization: number_of_factors(L),
    counter_lzssno_factorization: number_of_factors(P),
    counter_lz77_factorization: number_of_factors(D),
    counter_reverse_lzss_factorization: number_of_factors(j),
    counter_lexparse_factorization: number_of_factors(X),
    counter_lz78_factorization: number_of_factors(v),
    counter_lzw_factorization: number_of_factors(b),
    counter_necklace_factorization: number_of_factors(G),
    counter_lzend_factorization: number_of_factors(T),
    counter_gamma_factorization: number_of_factors(S),
    counter_bw_transform: number_of_runs(z),
    counter_necklace_conjugate_transform: number_of_runs(_),
    counter_invert_transform: number_of_runs(m),
    counter_revert_transform: number_of_runs(y),
    counter_bbw_transform: number_of_runs(Q),
    counter_inverse_bbw_transform: number_of_runs(tt)
  }
}
const citations = {};

function generate_fibonacci_word(t) {
  if (t <= 0) return "b";
  return [...generate_fibonacci_word(t - 1)].map(t => "a" == t ? "ab" : "a").join("")
}

function generate_tribonacci_word(t) {
  if (t <= 0) return "a";
  return [...generate_tribonacci_word(t - 1)].map(t => "a" == t ? "ab" : "b" == t ? "ac" : "a").join("")
}

function generate_thue_morse_word(t) {
  if (t <= 0) return "a";
  const e = generate_thue_morse_word(t - 1);
  return e + [...e].map(t => "a" == t ? "b" : "a").join("")
}

function generate_mephisto_waltz_word(t) {
  if (t <= 0) return "a";
  return [...generate_mephisto_waltz_word(t - 1)].map(t => "a" == t ? "aab" : "bba").join("")
}

function generate_vtm_word(t) {
  if (t <= 0) return "a";
  return [...generate_vtm_word(t - 1)].map(t => "a" == t ? "abc" : "b" == t ? "ac" : "b").join("")
}

function generate_sierpinski_word(t) {
  if (t <= 0) return "a";
  return [...generate_sierpinski_word(t - 1)].map(t => "a" == t ? "aba" : "bbb").join("")
}

function generate_pell_word(t) {
  if (t <= 0) return "a";
  return [...generate_pell_word(t - 1)].map(t => "a" == t ? "aab" : "a").join("")
}

function generate_chacon_word(t) {
  if (t <= 0) return "a";
  return [...generate_chacon_word(t - 1)].map(t => "a" == t ? "aaba" : "b").join("")
}

function generate_von_neumann_word(t) {
  if (t <= 0) return "a";
  return [...generate_von_neumann_word(t - 1)].map(t => "a" == t ? "aab" : "b").join("")
}

function rudin_shapiro_preword(t) {
  if (t <= 0) return "a";
  return [...rudin_shapiro_preword(t - 1)].map(t => "a" == t ? "ab" : "b" == t ? "ac" : "c" == t ? "db" : "dc").join("")
}

function generate_rudin_shapiro_word(t) {
  if (t <= 0) return "a";
  return [...rudin_shapiro_preword(t)].map(t => "a" == t || "b" == t ? "a" : "b").join("")
}

function baum_sweet_preword(t) {
  if (t <= 0) return "a";
  return [...baum_sweet_preword(t - 1)].map(t => "a" == t ? "ab" : "b" == t ? "cb" : "c" == t ? "bd" : "dd").join("")
}

function generate_baum_sweet_word(t) {
  if (t <= 0) return "a";
  return [...baum_sweet_preword(t)].map(t => "c" == t || "d" == t ? "a" : t).join("")
}

function generate_kolakoski_word(t) {
  if (t <= 0) return "ab";
  const e = generate_kolakoski_word(t - 1);
  let n = "";
  for (let t = 0; t < e.length; ++t) n += t % 2 == 0 ? "a" == e[t] ? "a" : "aa" : "a" == e[t] ? "b" : "bb";
  return n
}
citations.allouche03automatic = 'Jean-Paul Allouche and Jeffrey Shallit. <em><a href="https://doi.org/10.1017/CBO9780511546563">Automatic sequences: Theory, applications, generalizations</a></em>. Cambridge University Press, 2003.', citations.manber93sa = 'Udi Manber and Eugene W. Myers. <a href="https://doi.org/10.1137/0222058">Suffix arrays: <span>A</span> new method for on-line string searches</a>. <em><span>SIAM</span> J. Comput.</em>, 22(5):935–948, 1993.', citations.burrows94bwt = "Michael Burrows and David J. Wheeler. A block sorting lossless data compression algorithm. Technical report, 124, Digital Equipment Corporation, Palo Alto, California, 1994.", citations.burrows94bwt = "Michael Burrows and David J. Wheeler. A block sorting lossless data compression algorithm. Technical report, 124, Digital Equipment Corporation, Palo Alto, California, 1994.", citations.manber93sa = 'Udi Manber and Eugene W. Myers. <a href="https://doi.org/10.1137/0222058">Suffix arrays: <span>A</span> new method for on-line string searches</a>. <em><span>SIAM</span> J. Comput.</em>, 22(5):935–948, 1993.', citations.karkkainen09plcp = 'Juha Kärkkäinen, Giovanni Manzini, and Simon J. Puglisi. <a href="https://doi.org/10.1007/978-3-642-02441-2_17">Permuted longest-common-prefix array</a>. In <em>Proc. CPM</em>, volume 5577, pages 181–192. 2009.', citations.karkkainen09plcp = 'Juha Kärkkäinen, Giovanni Manzini, and Simon J. Puglisi. <a href="https://doi.org/10.1007/978-3-642-02441-2_17">Permuted longest-common-prefix array</a>. In <em>Proc. CPM</em>, volume 5577, pages 181–192. 2009.', citations.grossi05csa = 'Roberto Grossi and Jeffrey Scott Vitter. <a href="https://doi.org/10.1137/S0097539702402354">Compressed suffix arrays and suffix trees with applications to text indexing and string matching</a>. <em><span>SIAM</span> J. Comput.</em>, 35(2):378–407, 2005.', citations.chen58lyndon = "Kuo Tsai Chen, Ralph H. Fox, and Roger C. Lyndon. Free differential calculus, <span>IV</span>. <span>T</span>he quotient groups of the lower central series. <em>Annals of Mathematics</em>, 68(1):81–95, 1958.", citations.raskhodnikova13sublinear = 'Sofya Raskhodnikova, Dana Ron, Ronitt Rubinfeld, and Adam D. Smith. <a href="https://doi.org/10.1007/s00453-012-9618-6">Sublinear algorithms for approximating string compressibility</a>. <em>Algorithmica</em>, 65(3):685–709, 2013.', citations.raskhodnikova13sublinear = 'Sofya Raskhodnikova, Dana Ron, Ronitt Rubinfeld, and Adam D. Smith. <a href="https://doi.org/10.1007/s00453-012-9618-6">Sublinear algorithms for approximating string compressibility</a>. <em>Algorithmica</em>, 65(3):685–709, 2013.', citations.raskhodnikova13sublinear = 'Sofya Raskhodnikova, Dana Ron, Ronitt Rubinfeld, and Adam D. Smith. <a href="https://doi.org/10.1007/s00453-012-9618-6">Sublinear algorithms for approximating string compressibility</a>. <em>Algorithmica</em>, 65(3):685–709, 2013.', citations.burrows94bwt = "Michael Burrows and David J. Wheeler. A block sorting lossless data compression algorithm. Technical report, 124, Digital Equipment Corporation, Palo Alto, California, 1994.", citations.nong11sais = 'Ge Nong, Sen Zhang, and Wai Hong Chan. <a href="https://doi.org/10.1109/TC.2010.188">Two efficient algorithms for linear time suffix array construction</a>. <em><span>IEEE</span> Trans. Computers</em>, 60(10):1471–1484, 2011.', citations.storer82lzss = 'James A. Storer and Thomas G. Szymanski. <a href="https://doi.org/10.1145/322344.322346">Data compression via textural substitution</a>. <em>J. <span>ACM</span></em>, 29(4):928–951, 1982.', citations.storer82lzss = 'James A. Storer and Thomas G. Szymanski. <a href="https://doi.org/10.1145/322344.322346">Data compression via textural substitution</a>. <em>J. <span>ACM</span></em>, 29(4):928–951, 1982.', citations.ziv77lz = 'Jacob Ziv and Abraham Lempel. <a href="https://doi.org/10.1109/TIT.1977.1055714">A universal algorithm for sequential data compression</a>. <em><span>IEEE</span> Trans. Information Theory</em>, 23(3):337–343, 1977.', citations.storer82lzss = 'James A. Storer and Thomas G. Szymanski. <a href="https://doi.org/10.1145/322344.322346">Data compression via textural substitution</a>. <em>J. <span>ACM</span></em>, 29(4):928–951, 1982.', citations.navarro21approximation = 'Gonzalo Navarro, Carlos Ochoa, and Nicola Prezza. <a href="https://doi.org/10.1109/TIT.2020.3042746">On the approximation ratio of ordered parsings</a>. <em><span>IEEE</span> Trans. Inf. Theory</em>, 67(2):1008–1026, 2021.', citations.franek16algorithms = "Frantisek Franek, A. S. M. Sohidull Islam, Mohammad Sohel Rahman, and William F. Smyth. Algorithms to compute the <span>Lyndon</span> array. In <em>Proc. PSC</em>, pages 172–184. 2016.", citations.hon13spaceefficient = 'Wing-Kai Hon, Tsung-Han Ku, Rahul Shah, and Sharma V. Thankachan. <a href="https://doi.org/10.1007/978-3-642-38905-4\\_15">Space-efficient construction algorithm for the circular suffix tree</a>. In <em>Proc. CPM</em>, volume 7922, pages 142–152. 2013.', citations.hon13spaceefficient = 'Wing-Kai Hon, Tsung-Han Ku, Rahul Shah, and Sharma V. Thankachan. <a href="https://doi.org/10.1007/978-3-642-38905-4\\_15">Space-efficient construction algorithm for the circular suffix tree</a>. In <em>Proc. CPM</em>, volume 7922, pages 142–152. 2013.', citations.bannai25survey = 'Hideo Bannai, Dominik Köppl, and Zsuzsanna Lipták. <a href="https://doi.org/10.4230/OASIcs.Manzini.2">A survey of the bijective <span>Burrows</span>–<span>Wheeler</span> transform</a>. In <em>The expanding world of compressed data: A festschrift for <span>Giovanni</span> <span>Manzini</span>’s 60th birthday</em>, volume 131, pages 2:1–2:26. 2025.', citations.bannai25survey = 'Hideo Bannai, Dominik Köppl, and Zsuzsanna Lipták. <a href="https://doi.org/10.4230/OASIcs.Manzini.2">A survey of the bijective <span>Burrows</span>–<span>Wheeler</span> transform</a>. In <em>The expanding world of compressed data: A festschrift for <span>Giovanni</span> <span>Manzini</span>’s 60th birthday</em>, volume 131, pages 2:1–2:26. 2025.', citations.bannai25survey = 'Hideo Bannai, Dominik Köppl, and Zsuzsanna Lipták. <a href="https://doi.org/10.4230/OASIcs.Manzini.2">A survey of the bijective <span>Burrows</span>–<span>Wheeler</span> transform</a>. In <em>The expanding world of compressed data: A festschrift for <span>Giovanni</span> <span>Manzini</span>’s 60th birthday</em>, volume 131, pages 2:1–2:26. 2025.', citations.ziv78lz = 'Jacob Ziv and Abraham Lempel. <a href="https://doi.org/10.1109/TIT.1978.1055934">Compression of individual sequences via variable-rate coding</a>. <em><span>IEEE</span> Trans. Information Theory</em>, 24(5):530–536, 1978.', citations.welch84lzw = 'Terry A. Welch. <a href="https://doi.org/10.1109/MC.1984.1659158">A technique for high-performance data compression</a>. <em><span>IEEE</span> Computer</em>, 17(6):8–19, 1984.', citations.chen58lyndon = "Kuo Tsai Chen, Ralph H. Fox, and Roger C. Lyndon. Free differential calculus, <span>IV</span>. <span>T</span>he quotient groups of the lower central series. <em>Annals of Mathematics</em>, 68(1):81–95, 1958.", citations.manacher75new = 'Glenn K. Manacher. <a href="https://doi.org/10.1145/321892.321896">A new linear-time "on-line" algorithm for finding the smallest initial palindrome of a string</a>. <em>J. <span>ACM</span></em>, 22(3):346–351, 1975.', citations.manacher75new = 'Glenn K. Manacher. <a href="https://doi.org/10.1145/321892.321896">A new linear-time "on-line" algorithm for finding the smallest initial palindrome of a string</a>. <em>J. <span>ACM</span></em>, 22(3):346–351, 1975.', citations.kreft13lzend = 'Sebastian Kreft and Gonzalo Navarro. <a href="https://doi.org/10.1016/j.tcs.2012.02.006">On compressing and indexing repetitive sequences</a>. <em>Theor. Comput. Sci.</em>, 483:115–133, 2013.', citations.kempa18stringattractors = 'Dominik Kempa and Nicola Prezza. <a href="https://doi.org/10.1145/3188745.3188814">At the roots of dictionary compression: String attractors</a>. In <em>Proc. STOC</em>, pages 827–840. 2018.';
const string_generators = {
    fibonacci_word: generate_fibonacci_word,
    tribonacci_word: generate_tribonacci_word,
    thue_morse_word: generate_thue_morse_word,
    mephisto_waltz_word: generate_mephisto_waltz_word,
    vtm_word: generate_vtm_word,
    sierpinski_word: generate_sierpinski_word,
    pell_word: generate_pell_word,
    chacon_word: generate_chacon_word,
    von_neumann_word: generate_von_neumann_word,
    rudin_shapiro_word: generate_rudin_shapiro_word,
    baum_sweet_word: generate_baum_sweet_word,
    kolakoski_word: generate_kolakoski_word
  },
  tutorials = {};

function number_of_runs(t) {
  if (!t) return 0;
  let e = 1,
    n = t[0];
  for (let r = 1; r < t.length; ++r) t[r] !== n && (e++, n = t[r]);
  return e
}

function number_of_factors(t) {
  return t ? t.reduce((t, e) => t + (e ? 1 : 0), 0) : 0
}

function pad_right(t, e, n) {
  if (t.length >= n || 0 === e.length) return t;
  const r = Math.ceil((n - t.length) / e.length);
  return t + e.repeat(r)
}

function pad_left(t, e, n) {
  if (t.length >= n || 0 === e.length) return t;
  const r = Math.ceil((n - t.length) / e.length);
  return e.repeat(r) + t
}

function increment_array(t, e = 1) {
  return t.map(t => t + e)
}

function replace_invalid_position(t, e) {
  return t.map(t => t >= e ? "-" : t)
}

function prettify_string(t, e = " ", n = 0, r = !0) {
  t = t.split("\0").join("$");
  const i = r ? String(t.length + n - 1).length : 0;
  let a = e;
  return r || (a = ""), t.split("").map(t => pad_left(t, " ", i)).join(a)
}

function prettify_array(t, e = " ", n = 0) {
  const r = ("" + Math.max(0, t.length + n - 1)).toString().length;
  return t.map(t => pad_left("" + t, " ", r)).join(e)
}

function prettify_factorization(t, e, n = " ", r = 0) {
  const i = t.length,
    a = String(Math.max(0, i + r - 1)).length;
  let o = "";
  for (let r = 0; r < i; ++r) {
    o += pad_left(r === i - 1 && "\0" === t[r] ? "$" : t[r], " ", a), o += !0 === e[r] ? "|" + n.substring(1) : n
  }
  return o
}

function encodeWhitespaces(t) {
  return t.replace(/\r/g, "␍").replace(/\n/g, "↵").replace(/\t/g, "␉").replace(/\v/g, "␋").replace(/\f/g, "␌").replace(/ /g, "⎵")
}

function decodeWhitespaces(t) {
  return t.replace(/\u240d/g, "\r").replace(/\u21b5/g, "\n").replace(/\u2409/g, "\t").replace(/\u240b/g, "\v").replace(/\u240c/g, "\f").replace(/\u23b5/g, " ")
}

function repeat(t, e) {
  let n = "";
  for (; e-- > 0;) n += t;
  return n
}

function escapeLatex(t) {
  return String(t).replace(/\\/g, "\\textbackslash{}").replace(/([#$%&_{}])/g, "\\$1")
}

function isBoolRow(t) {
  return "boolean" == typeof t.data[0]
}

function isStringRow(t) {
  return "string" == typeof t.data[0]
}

function partitionsFromBool(t) {
  const e = [];
  let n = 0;
  for (let r = 0; r < t.length; r++) n++, t[r] && (e.push(n), n = 0);
  return e
}

function export_latex(t) {
  const e = t[0].data.length,
    n = t.find(isStringRow);
  if (!n) throw new Error("Row T (string[]) required");
  const r = n.data,
    i = [];
  i.push(`\\begin{tabular}{l|${"c".repeat(e)}}`), i.push("\\hline");
  for (const n of t) {
    let t = `${escapeLatex(n.name)} & `;
    if (isBoolRow(n)) {
      const e = partitionsFromBool(n.data);
      let i = 0;
      for (let n = 0; n < e.length; n++) {
        const a = e[n];
        let o = "";
        for (let t = 0; t < a; t++) o += escapeLatex(r[i++]);
        t += `\\multicolumn{${a}}{c}{${o}}`, n !== e.length - 1 && (t += " & ")
      }
    } else
      for (let r = 0; r < e; r++) t += escapeLatex(n.data[r]), r !== e - 1 && (t += " & ");
    t += " \\\\", i.push(t)
  }
  return i.push("\\hline"), i.push("\\end{tabular}"), i.join("\n")
}

function export_markdown(t) {
  const e = t[0].data.length,
    n = t.find(isStringRow);
  if (!n) throw new Error("Row T (string[]) required for boolean partitions");
  const r = n.data,
    i = [],
    a = [" "];
  for (let t = 0; t < e; t++) a.push(String(t + 1));
  i.push("|" + a.join("|") + "|"), i.push("|" + repeat("---|", e + 1));
  for (const n of t) {
    const t = [n.name];
    if (isBoolRow(n)) {
      let i = "";
      for (let t = 0; t < e; t++) i += r[t], n.data[t] && (i += "|");
      t.push(i)
    } else
      for (let r = 0; r < e; r++) t.push(String(n.data[r]));
    i.push("|" + t.join("|") + "|")
  }
  return i.join("\n")
}

function escape_csv(t) {
  const e = String(t);
  return /[",\n]/.test(e) ? `"${e.replace(/"/g,'""')}"` : e
}

function export_csv(t) {
  const e = t[0].data.length,
    n = [];
  for (const r of t) {
    const t = [];
    t.push(r.name);
    for (let n = 0; n < e; n++) t.push(String(r.data[n]));
    n.push(t.map(escape_csv).join(","))
  }
  return n.join("\n")
}
tutorials.fibonacci_word = {
  title: "Fibonacci",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to ab, b \\to a \\} \\) on the letter 'b'",
  oeis: "A003849",
  wikipedia: "Fibonacci_word"
}, tutorials.tribonacci_word = {
  title: "Tribonacci",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to ab, b \\to ac, c \\to a \\} \\) on the letter 'a'",
  oeis: "A080843",
  wikipedia: "Tribonacci_word"
}, tutorials.thue_morse_word = {
  title: "Thue-Morse",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to ab, b \\to ba \\} \\) on the letter 'a'",
  oeis: "A010060",
  wikipedia: "Thue-Morse_sequence"
}, tutorials.mephisto_waltz_word = {
  title: "Mephisto-Waltz",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aab, b \\to bba \\} \\) on the letter 'a'",
  oeis: "A064990",
  cite: "allouche03automatic"
}, tutorials.vtm_word = {
  title: "vtm",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to abc, b \\to ac, c \\to b \\} \\) on the letter 'a'"
}, tutorials.sierpinski_word = {
  title: "Sierpinski",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aba, b \\to bbb \\} \\) on the letter 'a'",
  oeis: "A316829"
}, tutorials.pell_word = {
  title: "Pell",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aab, b \\to a \\} \\) on the letter 'a'",
  oeis: "A171588",
  wikipedia: "Pell_number"
}, tutorials.chacon_word = {
  title: "Chacon",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aaba, b \\to b \\} \\) on the letter 'a'",
  oeis: "A049320"
}, tutorials.von_neumann_word = {
  title: "Neumannn",
  content: "Pure morphic word generated by the morphism \\( \\{ a \\to aab, b \\to b \\} \\) on the letter 'a'",
  oeis: "A308187"
}, tutorials.rudin_shapiro_word = {
  title: "Rudin-Shapiro",
  content: "Morphic word generated by the morphism \\( \\{ a \\to ab, b \\to ac, c \\to db, d \\to dc \\} \\) followed by the coding \\( \\{ a,b \\to a; c,d \\to b \\} \\) on the letter 'a'",
  oeis: "A020987",
  wikipedia: "Rudin–Shapiro_sequence"
}, tutorials.baum_sweet_word = {
  title: "Baum-Sweet",
  content: "Word defined by setting the \\(j\\)-th letter to 'b' if the binary representation of \\(j\\) contains no block of consecutive 0s of odd length, and to 'a' otherwise.",
  oeis: "A086747",
  wikipedia: "Baum–Sweet_sequence"
}, tutorials.kolakoski_word = {
  title: "Kolakoski",
  content: "Self-generating word over the alphabet {a,b} where 'a' represents 1 and 'b' represents 2. The word starts with \"ab\" and the lengths of consecutive runs are given by the word itself.",
  oeis: "A000002",
  wikipedia: "Kolakoski_sequence"
}, tutorials.sigma = {
  title: "&sigma;",
  content: "The shortest period of a string is the smallest positive integer such that the string is a prefix of an infinite repetition of the prefix of that length. Concretely, the shortest period \\(p\\) of the text \\(T\\) is the length of the shortest prefix \\(P\\) of \\(T\\) such that \\(T\\) is a prefix of \\(P^{k}\\) for some integer \\(k \\geq 1\\).",
  wikipedia: "Alphabet_(formal_languages)"
}, tutorials.period = {
  title: "p",
  content: "The shortest period of a string is the smallest positive integer such that the string is a prefix of an infinite repetition of the prefix of that length. Concretely, the shortest period \\(p\\) of the text \\(T\\) is the length of the shortest prefix \\(P\\) of \\(T\\) such that \\(T\\) is a prefix of \\(P^{k}\\) for some integer \\(k \\geq 1\\).",
  wikipedia: "Periodic_sequence"
}, tutorials.exponent = {
  title: "e",
  content: "The exponent of a string is the division of the string's length by its shortest period, representing how many times the shortest period needs to be repeated to form the string. Formally, the exponent of the text \\(T\\) is defined as the length of \\(T\\) divided by the length of its shortest period \\(p\\), i.e., \\(\\frac{|T|}{p}\\).",
  wikipedia: "Periodic_sequence"
}, tutorials.regularity = {
  title: "R",
  content: "The regularity type of a string classifies it based on its periodic structure. A string can be categorized as unbordered, primitive, square, or non-primitive based on its borders and periods. Specifically, a string is unbordered if it has no proper border, primitive if it cannot be expressed as a repetition of a smaller substring, square if it is formed by repeating a substring exactly twice, and non-primitive if it can be expressed as a repetition of a smaller substring more than twice."
}, tutorials.suffix_array = {
  title: "SA",
  content: "The suffix array sorts the entry indices of a string based on the lexicographical order of their corresponding suffixes. Formally, the suffix array \\(\\mathsf{SA}\\) of the text \\(T[1..n]\\) is an array of integers representing the starting indices of all the suffixes of \\(T\\), sorted in lexicographical order. It obeys that \\(T[\\mathsf{SA}[i]..n] \\prec T[\\mathsf{SA}[i+1]..n]\\) for all text positions \\(i \\in [1..n-1]\\).",
  cite: "manber93sa",
  wikipedia: "Suffix_array"
}, tutorials.border_array = {
  title: "B",
  content: "The border array of a string stores the lengths of the longest borders for each prefix of the string. A border of a string is defined as a substring that is both a proper prefix and a proper suffix. Formally, the border array \\(\\mathsf{B}\\) for a text \\(T[1..n]\\) is an array where each entry \\(\\mathsf{B}[i]\\) represents the length of the longest border of the prefix \\(T[1..i]\\), i.e., \\(\\mathsf{B}[i]\\) is the largest integer \\(k \\le i-1\\) such that \\(T[1..k] = T[i-k+1..i]\\). By definition, \\(\\mathsf{B}[0] = 0\\).",
  wikipedia: "Knuth–Morris–Pratt_algorithm"
}, tutorials.bw_transform = {
  title: "BWT",
  content: "The Burrows-Wheeler Transform (BWT) is a reversible transformation that rearranges the characters of a string based on the lexicographical order of its cyclic rotations. Formally, given a text \\(T[1..n]\\) and its rotation array \\(\\mathsf{Rot}\\), the BWT \\(\\mathsf{BWT}[1..n]\\) is defined such that \\(\\mathsf{BWT}[i] = T[(\\mathsf{Rot}[i] + n - 1) \\mod n]\\) for each \\(i \\in [1..n]\\).",
  cite: "burrows94bwt",
  wikipedia: "Burrows%E2%80%93Wheeler_transform"
}, tutorials.first_array = {
  title: "F",
  content: "The First Column Array represents the first column of the sorted rotations of a string, which is obtained by sorting the characters of the string in lexicographical order. Formally, for a given text \\(T[1..n]\\), the First Column Array \\(\\mathsf{F}\\) is defined as the sorted sequence of characters in \\(T\\).",
  cite: "burrows94bwt",
  wikipedia: "Burrows%E2%80%93Wheeler_transform"
}, tutorials.index_array = {
  title: "i",
  content: "The index array contains a sequence of integers from \\(1\\) to \\(n\\), where \\(n\\) is the length of the input text \\(T[1..n]\\). Formally, the index array \\(\\mathsf{i}\\) is defined such that \\(\\mathsf{i}[j] = j\\) for each \\(j \\in [1..n]\\)."
}, tutorials.rotation_array = {
  title: "Rot",
  content: "The rotation array sorts the entry indices of a string based on the lexicographical order of their corresponding cyclic rotations. Formally, the rotation array \\(\\mathsf{Rot}\\) of the text \\(T[1..n]\\) is an array of integers representing the starting indices of all the cyclic rotations of \\(T\\), sorted in lexicographical order. It obeys that \\(T[\\mathsf{Rot}[i]..n]T[1..\\mathsf{Rot}[i]-1] \\prec T[\\mathsf{Rot}[i+1]..n]T[1..\\mathsf{Rot}[i+1]-1]\\) for all text positions \\(i \\in [1..n-1]\\), where $\\prec$ is a total order by assigning lower ranks to lexicographically smaller strings and uses the text position \\(i\\) for tie-breaking."
}, tutorials.inverse_suffix_array = {
  title: "ISA",
  content: "The inverse suffix array provides a mapping from each starting index of the suffixes of a string back to their respective positions in the suffix array. Formally, given the suffix array \\(\\mathsf{SA}\\) of the text \\(T[1..n]\\), the inverse suffix array \\(\\mathsf{ISA}\\) is defined such that \\(\\mathsf{ISA}[\\mathsf{SA}[i]] = i\\) for each \\(i \\in [1..n]\\).",
  cite: "manber93sa",
  wikipedia: "Suffix_array"
}, tutorials.phi_array = {
  title: "&Phi;",
  content: "The Phi array provides a mapping from each starting index of the suffixes of a string to the starting index of the lexicographically preceding suffix. Formally, given the suffix array \\(\\mathsf{SA}\\) and the inverse suffix array \\(\\mathsf{ISA}\\) of the text \\(T[1..n]\\), the Phi array \\(\\mathsf{\\Phi}\\) is defined such that \\(\\mathsf{\\Phi}[i] = \\mathsf{SA}[\\mathsf{ISA}[i] - 1]\\) if \\(\\mathsf{ISA}[i] > 0\\), and \\(\\mathsf{\\Phi}[i] = \\bot\\) if \\(\\mathsf{ISA}[i] = 0\\), for each \\(i \\in [1..n]\\).",
  cite: "karkkainen09plcp"
}, tutorials.inverse_phi_array = {
  title: "&Phi;&#8315;&#185;",
  content: "The inverse Phi array provides a mapping from each starting index of the suffixes of a string to the starting index of the lexicographically succeeding suffix. Formally, given the suffix array \\(\\mathsf{SA}\\) and the inverse suffix array \\(\\mathsf{ISA}\\) of the text \\(T[1..n]\\), the inverse Phi array \\(\\mathsf{\\Phi}^{-1}\\) is defined such that \\(\\mathsf{\\Phi}^{-1}[i] = \\mathsf{SA}[\\mathsf{ISA}[i] + 1]\\) if \\(\\mathsf{ISA}[i] \\le n-1 \\), and \\(\\mathsf{\\Phi}^{-1}[i] = \\bot\\) if \\(\\mathsf{ISA}[i] = n \\), for each \\(i \\in [1..n]\\)."
}, tutorials.lcp_array = {
  title: "LCP",
  content: "The Longest Common Prefix (LCP) array stores the lengths of the longest common prefixes between consecutive suffixes in the suffix array of a string. Formally, for a given text \\(T[1..n]\\) and its suffix array \\(\\mathsf{SA}\\), the LCP array \\(\\mathsf{LCP}[1..n]\\) is defined such that \\(\\mathsf{LCP}[1] = 0\\) and \\(\\mathsf{LCP}[i] = \\text{lcp}(T[\\mathsf{SA}[i]..n], T[\\mathsf{SA}[i-1]..n])\\) for each \\(i \\in [2..n]\\), where \\(\\text{lcp}(S_1, S_2)\\) denotes the length of the longest common prefix between the suffixes \\(S_1\\) and \\(S_2\\).",
  wikipedia: "Longest_common_prefix_array"
}, tutorials.lcp_array = {
  title: "&Sigma; LCP",
  content: "The sum of the Longest Common Prefix (LCP) array values provides a measure of the total length of common prefixes between consecutive suffixes in the suffix array of a string. Formally, for a given LCP array \\(\\mathsf{LCP}[1..n]\\), the sum \\(\\Sigma \\mathsf{LCP}\\) is defined as \\(\\sum_{i=1}^{n} \\mathsf{LCP}[i]\\).",
  wikipedia: "Longest_common_prefix_array"
}, tutorials.plcp_array = {
  title: "PLCP",
  content: "The Permuted Longest Common Prefix (PLCP) array reorders the values of the Longest Common Prefix (LCP) array based on the respective positions in the string. Formally, for the inverse suffix array \\(\\mathsf{ISA}\\) and LCP array \\(\\mathsf{LCP}\\) of the text \\(T[1..n]\\), the PLCP array \\(\\mathsf{PLCP}[1..n]\\) is defined such that \\(\\mathsf{PLCP}[i] = \\mathsf{LCP}[\\mathsf{ISA}[i]]\\) for each \\(i \\in [1..n]\\).",
  cite: "karkkainen09plcp",
  wikipedia: "Longest_common_prefix_array"
}, tutorials.psi_array = {
  title: "&Psi;",
  content: "The Psi array provides a mapping inside the suffix array that advances by one text position. Formally, given the suffix array \\(\\mathsf{SA}\\) and the inverse suffix array \\(\\mathsf{ISA}\\) of the text \\(T[1..n]\\), the Psi array \\(\\mathsf{\\Psi}\\) is defined such that \\(\\mathsf{\\Psi}[i] = \\mathsf{ISA}[\\mathsf{SA}[i] + 1]\\) if \\(\\mathsf{SA}[i] + 1 < n\\), and \\(\\mathsf{\\Psi}[i] = \\bot\\) if \\(\\mathsf{SA}[i] + 1 = n\\), for each \\(i \\in [1..n]\\).",
  cite: "grossi05csa"
}, tutorials.lyndon_factorization = {
  title: "LynF",
  content: "The Lyndon factorization of a string decomposes it into a sequence of Lyndon words in lexicographically non-increasing order, where a Lyndon word is a non-empty string that is strictly smaller in lexicographical order than all of its non-trivial rotations.",
  cite: "chen58lyndon"
}, tutorials.delta = {
  title: "&delta;",
  content: "The substring complexity measure quantifies the maximum ratio of substring complexity to length. Given an array of substring complexities for lengths \\(1\\) to \\(n\\), it computes the maximum value of \\(\\frac{\\mathsf{SC}[k]}{k}\\) for \\(k \\in [1..n]\\), where \\(\\mathsf{SC}[k]\\) is the substring complexity for length \\(k\\).",
  cite: "raskhodnikova13sublinear"
}, tutorials.delta_argmax = {
  title: "max &delta;",
  content: "The substring complexity measure length identifies the substring length that maximizes the ratio of substring complexity to length. Given an array of substring complexities for lengths \\(1\\) to \\(n\\), it computes the length \\(k\\) that maximizes \\(\\frac{\\mathsf{SC}[k]}{k}\\), where \\(\\mathsf{SC}[k]\\) is the substring complexity for length \\(k\\).",
  cite: "raskhodnikova13sublinear"
}, tutorials.substring_complexity = {
  title: "SC",
  content: "The substring complexity array quantifies the number of distinct substrings of various lengths within a string. Given the Longest Common Prefix (LCP) array of a string, the substring complexity array \\(\\mathsf{SC}[1..n]\\) is defined such that for each length \\(k \\in [1..n]\\), \\(\\mathsf{SC}[k]\\) represents the count of distinct substrings of length \\(k\\). The computation leverages the LCP values to efficiently determine the number of new substrings introduced at each length.",
  cite: "raskhodnikova13sublinear"
}, tutorials.lf_array = {
  title: "LF",
  content: "The Last-to-First (LF) mapping array identifies characters from the last column with those from the first column of the Burrows-Wheeler Transform (BWT) that orginated from the same text position. Given the first column \\(\\mathsf{F}\\) and \\(\\textsf{BWT}\\), the LF mapping array \\(\\mathsf{LF}[1..n]\\) is defined such that \\(\\mathsf{LF}[i] = \\text{select}(\\textsf{F}, \\textsf{BWT}[i], \\text{rank}(\\textsf{BWT}, \\textsf{BWT}[i], i))\\) for each \\(i \\in [1..n]\\), where \\(\\text{rank}(\\textsf{BWT}, c, i)\\) counts the occurrences of character \\(c\\) in the prefix \\(\\textsf{BWT}[1..i]\\), and \\(\\text{select}(\\textsf{F}, c, r)\\) finds the position of the \\(r\\)-th occurrence of character \\(c\\) in \\(\\textsf{F}\\).",
  cite: "burrows94bwt",
  wikipedia: "Burrows%E2%80%93Wheeler_transform"
}, tutorials.sl_string = {
  title: "S/L",
  content: "The S/L type string classifies each character in a string as either S-type or L-type based on the lexicographic order of the suffixes starting at those characters. A character at position \\(i\\) is classified as S-type if the suffix starting at \\(i\\) is lexicographically smaller than the suffix starting at \\(i+1\\), and L-type if it is larger. If the suffixes are equal, the type is determined by the type of the suffix starting at \\(i+1\\). Additionally, an S-type character that is the first character or immediately preceded by an L-type character is marked as S*-type.",
  cite: "nong11sais"
}, tutorials.lpf_array = {
  title: "LPF",
  content: "The Longest Previous Factor (LPF) array stores the length of the longest prefix of each suffix of a string that matches a substring starting at a prior position within the same string. Formally, for a given text \\(T[1..n]\\), the LPF array \\(\\mathsf{LPF}[1..n]\\) is defined such that \\(\\mathsf{LPF}[i] = \\max_{j \\in [1..i-1]} \\text{lcp}(T[i..n], T[j..n])\\) for each \\(i \\in [1..n]\\), where \\(\\text{lcp}(S_1, S_2)\\) denotes the length of the longest common prefix between the suffixes \\(S_1\\) and \\(S_2\\)."
}, tutorials.lpnf_array = {
  title: "LPnF",
  content: "The Longest Previous Non-Overlapping Factor (LPnF) array stores the length of the longest prefix of each suffix of a string that matches a substring ending at a prior position within the same string. Formally, for a given text \\(T[1..n]\\), the LPnF array \\(\\mathsf{LPnF}[1..n]\\) is defined such that \\(\\mathsf{LPnF}[i] = \\max_{j \\in [1..i-1]} \\min(i-j,\\text{lcp}(T[i..n], T[j..n]))\\) for each \\(i \\in [1..n]\\), where \\(\\text{lcp}(S_1, S_2)\\) denotes the length of the longest common prefix between the suffixes \\(S_1\\) and \\(S_2\\)."
}, tutorials.lnf_array = {
  title: "LNF",
  content: "The Longest Next Factor (LNF) array is the LPF array of the reversed text."
}, tutorials.lzss_factorization = {
  title: "LZSS",
  content: "The Lempel-Ziv-Storer-Szymanski (LZSS) factorization decomposes a string into a sequence of factors, where each factor is either a new character or a reference to a substring with an earlier starting position. The factorization is constructed greedily by selecting the longest previous factor at each position in the string. Formally, given a text \\(T[1..n]\\) the length of the factor starting at position \\(i\\) is \\(\\max \\{1\\} \\cup \\{\\text{lcp}(T[i..n], T[j..n]) \\mid j \\in [1..i-1] \\}\\).",
  cite: "storer82lzss"
}, tutorials.lzssno_factorization = {
  title: "LZSSno",
  content: "The Lempel-Ziv-Storer-Szymanski non-overlapping (LZSSno) factorization decomposes a string into a sequence of factors, where each factor is either a new character or a reference to a substring ending at an earlier positition. The factorization is constructed greedily by selecting the longest previous non-overlapping factor at each position in the string. Formally, given a text \\(T[1..n]\\) the length of the factor starting at position \\(i\\) is \\(\\max \\{1\\} \\cup \\{\\min(i-j, \\text{lcp}(T[i..n], T[j..n])) \\mid j \\in [1..i-1] \\}\\).",
  cite: "storer82lzss"
}, tutorials.lz77_factorization = {
  title: "LZ77",
  content: "The Lempel-Ziv-77  (LZ77) factorization decomposes a string into a sequence of factors, where each factor is either a new character or a reference to a substring starting at a prior position within the same string. The factorization is constructed greedily by selecting the longest previous factor at each position in the string, with an additional character appended to the factor. Formally, given a text \\(T[1..n]\\) the length of the factor starting at position \\(i\\) is \\(\\max \\{1\\} \\cup \\{\\text{lcp}(T[i..n], T[j..n]) + 1 \\mid j \\in [1..i-1] \\}\\).",
  cite: "ziv77lz"
}, tutorials.reverse_lzss_factorization = {
  title: "rLZSS",
  content: "The Reverse Lempel-Ziv-Storer-Szymanski (rLZSS) factorization of a string is the LZSS factorization of the reversed string obtained by reading the string in reversed order.",
  cite: "storer82lzss"
}, tutorials.lexparse_factorization = {
  title: "LexParse",
  content: "The lexicographic parse (lexparse) decomposes a string into a sequence of factors based on the permuted longest common prefix (PLCP) array. Each factor is determined by the longest prefix of the suffix starting at the current position that matches a substring starting at a lexicographically smaller suffix position. Formally, for a given text \\(T[1..n]\\) and its PLCP array \\(\\mathsf{PLCP}[1..n]\\), the length of the factor starting at position \\(i\\) is \\(\\mathsf{PLCP}[i]\\) or 1 if \\(\\mathsf{PLCP}[i] = 0\\).",
  cite: "navarro21approximation"
}, tutorials.nss_array = {
  title: "NSS",
  content: "The Next Smaller Suffix (NSS) array identifies the subsequent suffix in text order that is lexicographically smaller than the current suffix. Given the inverse suffix array \\(\\mathsf{ISA}\\) of a text \\(T[1..n]\\), the NSS array \\(\\mathsf{NSS}[1..n]\\) is defined such that \\(\\mathsf{NSS}[i] = \\min \\{ j > i \\mid \\mathsf{ISA}[j] < \\mathsf{ISA}[i] \\}\\) if such a \\(j\\) exists, and \\(\\mathsf{NSS}[i] = \\bot \\) otherwise, for each \\(i \\in [1..n]\\)."
}, tutorials.pss_array = {
  title: "PSS",
  content: "The Previous Smaller Suffix (PSS) array identifies the preceding suffix in text order that is lexicographically smaller than the current suffix. Given the inverse suffix array \\(\\mathsf{ISA}\\) of a text \\(T[1..n]\\), the PSS array \\(\\mathsf{PSS}[1..n]\\) is defined such that \\(\\mathsf{PSS}[i] = \\max \\{ j < i \\mid \\mathsf{ISA}[j] < \\mathsf{ISA}[i] \\}\\) if such a \\(j\\) exists, and \\(\\mathsf{PSS}[i] = \\bot \\) otherwise, for each \\(i \\in [1..n]\\)."
}, tutorials.lyndon_array = {
  title: "Lyndon",
  content: "The Lyndon array stores the lengths of the longest Lyndon words starting at each position in a string. A Lyndon word is a non-empty string that is strictly smaller in lexicographical order than all of its non-trivial rotations. Given the Next Smaller Suffix (NSS) array \\(\\mathsf{NSS}[1..n]\\) of a text \\(T[1..n]\\), the Lyndon array \\(\\mathsf{Lyndon}[1..n]\\) is defined such that \\(\\mathsf{Lyndon}[i] = \\mathsf{NSS}[i] - i\\) if \\(\\mathsf{NSS}[i] \\neq \\bot\\), and \\(\\mathsf{Lyndon}[i] = n - i + 1\\) otherwise, for each \\(i \\in [1..n]\\).",
  cite: "franek16algorithms"
}, tutorials.necklace_conjugate_transform = {
  title: "necklace",
  content: "The necklace conjugate of a string is the lexicographically smallest string that can be obtained by rotating the original string. This involves generating all possible rotations (conjugates) of the string and selecting the smallest one in lexicographic order."
}, tutorials.invert_transform = {
  title: "Invert",
  content: "The invert transform of a string maps each character to its complementary character based on the minimum and maximum characters in the string. Specifically, given a text \\(T[1..n]\\), the invert transform \\(\\mathsf{Invert}(T)\\) maps each character \\(T[i]\\) to \\(\\text{max_j} T[j] - (c - \\text{min_j T[j]})\\)."
}, tutorials.revert_transform = {
  title: "Revert",
  content: "The revert transform of a string is obtained by reversing the order of its characters. Given a text \\(T[1..n]\\), the revert transform \\(\\mathsf{Revert}(T)\\) produces the string \\(T[n] T[n-1] \\ldots T[1]\\), where the characters are arranged in the opposite order, effectively reading the string backwards."
}, tutorials.circular_suffix_array = {
  title: "CSA",
  content: "The Circular Suffix Array (CSA) of a string is a permutation of text positions that assigns a rank to each cyclic rotation (conjugate) of the Lyndon factors of the string based on the omega order. Given a text \\(T[1..n]\\) and its Lyndon factorization, the CSA \\(\\mathsf{CSA}[1..n]\\) is defined such that \\(\\mathsf{CSA}[i]\\) gives the starting position in \\(T\\) of the \\(i\\)-th smallest conjugate in \\(\\omega\\)-order among all conjugates of the Lyndon factors of \\(T\\).",
  cite: "hon13spaceefficient"
}, tutorials.inverse_circular_suffix_array = {
  title: "CISA",
  content: "The inverse circular suffix array (ICSA) is the reverse permutation of the circular suffix array (CSA).",
  cite: "hon13spaceefficient"
}, tutorials.bbw_indices = {
  title: "BBWTi",
  content: "The Bijective Burrows-Wheeler Transform Indices (BBWTi) array stores the text positions of the circular sufix array (CSA) decremented by one, but mapping positions at the beginning of Lyndon factors to the end of the respective Lyndon factor.",
  cite: "bannai25survey"
}, tutorials.bbw_transform = {
  title: "BBWT",
  content: "The Bijective Burrows-Wheeler Transform (BBWT) of a string rearranges the characters of the original string based on the Bijective Burrows-Wheeler Transform Indices (BBWTi). Given a text \\(T[1..n]\\) and its BBWTi array \\(\\mathsf{BBWTi}[1..n]\\), the BBWT \\(\\mathsf{BBWT}[1..n]\\) is defined such that \\(\\mathsf{BBWT}[i] = T[\\mathsf{BBWTi}[i]]\\) for each \\(i \\in [1..n]\\).",
  cite: "bannai25survey"
}, tutorials.inverse_bbw_transform = {
  title: "BBWT&#8315;&#185;",
  content: "The inverse Bijective Burrows-Wheeler Transform (inverse BBWT), also called the Gessel-Reutenauer transformation, applies the LF-mapping on the cycles in the BBWT to extract all Lyndon words, which sorted in lexicographically descreing order recovers the original text.",
  cite: "bannai25survey"
}, tutorials.lz78_factorization = {
  title: "LZ78",
  content: "The Lempel-Ziv-78 (LZ78) factorization decomposes a string into a sequence of factors based on previously seen substrings. Each factor consists of a reference to the longest previously seen factor (or zero if none exists) followed by a new character.",
  cite: "ziv78lz"
}, tutorials.lzw_factorization = {
  title: "LZW",
  content: "The Lempel-Ziv-Welch (LZW) factorization decomposes a string into a sequence of factors by building a dictionary of previously seen substrings. Each factor is the longest prefix of the remaining text that exists in the dictionary, followed by the next character.",
  cite: "welch84lzw"
}, tutorials.necklace_factorization = {
  title: "NeckF",
  content: "The Necklace factorization is the Lyndon factorization colliding all equal Lyndon factors to a single factor that is a necklace. The number of factors is the number of distinct Lyndon factors.",
  cite: "chen58lyndon"
}, tutorials.odd_maximal_palindromic_length_array = {
  title: "o-pali",
  content: "The odd maximal palindromic length array (o-pali) stores at each position the length of the left arm of the longest odd-length palindromic substring centered at that position, excluding the position itself in the length measurement. Hence, a palindrome of length \\(2k+1\\) contributes \\(k\\) to the o-pali array at its center position.",
  cite: "manacher75new"
}, tutorials.even_maximal_palindromic_length_array = {
  title: "e-pali",
  content: "The even maximal palindromic length array (e-pali) stores at each position the length of the longest even-length palindromic substring centered between that and its preding position.",
  cite: "manacher75new"
}, tutorials.lzend_factorization = {
  title: "LZend",
  content: "The LZ-end factorization is a restriction of the Lempel-Ziv 77 factorization where each new factor, omitting its last new character, must be the longest possible prefix of the remaining text that also appears ending exactly at the end of a previous factor, or just a single character if no such match exists.",
  cite: "kreft13lzend"
}, tutorials.gamma_factorization = {
  title: "&Gamma;",
  content: "A string attractor is a set of positions in a string such that every distinct substring has at least one occurrence that crosses one of these positions. The smallest string attractor size is the minimum number of positions needed to form such a set. Here, \\(\\Gamma\\) is the leftmost such smallest string attractor, i.e., the one that has the lexicographically smallest sequence of positions.",
  cite: "kempa18stringattractors"
};
class DataStructureList {
  constructor(t, e, n, r) {
    this.dictionary = {}, this.enParent = t, this.disParents = e && e.nodeType ? {
      all: e
    } : e || {}, this.defaultDisParent = this.disParents.all || this.disParents.index || this.disParents.length || this.disParents.string || this.disParents.factor || t, this.onChange = n, this.enableDblClick = r
  }
  getDisabledParent(t) {
    return t ? (t.classList.contains("qa-structure-string") && this.disParents.string ? this.disParents.string : t.classList.contains("qa-structure-index") && this.disParents.index ? this.disParents.index : t.classList.contains("qa-structure-length") && this.disParents.length ? this.disParents.length : t.classList.contains("qa-structure-factor") && this.disParents.factor ? this.disParents.factor : this.defaultDisParent) : this.defaultDisParent
  }
  add(t) {
    this.dictionary[t.dataset.ds] = t;
    var e = this;
    t.ondblclick = function() {
      e.toggle(t.dataset.ds)
    }
  }
}
DataStructureList.prototype.getEnabled = function() {
  for (var t = "", e = this.enParent.getElementsByClassName("qa-structure"), n = 0; n < e.length; n++) {
    var r = e[n].dataset.ds;
    this.enabled(r) && (t += r + "-")
  }
  return t.slice(0, Math.max(0, t.length - 1))
}, DataStructureList.prototype.setEnabled = function(t) {
  for (var e in this.dictionary) this.disable(e);
  for (var n = t.split("-"), r = 0; r < n.length; r++) this.enable(n[r])
}, DataStructureList.prototype.enabled = function(t) {
  return this.dictionary[t] && this.dictionary[t].parentElement == this.enParent
}, DataStructureList.prototype.isIndex = function(t) {
  return this.dictionary[t] && this.dictionary[t].classList.contains("qa-structure-index")
}, DataStructureList.prototype.isLength = function(t) {
  return this.dictionary[t] && this.dictionary[t].classList.contains("qa-structure-length")
}, DataStructureList.prototype.isString = function(t) {
  return this.dictionary[t] && this.dictionary[t].classList.contains("qa-structure-string")
}, DataStructureList.prototype.isFactorization = function(t) {
  return this.dictionary[t] && this.dictionary[t].classList.contains("qa-structure-factor")
}, DataStructureList.prototype.forEachEnabled = function(t) {
  for (var e = this.enParent.getElementsByClassName("qa-structure"), n = 0; n < e.length; n++) {
    var r = e[n].dataset.ds;
    this.enabled(r) && t(r)
  }
}, DataStructureList.prototype.enable = function(t) {
  var e = this.dictionary[t];
  e && (this.enParent.appendChild(e), this.onChange())
}, DataStructureList.prototype.disable = function(t) {
  var e = this.dictionary[t];
  e && (this.getDisabledParent(e).appendChild(e), this.onChange())
}, DataStructureList.prototype.toggle = function(t) {
  this.enabled(t) ? this.disable(t) : this.enable(t)
};
class CounterList {
  constructor(t, e, n, r) {
    this.dictionary = {}, this.enParent = t, this.disParent = e, this.onChange = n, this.enableDblClick = r
  }
  add(t) {
    this.dictionary[t.dataset.ds] = t;
    var e = this;
    t.ondblclick = function() {
      e.toggle(t.dataset.ds)
    }
  }
}

function OptionList(t) {
  this.dictionary = {}, this.onChange = t
}

function toggleVisibility(t, e) {
  for (var n = document.getElementById(t), r = 0; r < n.children.length; r++) n.children[r].classList.contains("qa-item") && (n.children[r].style.display = e ? "block" : "none")
}

function changeVisibility(t, e) {
  const n = e ? "qa-visible" : "qa-hidden",
    r = e ? "qa-hidden" : "qa-visible";
  t.classList.remove(r), t.classList.add(n)
}

function getOwnText(t) {
  let e = "";
  for (const n of t.childNodes) n.nodeType === Node.TEXT_NODE && (e += n.textContent);
  return e
}
var qa_counter_automatic, qa_counter_itemlists, qa_text, qa_ds_output, qa_counter_output, qa_generate_string_list, qa_generate_string_range, qa_generate_string_rank, qa_generate_string_span, qa_transform_active, qa_transform_active_span, qa_transform_list, qa_transform_input;
CounterList.prototype.getEnabled = function() {
  for (var t = "", e = this.enParent.getElementsByClassName("qa-counter"), n = 0; n < e.length; n++) {
    var r = e[n].dataset.ds;
    this.enabled(r) && (t += r + "-")
  }
  return t.slice(0, Math.max(0, t.length - 1))
}, CounterList.prototype.setEnabled = function(t) {
  for (var e in this.dictionary) this.disable(e);
  for (var n = t.split("-"), r = 0; r < n.length; r++) this.enable(n[r])
}, CounterList.prototype.enabled = function(t) {
  return this.dictionary[t] && this.dictionary[t].parentElement == this.enParent
}, CounterList.prototype.forEachEnabled = function(t) {
  for (var e = this.enParent.getElementsByClassName("qa-counter"), n = 0; n < e.length; n++) {
    var r = e[n].dataset.ds;
    this.enabled(r) && t(r)
  }
}, CounterList.prototype.enable = function(t) {
  var e = this.dictionary[t];
  e && (this.enParent.appendChild(e), this.onChange())
}, CounterList.prototype.disable = function(t) {
  var e = this.dictionary[t];
  e && (this.disParent.appendChild(e), this.onChange())
}, CounterList.prototype.toggle = function(t) {
  this.enabled(t) ? this.disable(t) : this.enable(t)
}, OptionList.prototype.add = function(t) {
  this.dictionary[t.dataset.opt] = t, t.onchange = this.onChange
}, OptionList.prototype.getEnabled = function() {
  var t = "";
  for (var e in this.dictionary) this.enabled(e) && (t += e + "-");
  return t.substr(0, Math.max(0, t.length - 1))
}, OptionList.prototype.setEnabled = function(t) {
  for (var e in this.dictionary) this.disable(e);
  for (var n = t.split("-"), r = 0; r < n.length; r++) this.enable(n[r])
}, OptionList.prototype.enabled = function(t) {
  return this.dictionary[t] && this.dictionary[t].checked
}, OptionList.prototype.enable = function(t) {
  var e = this.dictionary[t];
  e && (e.checked = !0, this.onChange())
}, OptionList.prototype.disable = function(t) {
  var e = this.dictionary[t];
  e && (e.checked = !1, this.onChange())
}, OptionList.prototype.toggle = function(t) {
  this.enabled(t) ? this.disable(t) : this.enable(t)
};
var ds_name2html = {},
  counter_name2html = {},
  qa_prepend_input, qa_append_input, qa_separator_input, structures_list, counters_list, options_list, structures_default, counters_default, options_default;
const separator_default = " ";
var is_update_requested = !0,
  is_update_ready = !0,
  generate_string_default, generate_string_range_default, transform_default, prepend_default, append_default, timeout_default;

function update_history() {
  is_update_ready ? (is_update_ready = !1, update_history_internal(), setTimeout(() => {
    is_update_ready = !0, is_update_requested && (is_update_requested = !1, update_history())
  }, 1e3)) : is_update_requested = !0
}
const counter_automatic_default = !0;

function update_history_internal() {
  var t = $.query.empty();
  const e = options_list.enabled("whitespace") ? decodeWhitespaces(qa_text.value) : qa_text.value;
  e && (t = t.set("text", e));
  const n = structures_list.getEnabled();
  n != structures_default && (t = t.set("structures", n));
  const r = options_list.getEnabled();
  r != options_default && (t = t.set("options_list", r));
  const i = decodeWhitespaces(qa_separator_input.value);
  i != separator_default && (t = t.set("sep", i));
  const a = counters_list.getEnabled();
  a != counters_default && (t = t.set("counters", a));
  const o = qa_generate_string_list.value;
  o != generate_string_default && (t = t.set("generate_string", o));
  const s = qa_generate_string_range.value;
  s != generate_string_range_default && (t = t.set("generate_string_range", s));
  const c = qa_transform_list.value;
  c != transform_default && (t = t.set("transform", c));
  const l = qa_transform_input.value;
  "" != l && (t = t.set("transform_input", l));
  const u = qa_timeout_range.value;
  u != timeout_default && (t = t.set("timeout", u));
  const f = qa_prepend_input.value;
  f != prepend_default && (t = t.set("prepend", f));
  const h = qa_append_input.value;
  h != append_default && (t = t.set("append", h));
  const d = qa_counter_automatic.checked;
  d != counter_automatic_default && (t = t.set("counter_automatic", d ? "1" : "0"));
  /* UI state in URL: compact view + hidden lists */
  const cv = document.getElementById("qa-compact-view");
  if (cv) {
    const cvDefault = !!(window.matchMedia && window.matchMedia("(max-width: 640px)").matches);
    const cvOn = !!cv.checked;
    if (cvOn !== cvDefault) t = t.set("compact", cvOn ? "1" : "0");
  }
  const adv = document.getElementById("qa-show-advanced-options");
  if (adv) {
    const advDefault = !(window.matchMedia && window.matchMedia("(max-width: 640px)").matches);
    const advOn = !!adv.checked;
    if (advOn !== advDefault) t = t.set("adv", advOn ? "1" : "0");
  }
  const hidden = [];
  ["qa-structures-enabled", "qa-structures-disabled-string", "qa-structures-disabled-index", "qa-structures-disabled-length", "qa-structures-disabled-factor"].forEach((id) => {
    const el = document.getElementById(id);
    if (!el) return;
    const btn = el.querySelector(".qa-toggle-btn");
    const expanded = btn ? btn.getAttribute("aria-expanded") : null;
    const shown = expanded === null ? true : expanded !== "false";
    if (!shown) hidden.push(id);
  });
  if (hidden.length) t = t.set("hidden_lists", hidden.join(","));;
  window.history.replaceState("", "", window.location.pathname + t.toString())
}

function load_history_internal() {
  const t = $.query.get("text").toString();
  t && (qa_text.value = t);
  const e = $.query.get("counters").toString();
  e && counters_list.setEnabled(e);
  const n = $.query.get("structures").toString();
  n && structures_list.setEnabled(n);
  const r = $.query.get("options_list").toString();
  r && options_list.setEnabled(r);
  const i = $.query.get("sep").toString();
  i && (qa_separator_input.value = encodeWhitespaces(i));
  const a = $.query.get("generate_string").toString();
  a && (qa_generate_string_list.value = a), a && "custom" != a ? (changeVisibility(qa_generate_string_span, !0), changeVisibility(qa_text, !1)) : (changeVisibility(qa_generate_string_span, !1), changeVisibility(qa_text, !0));
  const o = $.query.get("generate_string_range").toString();
  o && (qa_generate_string_range.value = o, qa_generate_string_rank.innerHTML = qa_generate_string_range.value);
  const s = $.query.get("transform").toString();
  s && (qa_transform_list.value = s), "custom" == s ? (changeVisibility(qa_transform_input, !0), changeVisibility(qa_transform_active_span, !0)) : (changeVisibility(qa_transform_input, !1), changeVisibility(qa_transform_active_span, !1));
  const c = $.query.get("transform_input").toString();
  c && (qa_transform_input.value = c);
  const l = $.query.get("timeout").toString();
  l && (qa_timeout_range.value = l, qa_timeout_value.textContent = l);
  const u = $.query.get("prepend").toString();
  u && (qa_prepend_input.value = u);
  const f = $.query.get("append").toString();
  f && (qa_append_input.value = f);
  const h = $.query.get("counter_automatic").toString();
  h && (qa_counter_automatic.checked = "1" == h), qa_counter_automatic.checked ? changeVisibility(qa_counter_itemlists, !1) : changeVisibility(qa_counter_itemlists, !0)
  /* UI state from URL (for setupShowHide + compact view) */
  const __hidden = $.query.get("hidden_lists").toString();
  window.qa_hidden_lists = new Set(__hidden ? __hidden.split(",").filter(Boolean) : []);
  window.qa_compact_param = $.query.get("compact").toString();
  window.qa_adv_param = $.query.get("adv").toString();
}

function updateTextAreas() {
  updateTextArea(qa_text), updateTextArea(qa_ds_output)
}

function updateTextArea(t) {
  t.style.height = "", t.style.height = 10 + t.scrollHeight + "px"
}
var wasWhitespace = !1;

function updateWhitespaces() {
  if (options_list.enabled("whitespace")) {
    const t = qa_text.selectionStart,
      e = qa_text.selectionEnd;
    qa_text.value = encodeWhitespaces(qa_text.value), qa_text.selectionStart = t, qa_text.selectionEnd = e, wasWhitespace = !0
  } else if (wasWhitespace) {
    const t = qa_text.selectionStart,
      e = qa_text.selectionEnd;
    qa_text.value = decodeWhitespaces(qa_text.value), qa_text.selectionStart = t, qa_text.selectionEnd = e, wasWhitespace = !1
  }
}

function eval_with_context(context, js_code) {
  return eval("with(context) { " + js_code + " }")
}

function custom_transform_text(t, e) {
  for (var n = "", r = 0; r < t.length; r++) try {
    const i = eval_with_context({
      i: r,
      text: t
    }, e);
    n += void 0 !== i ? i : t[r]
  } catch (e) {
    return alert("Error in transformation: " + e.message), qa_transform_active.checked = !1, t
  }
  return n
}

function transform_text(t) {
  const e = qa_transform_list.value;
  if ("none" == e) return t;
  if ("custom" == e) return 0 == qa_transform_active.checked ? t : custom_transform_text(t, qa_transform_input.value);
  return build_ds(t, structure_flags[e])[e]
}

function generate_text() {
  return "custom" == qa_generate_string_list.value ? qa_text.value : qa_generate_string_list.value in string_generators ? string_generators[qa_generate_string_list.value](parseInt(qa_generate_string_range.value)) : "Unknown string generator: " + qa_generate_string_list.value
}

function construct_text() {
  qa_generate_string_range.value;
  let t = generate_text();
  return options_list.enabled("whitespace") && (t = decodeWhitespaces(t)), t || (t = qa_text.placeholder), t = transform_text(t), 0 == t.length ? (qa_ds_output.value = "", void(qa_counter_output.value = "")) : (qa_prepend_input.value && (t = qa_prepend_input.value + t), qa_append_input.value && (t += qa_append_input.value), options_list.enabled("dollar") && (t += "\0"), t)
}

function prettify_row(t, e, n, r, i, a) {
  structures_list.isIndex(e) && (0 != i && (n = increment_array(n)), n = replace_invalid_position(n, i + t.length));
  const o = ds_name2html[e] ? ds_name2html[e] : e;
  return structures_list.isString(e) && (n = n.split("\0").join("$")), a ? (structures_list.isString(e) ? (options_list.enabled("whitespace") && (n = encodeWhitespaces(n)), n = prettify_string(n, r, i, options_list.enabled("tabularize"))) : n = structures_list.isFactorization(e) ? options_list.enabled("facttext") ? prettify_factorization(options_list.enabled("whitespace") ? encodeWhitespaces(t) : t, n, r, i) : prettify_array(n.map(t => t ? 1 : 0), r, i) : prettify_array(n, r, i), {
    name: o,
    data: n
  }) : {
    name: o,
    data: n
  }
}

function fill_updates(t) {
  const e = decodeWhitespaces(qa_separator_input.value);
  let n = 0;
  structures_list.forEachEnabled(function(t) {
    const e = ds_name2html[t] ? ds_name2html[t] : t;
    e.length > n && (n = e.length)
  });
  const r = options_list.enabled("baseone") ? 1 : 0,
    i = [];
  if (structures_list.forEachEnabled(function(n) {
      let a = t[n];
      a ? i.push(prettify_row(t.text, n, a, e, r, "plain" == qa_output_select.value)) : i.push("Function " + n + ": not defined")
    }), "plain" == qa_output_select.value) {
    const t = i.map(t => pad_right(t.name + ":", " ", n + 2) + t.data);
    qa_ds_output.value = t.join("\n")
  } else "latex" == qa_output_select.value ? qa_ds_output.value = export_latex(i) : "markdown" == qa_output_select.value ? qa_ds_output.value = export_markdown(i) : qa_ds_output.value = export_csv(i);
  enabled_counters = qa_counter_automatic.checked ? structures_list : counters_list;
  const a = [];
  enabled_counters.forEachEnabled(function(e) {
    let n = t["counter_" + e];
    const r = counter_name2html[e] ? counter_name2html[e] : e;
    if (void 0 === n) {
      if (qa_counter_automatic.checked) return;
      a.push(e + ": not defined")
    } else a.push(r + ": " + n)
  }), qa_counter_output.innerHTML = [...a].map(t => '<span class="qa-item">' + t + "</span>").join("&nbsp;"), updateTextAreas(), update_history()
}
var qa_worker = null,
  qa_is_loaded = !1,
  qa_tutorial_open_button, qa_tutorial_close_button, qa_tutorial_overlay, qa_tutorial_title, qa_tutorial_content, qa_tutorial_oeis, qa_tutorial_cite, qa_tutorial_wikipedia, qa_output_select, qa_timeout_range, qa_timeout_value, qa_computation_status;

function updateArrays() {
  if (!qa_is_loaded || null !== qa_worker) return;
  qa_separator_input.value = encodeWhitespaces(qa_separator_input.value), updateWhitespaces();
  let t = 0;
  structures_list.forEachEnabled(function(e) {
    t |= structure_flags[e]
  }), counters_list.forEachEnabled(function(e) {
    structure_flags[e] && (t |= structure_flags[e]);
    const n = "counter_" + e;
    structure_flags[n] && (t |= structure_flags[n])
  });
  const e = construct_text(),
    n = document.querySelectorAll('script[type="text/js-worker"]');
  if (!n || !n[0].innerHTML) {
    qa_computation_status.textContent = "Warning: No worker scripts found!", qa_timeout_range.disabled = !0;
    const n = build_ds(e, t);
    return n.text = e, void fill_updates(n)
  }
  const r = new Blob(Array.prototype.map.call(document.querySelectorAll("script[type='text/js-worker']"), t => t.textContent), {
      type: "text/javascript"
    }),
    i = window.URL.createObjectURL(r),
    a = Number(qa_timeout_range.value);
  qa_computation_status.textContent = `Computing... (timeout: ${a}s)`;
  const o = Date.now(),
    s = a > 0 ? setTimeout(() => {
      qa_worker.terminate(), qa_worker = null, qa_computation_status.textContent = `Killed after ${a}s`
    }, 1e3 * a) : null;
  (qa_worker = new Worker(i)).onerror = t => {
    qa_worker.terminate(), qa_worker = null, clearTimeout(s), qa_computation_status.textContent = `Error during computation: ${t.message}`
  }, qa_worker.postMessage([e, t]), qa_worker.onmessage = t => {
    const n = t.data;
    n.text = e, qa_worker.terminate(), qa_worker = null, clearTimeout(s), qa_computation_status.textContent = `Computation finished in ${((Date.now()-o)/1e3).toFixed(2)}s`, fill_updates(n)
  }
}

function initDragAndDrop(t, e) {
  var n = Array.isArray(t) ? t : [t, e],
    r = {
      "qa-structures-disabled-string": "qa-structure-string",
      "qa-structures-disabled-index": "qa-structure-index",
      "qa-structures-disabled-length": "qa-structure-length",
      "qa-structures-disabled-factor": "qa-structure-factor"
    };

  function i(t) {
    return t && "qa-structures-enabled" === t.id ? "qa-enabled" : "qa-" + (t && t.id ? t.id : "x")
  }

  function a(t, e) {
    if ("qa-structures-enabled" === t) return !0;
    var n = r[t];
    return !!n && e.classList.contains(n)
  }
  for (var o = 0; o < n.length; o++) {
    var s = n[o];
    s && Sortable.create(s, {
      group: {
        name: i(s),
        pull: !0,
        put: function(t, e, n) {
          return a(t.el.id, n)
        }
      },
      draggable: ".qa-item",
      ghostClass: "qa-item-ghost",
      dragClass: "qa-item-drag",
      onSort: updateArrays
    })
  }
}

function update_tutorial(t, e) {
  if (void 0 === tutorials[t]) return;
  const n = tutorials[t];
  qa_tutorial_title.innerHTML = n.title, qa_tutorial_content.innerHTML = n.content, "undefined" != typeof MathJax && MathJax.typeset([qa_tutorial_content]), void 0 !== n.oeis ? (qa_tutorial_oeis.style.display = "block", qa_tutorial_oeis.innerHTML = "Converges to OEIS sequence " + n.oeis, qa_tutorial_oeis.href = "https://oeis.org/" + n.oeis) : qa_tutorial_oeis.style.display = "none", void 0 !== n.cite ? (qa_tutorial_cite.style.display = "block", qa_tutorial_cite.href = n.cite, void 0 !== citations && "undefined" !== citations[n.cite] && (qa_tutorial_cite.innerHTML = citations[n.cite])) : qa_tutorial_cite.style.display = "none", void 0 !== n.wikipedia ? (qa_tutorial_wikipedia.style.display = "block", qa_tutorial_wikipedia.innerHTML = "Wikipedia Article about " + e, qa_tutorial_wikipedia.href = "https://en.wikipedia.org/wiki/" + n.wikipedia) : qa_tutorial_wikipedia.style.display = "none", qa_tutorial_open_button.innerHTML = "Tell me more about <b>" + e + "</b>!", qa_tutorial_open_button.style.display = "inline-block"
}
window.onload = function() {
  qa_tutorial_open_button = document.getElementById("qa-tutorial-open-button"), qa_tutorial_close_button = document.getElementById("qa-tutorial-close-button"), qa_tutorial_overlay = document.getElementById("qa-tutorial-overlay"), qa_tutorial_title = document.getElementById("qa-tutorial-title"), qa_tutorial_content = document.getElementById("qa-tutorial-content"), qa_tutorial_oeis = document.getElementById("qa-tutorial-oeis"), qa_tutorial_cite = document.getElementById("qa-tutorial-cite"), qa_tutorial_wikipedia = document.getElementById("qa-tutorial-wikipedia"), qa_timeout_range = document.getElementById("qa-timeout-range"), qa_timeout_value = document.getElementById("qa-timeout-value"), qa_timeout_range.oninput = () => {
    qa_timeout_value.textContent = qa_timeout_range.value, update_history()
  }, qa_computation_status = document.getElementById("qa-computation-status"), qa_output_select = document.getElementById("qa-output-select"), qa_counter_itemlists = document.getElementById("qa-counter-itemlists"), qa_counter_automatic = document.getElementById("qa-counter-automatic"), qa_transform_active = document.getElementById("qa-transform-active"), qa_transform_list = document.getElementById("qa-transform-list"), qa_transform_input = document.getElementById("qa-transform-input"), qa_transform_active_span = document.getElementById("qa-transform-active-span"), qa_text = document.getElementById("qa-text"), qa_ds_output = document.getElementById("qa-ds-output"), qa_counter_output = document.getElementById("qa-counter-output"), qa_separator_input = document.getElementById("qa-separator-input"), qa_prepend_input = document.getElementById("qa-prepend-input"), qa_append_input = document.getElementById("qa-append-input"), qa_generate_string_list = document.getElementById("qa-generate-string-list"), qa_generate_string_range = document.getElementById("qa-generate-string-range"), qa_generate_string_rank = document.getElementById("qa-generate-string-rank"), qa_generate_string_span = document.getElementById("qa-generate-string-span"), timeout_default = qa_timeout_range.value, qa_separator_input.value = encodeWhitespaces(separator_default), generate_string_default = qa_generate_string_list.value, generate_string_range_default = qa_generate_string_range.value, transform_default = qa_transform_list.value, prepend_default = qa_prepend_input.value, append_default = qa_append_input.value;
  const t = document.getElementById("qa-structures-enabled"),
    e = {
      string: document.getElementById("qa-structures-disabled-string"),
      index: document.getElementById("qa-structures-disabled-index"),
      length: document.getElementById("qa-structures-disabled-length"),
      factor: document.getElementById("qa-structures-disabled-factor")
    };
  ! function() {
    const t = document.getElementById("qa-structures-disabled-source");
    if (!t) return;
    const n = Array.from(t.querySelectorAll(".qa-structure"));
    n.forEach(t => {
      t.classList.contains("qa-structure-string") ? e.string.appendChild(t) : t.classList.contains("qa-structure-index") ? e.index.appendChild(t) : t.classList.contains("qa-structure-length") ? e.length.appendChild(t) : t.classList.contains("qa-structure-factor") ? e.factor.appendChild(t) : e.index.appendChild(t)
    }), t.remove()
  }();
  const n = document.getElementById("qa-counter-enabled"),
    r = document.getElementById("qa-counter-disabled");
  structures_list = new DataStructureList(t, e, updateArrays, !0), document.querySelectorAll(".qa-structure").forEach(t => {
    structures_list.add(t)
  }), structures_default = structures_list.getEnabled(), counters_list = new CounterList(n, r, updateArrays, !0), document.querySelectorAll(".qa-counter").forEach(t => {
    counters_list.add(t)
  }), counters_default = counters_list.getEnabled(), options_list = new OptionList(updateArrays), document.querySelectorAll(".qa-option-cbx").forEach(t => {
    options_list.add(t)
  }), options_default = options_list.getEnabled(), initDragAndDrop([t, e.string, e.index, e.length, e.factor]), initDragAndDrop(n, r), load_history_internal(), qa_tutorial_open_button.onclick = function() {
    qa_tutorial_overlay.style.display = "block"
  }, qa_tutorial_close_button.onclick = function() {
    qa_tutorial_overlay.style.display = "none"
  }, window.onclick = function(t) {
    t.target == qa_tutorial_overlay && (qa_tutorial_overlay.style.display = "none")
  }, document.querySelectorAll(".qa-item").forEach(t => {
    void 0 !== tutorials[t.dataset.ds] && (t.onmouseover = function() {
      update_tutorial(t.dataset.ds, t.innerHTML)
    })
  });
  const i = [qa_transform_active, qa_prepend_input, qa_append_input, qa_transform_list, qa_transform_input, qa_generate_string_list, qa_output_select];
  for (const t in i) i[t].addEventListener("change", function() {
    updateArrays()
  }), i[t].addEventListener("input", function() {
    updateArrays()
  });
  qa_counter_automatic.addEventListener("change", function() {
    changeVisibility(qa_counter_itemlists, !qa_counter_automatic.checked), updateArrays()
  }), qa_generate_string_range.addEventListener("input", function() {
    qa_generate_string_rank.innerHTML = qa_generate_string_range.value, updateArrays()
  }), qa_transform_list.addEventListener("change", function() {
    qa_transform_active.checked = !1, updateArrays()
  }), qa_generate_string_list.addEventListener("change", function() {
    const t = "custom" != this.value;
    changeVisibility(qa_generate_string_span, t), changeVisibility(qa_text, !t);
    const e = this.selectedIndex,
      n = this.options[e].innerHTML;
    update_tutorial(this.value, n), updateArrays()
  }), qa_transform_list.addEventListener("change", function() {
    const t = "custom" == this.value;
    changeVisibility(qa_transform_input, t), changeVisibility(qa_transform_active_span, t);
    const e = this.selectedIndex,
      n = this.options[e].innerHTML;
    update_tutorial(this.value, n), updateArrays()
  }), qa_transform_input.addEventListener("input", function() {
    qa_transform_active.checked = !1
  }), document.getElementById("qa-counter-disabled-visible").addEventListener("change", function() {
    toggleVisibility("qa-counter-disabled", this.checked)
  }), document.getElementById("qa-counter-enabled-visible").addEventListener("change", function() {
    toggleVisibility("qa-counter-enabled", this.checked)
  }), document.querySelectorAll(".qa-structure").forEach(t => {
    ds_name2html[t.dataset.ds] = getOwnText(t)
  }), document.querySelectorAll(".qa-counter").forEach(t => {
    counter_name2html[t.dataset.ds] = getOwnText(t)
  }), qa_text.oninput = updateArrays, qa_text.onpropertychange = updateArrays, qa_separator_input.oninput = updateArrays, qa_separator_input.onpropertychange = updateArrays, update_history_internal(), qa_is_loaded = !0, updateArrays();
  setupShowHide('qa-structures-enabled', true);
  setupShowHide('qa-structures-disabled-string', true);
  setupShowHide('qa-structures-disabled-index', true);
  setupShowHide('qa-structures-disabled-length', true);
  setupShowHide('qa-structures-disabled-factor', true)
};
  </script>
  
  
  
  <script>
    function setupShowHide(containerId, defaultShown = true) {
      const container = document.getElementById(containerId);
      if (!container) return;

      const btn = container.querySelector('.qa-toggle-btn');
      const colon = container.querySelector('.qa-itemlist-colon');
      if (!btn) return;

      let shown = defaultShown;

      if (window.qa_hidden_lists && window.qa_hidden_lists.has(containerId)) {
        shown = false;
      }

      function getItems() {
        return Array.from(container.querySelectorAll(':scope > .qa-item'));
      }

      function applyVisibilityToItems() {
        getItems().forEach(el => el.classList.toggle('qa-hidden', !shown));
        if (colon) colon.classList.toggle('qa-hidden', !shown);
      }

      function render() {
        btn.textContent = shown ? 'hide' : 'show';
        btn.setAttribute('aria-expanded', String(shown));
        container.dataset.qaShown = shown ? '1' : '0';
        applyVisibilityToItems();
      }

      // Keep "hidden" state consistent when items are moved into/out of this list later.
      const obs = new MutationObserver(() => {
        if (!shown) {
          getItems().forEach(el => el.classList.add('qa-hidden'));
          if (colon) colon.classList.add('qa-hidden');
        }
      });
      obs.observe(container, { childList: true });

      btn.addEventListener('click', (e) => {
        e.preventDefault();
        e.stopPropagation();
        shown = !shown;
        render();
        if (typeof update_history === 'function') update_history();
      });

      render();
    }

  </script>

  <script>
    // Compact view for the data-structures chooser
    (function () {
      const DESC_NORMAL = 'Choose your data structures and factorizations (drag and drop or double-click):<br>\n      You can use drag and drop to reorder your selection!';
      const DESC_COMPACT = 'Choose your data structures and factorizations (use the dropdown to add; double-click to remove):<br>\n      You can use drag and drop to reorder your selection!';

            const DISABLED_IDS = [
        'qa-structures-disabled-string',
        'qa-structures-disabled-index',
        'qa-structures-disabled-length',
        'qa-structures-disabled-factor'
      ];

function structureGroup(el) {
        if (!el) return 'other';
        if (el.classList.contains('qa-structure-string')) return 'string';
        if (el.classList.contains('qa-structure-index')) return 'index';
        if (el.classList.contains('qa-structure-length')) return 'length';
        if (el.classList.contains('qa-structure-factor')) return 'factor';
        return 'other';
      }

      const GROUP_TITLES = {
        string: 'Strings',
        index: 'Index arrays',
        length: 'Length arrays',
        factor: 'Factorizations',
        other: 'Other'
      };

      function getSymbol(el) {
        try {
          if (typeof getOwnText === 'function') return getOwnText(el).trim();
        } catch (_) {}
        // Fallback: first text node
        const node = Array.from(el.childNodes).find(n => n.nodeType === Node.TEXT_NODE);
        return (node ? node.textContent : el.textContent).trim();
      }

      function getLabel(el) {
        const sym = getSymbol(el);
        const tt = el.querySelector('.qa-tooltiptext');
        const desc = tt ? tt.textContent.trim() : '';
        return desc ? `${sym} — ${desc}` : sym;
      }

      function rebuildDropdown() {
        const select = document.getElementById('qa-structures-add-select');
        if (!select || !window.structures_list) return;

        // Keep placeholder
        const placeholder = select.querySelector('option[value=""]');
        select.innerHTML = '';
        if (placeholder) select.appendChild(placeholder);
        placeholder.selected = true;

        const groups = { string: [], index: [], length: [], factor: [], other: [] };
        for (const ds in structures_list.dictionary) {
          if (!structures_list.dictionary.hasOwnProperty(ds)) continue;
          if (structures_list.enabled(ds)) continue;
          const el = structures_list.dictionary[ds];
          groups[structureGroup(el)].push(el);
        }

        // Stable ordering: by label
        for (const k in groups) {
          groups[k].sort((a, b) => getLabel(a).localeCompare(getLabel(b)));
        }

        ['string', 'index', 'length', 'factor', 'other'].forEach(key => {
          if (!groups[key].length) return;
          const og = document.createElement('optgroup');
          og.label = GROUP_TITLES[key] || key;
          groups[key].forEach(el => {
            const opt = document.createElement('option');
            opt.value = el.dataset.ds;
            opt.textContent = getLabel(el);
            og.appendChild(opt);
          });
          select.appendChild(og);
        });
      }

      function setCompactView(on) {
        const desc = document.getElementById('qa-structures-description');
        const controls = document.getElementById('qa-structures-compact-controls');
        const box = document.getElementById('qa-structures-box');
        if (box) box.classList.toggle('qa-compact-on', on);

        if (desc) desc.innerHTML = on ? DESC_COMPACT : DESC_NORMAL;
        if (controls) controls.classList.toggle('qa-hidden', !on);
        DISABLED_IDS.forEach(id => {
          const el = document.getElementById(id);
          if (el) el.classList.toggle('qa-hidden', on);
        });

        if (on) rebuildDropdown();
      }

      window.addEventListener('load', () => {
        const cbx = document.getElementById('qa-compact-view');
        const select = document.getElementById('qa-structures-add-select');
        if (!cbx || !select) return;

        // Keep dropdown in sync whenever the enabled/disabled sets change.
        if (typeof window.updateArrays === 'function') {
          const originalUpdateArrays = window.updateArrays;
          window.updateArrays = function () {
            const r = originalUpdateArrays.apply(this, arguments);
            if (cbx.checked) rebuildDropdown();
            return r;
          };
        }


        // Keep dropdown in sync even when structures are toggled via double-click.
        let rebuildPending = false;
        const scheduleRebuild = () => {
          if (!cbx.checked) return;
          if (rebuildPending) return;
          rebuildPending = true;
          requestAnimationFrame(() => {
            rebuildPending = false;
            rebuildDropdown();
          });
        };

        const watchEls = [
          document.getElementById('qa-structures-enabled'),
          ...DISABLED_IDS.map(id => document.getElementById(id))
        ].filter(Boolean);

        const obs = new MutationObserver(scheduleRebuild);
        watchEls.forEach(el => obs.observe(el, { childList: true }));

        const structuresBox = document.getElementById('qa-structures-box');
        if (structuresBox) structuresBox.addEventListener('dblclick', scheduleRebuild, true);

        cbx.addEventListener('change', () => {
          setCompactView(cbx.checked);
          if (typeof update_history === 'function') update_history();
        });

        select.addEventListener('change', () => {
          const ds = select.value;
          if (!ds || !window.structures_list) return;
          structures_list.enable(ds);
          // Reset to placeholder after enabling.
          const placeholder = select.querySelector('option[value=""]');
          if (placeholder) placeholder.selected = true;
          rebuildDropdown();
        });

        // Initial state: URL overrides defaults; otherwise default depends on media width.
        const urlCompact = (typeof $ !== 'undefined' && $.query) ? $.query.get('compact').toString() : (window.qa_compact_param || '');
        const defaultOn = !!(window.matchMedia && window.matchMedia('(max-width: 640px)').matches);
        const initialOn = urlCompact === '1' ? true : urlCompact === '0' ? false : defaultOn;
        cbx.checked = initialOn;
        setCompactView(initialOn);
      });
    })();
  </script>
  <script>
    // Show/hide advanced options (URL-stored state)
    (function () {
      function apply(on) {
        document.querySelectorAll('.qa-advanced-option').forEach(el => {
          el.classList.toggle('qa-hidden', !on);
        });
      }

      window.addEventListener('load', () => {
        const cbx = document.getElementById('qa-show-advanced-options');
        if (!cbx) return;

        const urlAdv = (typeof $ !== 'undefined' && $.query) ? $.query.get('adv').toString() : (window.qa_adv_param || '');
        const defaultOn = !(window.matchMedia && window.matchMedia('(max-width: 640px)').matches);
        const initialOn = urlAdv === '1' ? true : urlAdv === '0' ? false : defaultOn;

        cbx.checked = initialOn;
        apply(initialOn);

        cbx.addEventListener('change', () => {
          apply(cbx.checked);
          if (typeof update_history === 'function') update_history();
        });
      });
    })();
  </script>

